{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cdb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bbefb",
   "metadata": {},
   "source": [
    "1) More actions, less actions: What are appropriate number of actions to discretise the range -2.0 to 2.0?\n",
    "2) Stability of training, i.e. should you train longer or cut it off within some number of episodes?\n",
    "3) Track the reward, save weights, plot performance. Reproduce your best possible agent by loading your best weights and test it for say, 10 times. Does it consistently balance the pendulum for all 10 times when tested?\n",
    "4) Exploration vs exploitation (the epsilon hyperparameter). Should you decay it?\n",
    "5) Explain the differences between this code and the lab code for cartpole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ce568",
   "metadata": {},
   "source": [
    "# NO NEED GPU! CPU will do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5572aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a3c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self,\n",
    "                 InputShape = 4,\n",
    "                 NActions = 2,\n",
    "                 Gamma = 0.95,  # Discount rate\n",
    "                 epsilon = 1.0,  # Exploration rate\n",
    "                 epsilon_min = 0.1,\n",
    "                 epsilon_decay = 0.995,\n",
    "                 learning_rate = 0.01,\n",
    "                 ReplayMemorySize = 10000,\n",
    "                 MinReplayMemory = 1000,\n",
    "                 UpdateTargetEveryThisEpisodes = 1,\n",
    "                 IntermediateSize = 64,\n",
    "                 BatchSize = 32):\n",
    "        \n",
    "        # Hyperparameters. #\n",
    "        \n",
    "        self.InputShape = InputShape\n",
    "        self.NActions = NActions\n",
    "        self.Gamma = Gamma\n",
    "        self.ReplayMemorySize = ReplayMemorySize\n",
    "        self.MinReplayMemory = MinReplayMemory\n",
    "        self.UpdateTargetEveryThisEpisodes = UpdateTargetEveryThisEpisodes\n",
    "        self.IntermediateSize = IntermediateSize\n",
    "        self.BatchSize = BatchSize\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.total_reward = 0  # Initialize total reward accumulator\n",
    "        self.episode_rewards = []  # List to store rewards for each episode\n",
    "        self.average_rewards = []\n",
    "    \n",
    "\n",
    "\n",
    "        # Main model. #\n",
    "        \n",
    "        self.Main = self.CreateModel('Main')\n",
    "        self.Optimiser = Adam()\n",
    "        \n",
    "        # Target model. #\n",
    "        \n",
    "        self.Target = self.CreateModel('Target')\n",
    "        self.Target.set_weights(self.Main.get_weights())\n",
    "        \n",
    "        # Replay memory. #\n",
    "        \n",
    "        self.ReplayMemory = deque(maxlen = ReplayMemorySize)\n",
    "        \n",
    "        # Target network update counter. #\n",
    "        \n",
    "        self.TargetUpdateCounter = 0\n",
    "\n",
    "    def save_weights(self, dir_path):\n",
    "        print(f'Saving weights to {dir_path}')\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        Main_path = os.path.join(dir_path, 'Main')\n",
    "        Target_path = os.path.join(dir_path, 'Target')\n",
    "        self.Main.save_weights(Main_path + '_main.weights.h5')\n",
    "        self.Target.save_weights(Target_path + '_target.weights.h5')\n",
    "    \n",
    "    \n",
    "    def load_weights(self, path):\n",
    "        print(f'Loading weights from {path}')\n",
    "        Main_path = os.path.join(path, 'Main')\n",
    "        Target_path = os.path.join(path, 'Target')\n",
    "        self.Main.load_weights(Main_path + '_main.weights.h5')\n",
    "        self.Target.load_weights(Target_path + '_target.weights.h5')\n",
    "\n",
    "    def moving_average (self, values, window):\n",
    "        weights = np.repeat(1.0, window)/window\n",
    "        return np.convolve(values, weights, 'valid')\n",
    "    \n",
    "    def plot_rewards(self):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(self.episode_rewards, marker='o')\n",
    "        plt.plot(self.moving_average(self.episode_rewards, 10), marker='o')\n",
    "        plt.title('Episode Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_avg_rewards(self):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(self.average_rewards, marker='o')\n",
    "        plt.plot(self.moving_average(self.average_rewards, 10), marker='o')\n",
    "        plt.title('Episode Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def CreateModel(self, Type):\n",
    "        inputs = Input(shape = (self.InputShape,), name = 'Input')\n",
    "        x = Dense(self.IntermediateSize, activation = 'relu', name = '1stHiddenLayer')(inputs)\n",
    "        x = Dense(self.IntermediateSize, activation = 'relu', name = '2ndHiddenLayer')(x)\n",
    "        outputs = Dense(self.NActions, activation = 'linear', name = 'Output')(x)\n",
    "        \n",
    "        NN = Model(inputs, outputs, name = f'{Type}')\n",
    "        NN.summary()\n",
    "        \n",
    "        return NN\n",
    "    \n",
    "    def UpdateReplayMemory(self, Information): # Information = (state, action, reward, SNext, Done)\n",
    "        self.ReplayMemory.append(Information)\n",
    "\n",
    "        # Epsilon-Greedy Policy to choose action\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # pull random action (exploration)\n",
    "            return random.randrange(self.action_size)\n",
    "        # else pull current-best action (greedy; exploitation)\n",
    "        act_values = self.model.predict(state, verbose = 0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "    def Train(self, EndOfEpisode, reward):\n",
    "        self.total_reward += reward  # Accumulate reward for the current episode\n",
    "\n",
    "        # Only train if replay memory has enough data. #\n",
    "        \n",
    "        if len(self.ReplayMemory) < self.MinReplayMemory:\n",
    "            print(f'DID NOT TRAIN..., replay memory = {len(self.ReplayMemory)}')\n",
    "            return\n",
    "        \n",
    "        # Get batch of data for training. #\n",
    "        \n",
    "        TrainingData = random.sample(self.ReplayMemory, self.BatchSize)\n",
    "        \n",
    "        # Get states from training data, then get corresponding Q values. #\n",
    "        \n",
    "        ListOfS = np.array([element[0] for element in TrainingData])\n",
    "        ListOfQ = np.array(self.Main(ListOfS))\n",
    "        \n",
    "        # Get future states from training data, then get corresponding Q values. #\n",
    "        \n",
    "        ListOfSNext = np.array([element[3] for element in TrainingData])\n",
    "        ListOfQNext = self.Target(ListOfSNext)\n",
    "        \n",
    "        # Build actual training data for neural network. #\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, (state, action, reward, SNext, Done) in enumerate(TrainingData):\n",
    "            if not Done:\n",
    "                MaxQNext = np.max(ListOfQNext[index])\n",
    "                QNext = reward + self.Gamma * MaxQNext\n",
    "            else:\n",
    "                QNext = reward\n",
    "            Q = ListOfQ[index]\n",
    "            Q[action] = QNext\n",
    "        \n",
    "            X.append(state)\n",
    "            Y.append(Q)\n",
    "        \n",
    "        # Train model using tf.GradientTape(), defined below.\n",
    "    \n",
    "        self.GTfit(X, Y)\n",
    "                \n",
    "        # Update target network every episode. #\n",
    "        \n",
    "        if EndOfEpisode:\n",
    "            self.episode_rewards.append(self.total_reward)  # Store total reward for the episode\n",
    "            self.total_reward = 0  # Reset total reward for the next episode\n",
    "            self.TargetUpdateCounter += 1\n",
    "\n",
    "        \n",
    "        # Update target if counter is full. #\n",
    "        \n",
    "        if self.TargetUpdateCounter >= self.UpdateTargetEveryThisEpisodes:\n",
    "            self.Target.set_weights(self.Main.get_weights())\n",
    "            self.TargetUpdateCounter = 0\n",
    "\n",
    "        # Decay epsilon gradually\n",
    "        # if self.epsilon > self.epsilon_min:\n",
    "        #     self.epsilon *= self.epsilon_decay\n",
    "        #     print('epsilon:', self.epsilon)\n",
    "\n",
    "\n",
    "    # This is the tf.GradientTape() which significantly speeds up training of neural networks\n",
    "    @tf.function\n",
    "    def GTfit(self, X, Y):\n",
    "        \n",
    "        # Train the neural network with this batch of data. #\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            Predictions = self.Main(tf.convert_to_tensor(X), training = True)\n",
    "            Loss = tf.math.reduce_mean(tf.math.square(tf.convert_to_tensor(Y) - Predictions))\n",
    "        Grad = tape.gradient(Loss, self.Main.trainable_variables)\n",
    "        self.Optimiser.apply_gradients(zip(Grad, self.Main.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc86272",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnvName = 'Pendulum-v0'\n",
    "IntermediateSize = 64\n",
    "\n",
    "Epsilon_decay = 0.995\n",
    "Epsilon = 1.0\n",
    "ShowEvery = 10\n",
    "InputShape = 3\n",
    "NActions = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543ebad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PendulumActionConverter(action, NActions=NActions):\n",
    "    ActualTorque = (action / NActions - 0.5) * 4\n",
    "    return ActualTorque\n",
    "\n",
    "def PendulumInverseActionConverter(action, NActions=NActions):\n",
    "    ActualA = round((action + 2) * (NActions - 1) / 4)\n",
    "    return(ActualA)\n",
    "\n",
    "def OneEpisode(DQN):\n",
    "    env = gym.make(f'{EnvName}')\n",
    "    state = env.reset()\n",
    "    ListOfRewards = []\n",
    "    Done = False\n",
    "    while not Done:\n",
    "        Q = DQN.Main(state.reshape(-1, state.shape[0]))\n",
    "        if np.random.rand() < Epsilon:\n",
    "            AStep = env.action_space.sample()\n",
    "            action = PendulumInverseActionConverter(AStep[0])\n",
    "        else:\n",
    "            action = np.argmax(Q)\n",
    "            action = PendulumActionConverter(action)\n",
    "            AStep = np.array([action])\n",
    "            action = PendulumInverseActionConverter(action)\n",
    "        Epsilon *= Epsilon_decay \n",
    "        print('Epsilon:',Epsilon)\n",
    "        if not _ % ShowEvery and len(DQN.ReplayMemory) >= DQN.MinReplayMemory:\n",
    "            env.render()\n",
    "        SNext, reward, Done, Info = env.step(AStep)\n",
    "        DQN.UpdateReplayMemory((state, action, reward, SNext, Done))\n",
    "        DQN.Train(Done, reward)\n",
    "        ListOfRewards.append(reward)\n",
    "\n",
    "        if Done:\n",
    "            print(f'Finished! | Return: {np.sum(ListOfRewards)} | average reward: {np.mean(ListOfRewards)}')\n",
    "            env.close()\n",
    "            return ListOfRewards\n",
    "        state = SNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c1d451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'Epsilon' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPISODES):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     reward \u001b[38;5;241m=\u001b[39m OneEpisode(dqn)\n\u001b[0;32m     15\u001b[0m     dqn\u001b[38;5;241m.\u001b[39mepisode_rewards\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39msum(reward))\n\u001b[0;32m     16\u001b[0m     dqn\u001b[38;5;241m.\u001b[39maverage_rewards\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(reward))\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mOneEpisode\u001b[1;34m(DQN)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Done:\n\u001b[0;32m     15\u001b[0m     Q \u001b[38;5;241m=\u001b[39m DQN\u001b[38;5;241m.\u001b[39mMain(state\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, state\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m Epsilon:\n\u001b[0;32m     17\u001b[0m         AStep \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     18\u001b[0m         action \u001b[38;5;241m=\u001b[39m PendulumInverseActionConverter(AStep[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'Epsilon' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import time\n",
    "STARTTIME = time.time()\n",
    "\n",
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "dir_path='best_dqn_weights'\n",
    "# dqn.load_weights(path=dir_path)\n",
    "\n",
    "EPISODES = 150\n",
    "best_reward = -1000\n",
    "avg_reward = []\n",
    "for _ in range(EPISODES):\n",
    "\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    dqn.episode_rewards.append(np.sum(reward))\n",
    "    dqn.average_rewards.append(np.mean(reward))\n",
    "    print(f'Best reward: {best_reward}')\n",
    "    if np.mean(reward) > best_reward:\n",
    "        best_reward = np.mean(reward)\n",
    "        dir_path = 'best_dqn_weights'\n",
    "        print(f'Saving best model weights for episode {_} with reward {np.mean(reward)}')\n",
    "        dqn.save_weights(dir_path=dir_path)\n",
    "        _ = 0\n",
    "        dqn.load_weights(path=dir_path)\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "\n",
    "print(f'Total time taken: {time.time() - STARTTIME} seconds ...')\n",
    "\n",
    "\n",
    "# Plot rewards\n",
    "dqn.plot_rewards()\n",
    "\n",
    "dqn.plot_avg_rewards()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85010d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_dqn_weights\n",
      "Episode 0\n",
      "DID NOT TRAIN..., replay memory = 1\n",
      "DID NOT TRAIN..., replay memory = 2\n",
      "DID NOT TRAIN..., replay memory = 3\n",
      "DID NOT TRAIN..., replay memory = 4\n",
      "DID NOT TRAIN..., replay memory = 5\n",
      "DID NOT TRAIN..., replay memory = 6\n",
      "DID NOT TRAIN..., replay memory = 7\n",
      "DID NOT TRAIN..., replay memory = 8\n",
      "DID NOT TRAIN..., replay memory = 9\n",
      "DID NOT TRAIN..., replay memory = 10\n",
      "DID NOT TRAIN..., replay memory = 11\n",
      "DID NOT TRAIN..., replay memory = 12\n",
      "DID NOT TRAIN..., replay memory = 13\n",
      "DID NOT TRAIN..., replay memory = 14\n",
      "DID NOT TRAIN..., replay memory = 15\n",
      "DID NOT TRAIN..., replay memory = 16\n",
      "DID NOT TRAIN..., replay memory = 17\n",
      "DID NOT TRAIN..., replay memory = 18\n",
      "DID NOT TRAIN..., replay memory = 19\n",
      "DID NOT TRAIN..., replay memory = 20\n",
      "DID NOT TRAIN..., replay memory = 21\n",
      "DID NOT TRAIN..., replay memory = 22\n",
      "DID NOT TRAIN..., replay memory = 23\n",
      "DID NOT TRAIN..., replay memory = 24\n",
      "DID NOT TRAIN..., replay memory = 25\n",
      "DID NOT TRAIN..., replay memory = 26\n",
      "DID NOT TRAIN..., replay memory = 27\n",
      "DID NOT TRAIN..., replay memory = 28\n",
      "DID NOT TRAIN..., replay memory = 29\n",
      "DID NOT TRAIN..., replay memory = 30\n",
      "DID NOT TRAIN..., replay memory = 31\n",
      "DID NOT TRAIN..., replay memory = 32\n",
      "DID NOT TRAIN..., replay memory = 33\n",
      "DID NOT TRAIN..., replay memory = 34\n",
      "DID NOT TRAIN..., replay memory = 35\n",
      "DID NOT TRAIN..., replay memory = 36\n",
      "DID NOT TRAIN..., replay memory = 37\n",
      "DID NOT TRAIN..., replay memory = 38\n",
      "DID NOT TRAIN..., replay memory = 39\n",
      "DID NOT TRAIN..., replay memory = 40\n",
      "DID NOT TRAIN..., replay memory = 41\n",
      "DID NOT TRAIN..., replay memory = 42\n",
      "DID NOT TRAIN..., replay memory = 43\n",
      "DID NOT TRAIN..., replay memory = 44\n",
      "DID NOT TRAIN..., replay memory = 45\n",
      "DID NOT TRAIN..., replay memory = 46\n",
      "DID NOT TRAIN..., replay memory = 47\n",
      "DID NOT TRAIN..., replay memory = 48\n",
      "DID NOT TRAIN..., replay memory = 49\n",
      "DID NOT TRAIN..., replay memory = 50\n",
      "DID NOT TRAIN..., replay memory = 51\n",
      "DID NOT TRAIN..., replay memory = 52\n",
      "DID NOT TRAIN..., replay memory = 53\n",
      "DID NOT TRAIN..., replay memory = 54\n",
      "DID NOT TRAIN..., replay memory = 55\n",
      "DID NOT TRAIN..., replay memory = 56\n",
      "DID NOT TRAIN..., replay memory = 57\n",
      "DID NOT TRAIN..., replay memory = 58\n",
      "DID NOT TRAIN..., replay memory = 59\n",
      "DID NOT TRAIN..., replay memory = 60\n",
      "DID NOT TRAIN..., replay memory = 61\n",
      "DID NOT TRAIN..., replay memory = 62\n",
      "DID NOT TRAIN..., replay memory = 63\n",
      "DID NOT TRAIN..., replay memory = 64\n",
      "DID NOT TRAIN..., replay memory = 65\n",
      "DID NOT TRAIN..., replay memory = 66\n",
      "DID NOT TRAIN..., replay memory = 67\n",
      "DID NOT TRAIN..., replay memory = 68\n",
      "DID NOT TRAIN..., replay memory = 69\n",
      "DID NOT TRAIN..., replay memory = 70\n",
      "DID NOT TRAIN..., replay memory = 71\n",
      "DID NOT TRAIN..., replay memory = 72\n",
      "DID NOT TRAIN..., replay memory = 73\n",
      "DID NOT TRAIN..., replay memory = 74\n",
      "DID NOT TRAIN..., replay memory = 75\n",
      "DID NOT TRAIN..., replay memory = 76\n",
      "DID NOT TRAIN..., replay memory = 77\n",
      "DID NOT TRAIN..., replay memory = 78\n",
      "DID NOT TRAIN..., replay memory = 79\n",
      "DID NOT TRAIN..., replay memory = 80\n",
      "DID NOT TRAIN..., replay memory = 81\n",
      "DID NOT TRAIN..., replay memory = 82\n",
      "DID NOT TRAIN..., replay memory = 83\n",
      "DID NOT TRAIN..., replay memory = 84\n",
      "DID NOT TRAIN..., replay memory = 85\n",
      "DID NOT TRAIN..., replay memory = 86\n",
      "DID NOT TRAIN..., replay memory = 87\n",
      "DID NOT TRAIN..., replay memory = 88\n",
      "DID NOT TRAIN..., replay memory = 89\n",
      "DID NOT TRAIN..., replay memory = 90\n",
      "DID NOT TRAIN..., replay memory = 91\n",
      "DID NOT TRAIN..., replay memory = 92\n",
      "DID NOT TRAIN..., replay memory = 93\n",
      "DID NOT TRAIN..., replay memory = 94\n",
      "DID NOT TRAIN..., replay memory = 95\n",
      "DID NOT TRAIN..., replay memory = 96\n",
      "DID NOT TRAIN..., replay memory = 97\n",
      "DID NOT TRAIN..., replay memory = 98\n",
      "DID NOT TRAIN..., replay memory = 99\n",
      "DID NOT TRAIN..., replay memory = 100\n",
      "DID NOT TRAIN..., replay memory = 101\n",
      "DID NOT TRAIN..., replay memory = 102\n",
      "DID NOT TRAIN..., replay memory = 103\n",
      "DID NOT TRAIN..., replay memory = 104\n",
      "DID NOT TRAIN..., replay memory = 105\n",
      "DID NOT TRAIN..., replay memory = 106\n",
      "DID NOT TRAIN..., replay memory = 107\n",
      "DID NOT TRAIN..., replay memory = 108\n",
      "DID NOT TRAIN..., replay memory = 109\n",
      "DID NOT TRAIN..., replay memory = 110\n",
      "DID NOT TRAIN..., replay memory = 111\n",
      "DID NOT TRAIN..., replay memory = 112\n",
      "DID NOT TRAIN..., replay memory = 113\n",
      "DID NOT TRAIN..., replay memory = 114\n",
      "DID NOT TRAIN..., replay memory = 115\n",
      "DID NOT TRAIN..., replay memory = 116\n",
      "DID NOT TRAIN..., replay memory = 117\n",
      "DID NOT TRAIN..., replay memory = 118\n",
      "DID NOT TRAIN..., replay memory = 119\n",
      "DID NOT TRAIN..., replay memory = 120\n",
      "DID NOT TRAIN..., replay memory = 121\n",
      "DID NOT TRAIN..., replay memory = 122\n",
      "DID NOT TRAIN..., replay memory = 123\n",
      "DID NOT TRAIN..., replay memory = 124\n",
      "DID NOT TRAIN..., replay memory = 125\n",
      "DID NOT TRAIN..., replay memory = 126\n",
      "DID NOT TRAIN..., replay memory = 127\n",
      "DID NOT TRAIN..., replay memory = 128\n",
      "DID NOT TRAIN..., replay memory = 129\n",
      "DID NOT TRAIN..., replay memory = 130\n",
      "DID NOT TRAIN..., replay memory = 131\n",
      "DID NOT TRAIN..., replay memory = 132\n",
      "DID NOT TRAIN..., replay memory = 133\n",
      "DID NOT TRAIN..., replay memory = 134\n",
      "DID NOT TRAIN..., replay memory = 135\n",
      "DID NOT TRAIN..., replay memory = 136\n",
      "DID NOT TRAIN..., replay memory = 137\n",
      "DID NOT TRAIN..., replay memory = 138\n",
      "DID NOT TRAIN..., replay memory = 139\n",
      "DID NOT TRAIN..., replay memory = 140\n",
      "DID NOT TRAIN..., replay memory = 141\n",
      "DID NOT TRAIN..., replay memory = 142\n",
      "DID NOT TRAIN..., replay memory = 143\n",
      "DID NOT TRAIN..., replay memory = 144\n",
      "DID NOT TRAIN..., replay memory = 145\n",
      "DID NOT TRAIN..., replay memory = 146\n",
      "DID NOT TRAIN..., replay memory = 147\n",
      "DID NOT TRAIN..., replay memory = 148\n",
      "DID NOT TRAIN..., replay memory = 149\n",
      "DID NOT TRAIN..., replay memory = 150\n",
      "DID NOT TRAIN..., replay memory = 151\n",
      "DID NOT TRAIN..., replay memory = 152\n",
      "DID NOT TRAIN..., replay memory = 153\n",
      "DID NOT TRAIN..., replay memory = 154\n",
      "DID NOT TRAIN..., replay memory = 155\n",
      "DID NOT TRAIN..., replay memory = 156\n",
      "DID NOT TRAIN..., replay memory = 157\n",
      "DID NOT TRAIN..., replay memory = 158\n",
      "DID NOT TRAIN..., replay memory = 159\n",
      "DID NOT TRAIN..., replay memory = 160\n",
      "DID NOT TRAIN..., replay memory = 161\n",
      "DID NOT TRAIN..., replay memory = 162\n",
      "DID NOT TRAIN..., replay memory = 163\n",
      "DID NOT TRAIN..., replay memory = 164\n",
      "DID NOT TRAIN..., replay memory = 165\n",
      "DID NOT TRAIN..., replay memory = 166\n",
      "DID NOT TRAIN..., replay memory = 167\n",
      "DID NOT TRAIN..., replay memory = 168\n",
      "DID NOT TRAIN..., replay memory = 169\n",
      "DID NOT TRAIN..., replay memory = 170\n",
      "DID NOT TRAIN..., replay memory = 171\n",
      "DID NOT TRAIN..., replay memory = 172\n",
      "DID NOT TRAIN..., replay memory = 173\n",
      "DID NOT TRAIN..., replay memory = 174\n",
      "DID NOT TRAIN..., replay memory = 175\n",
      "DID NOT TRAIN..., replay memory = 176\n",
      "DID NOT TRAIN..., replay memory = 177\n",
      "DID NOT TRAIN..., replay memory = 178\n",
      "DID NOT TRAIN..., replay memory = 179\n",
      "DID NOT TRAIN..., replay memory = 180\n",
      "DID NOT TRAIN..., replay memory = 181\n",
      "DID NOT TRAIN..., replay memory = 182\n",
      "DID NOT TRAIN..., replay memory = 183\n",
      "DID NOT TRAIN..., replay memory = 184\n",
      "DID NOT TRAIN..., replay memory = 185\n",
      "DID NOT TRAIN..., replay memory = 186\n",
      "DID NOT TRAIN..., replay memory = 187\n",
      "DID NOT TRAIN..., replay memory = 188\n",
      "DID NOT TRAIN..., replay memory = 189\n",
      "DID NOT TRAIN..., replay memory = 190\n",
      "DID NOT TRAIN..., replay memory = 191\n",
      "DID NOT TRAIN..., replay memory = 192\n",
      "DID NOT TRAIN..., replay memory = 193\n",
      "DID NOT TRAIN..., replay memory = 194\n",
      "DID NOT TRAIN..., replay memory = 195\n",
      "DID NOT TRAIN..., replay memory = 196\n",
      "DID NOT TRAIN..., replay memory = 197\n",
      "DID NOT TRAIN..., replay memory = 198\n",
      "DID NOT TRAIN..., replay memory = 199\n",
      "DID NOT TRAIN..., replay memory = 200\n",
      "Finished! | Return: -1566.4580871630415 | average reward: -7.8322904358152075\n",
      "Episode 1\n",
      "DID NOT TRAIN..., replay memory = 201\n",
      "DID NOT TRAIN..., replay memory = 202\n",
      "DID NOT TRAIN..., replay memory = 203\n",
      "DID NOT TRAIN..., replay memory = 204\n",
      "DID NOT TRAIN..., replay memory = 205\n",
      "DID NOT TRAIN..., replay memory = 206\n",
      "DID NOT TRAIN..., replay memory = 207\n",
      "DID NOT TRAIN..., replay memory = 208\n",
      "DID NOT TRAIN..., replay memory = 209\n",
      "DID NOT TRAIN..., replay memory = 210\n",
      "DID NOT TRAIN..., replay memory = 211\n",
      "DID NOT TRAIN..., replay memory = 212\n",
      "DID NOT TRAIN..., replay memory = 213\n",
      "DID NOT TRAIN..., replay memory = 214\n",
      "DID NOT TRAIN..., replay memory = 215\n",
      "DID NOT TRAIN..., replay memory = 216\n",
      "DID NOT TRAIN..., replay memory = 217\n",
      "DID NOT TRAIN..., replay memory = 218\n",
      "DID NOT TRAIN..., replay memory = 219\n",
      "DID NOT TRAIN..., replay memory = 220\n",
      "DID NOT TRAIN..., replay memory = 221\n",
      "DID NOT TRAIN..., replay memory = 222\n",
      "DID NOT TRAIN..., replay memory = 223\n",
      "DID NOT TRAIN..., replay memory = 224\n",
      "DID NOT TRAIN..., replay memory = 225\n",
      "DID NOT TRAIN..., replay memory = 226\n",
      "DID NOT TRAIN..., replay memory = 227\n",
      "DID NOT TRAIN..., replay memory = 228\n",
      "DID NOT TRAIN..., replay memory = 229\n",
      "DID NOT TRAIN..., replay memory = 230\n",
      "DID NOT TRAIN..., replay memory = 231\n",
      "DID NOT TRAIN..., replay memory = 232\n",
      "DID NOT TRAIN..., replay memory = 233\n",
      "DID NOT TRAIN..., replay memory = 234\n",
      "DID NOT TRAIN..., replay memory = 235\n",
      "DID NOT TRAIN..., replay memory = 236\n",
      "DID NOT TRAIN..., replay memory = 237\n",
      "DID NOT TRAIN..., replay memory = 238\n",
      "DID NOT TRAIN..., replay memory = 239\n",
      "DID NOT TRAIN..., replay memory = 240\n",
      "DID NOT TRAIN..., replay memory = 241\n",
      "DID NOT TRAIN..., replay memory = 242\n",
      "DID NOT TRAIN..., replay memory = 243\n",
      "DID NOT TRAIN..., replay memory = 244\n",
      "DID NOT TRAIN..., replay memory = 245\n",
      "DID NOT TRAIN..., replay memory = 246\n",
      "DID NOT TRAIN..., replay memory = 247\n",
      "DID NOT TRAIN..., replay memory = 248\n",
      "DID NOT TRAIN..., replay memory = 249\n",
      "DID NOT TRAIN..., replay memory = 250\n",
      "DID NOT TRAIN..., replay memory = 251\n",
      "DID NOT TRAIN..., replay memory = 252\n",
      "DID NOT TRAIN..., replay memory = 253\n",
      "DID NOT TRAIN..., replay memory = 254\n",
      "DID NOT TRAIN..., replay memory = 255\n",
      "DID NOT TRAIN..., replay memory = 256\n",
      "DID NOT TRAIN..., replay memory = 257\n",
      "DID NOT TRAIN..., replay memory = 258\n",
      "DID NOT TRAIN..., replay memory = 259\n",
      "DID NOT TRAIN..., replay memory = 260\n",
      "DID NOT TRAIN..., replay memory = 261\n",
      "DID NOT TRAIN..., replay memory = 262\n",
      "DID NOT TRAIN..., replay memory = 263\n",
      "DID NOT TRAIN..., replay memory = 264\n",
      "DID NOT TRAIN..., replay memory = 265\n",
      "DID NOT TRAIN..., replay memory = 266\n",
      "DID NOT TRAIN..., replay memory = 267\n",
      "DID NOT TRAIN..., replay memory = 268\n",
      "DID NOT TRAIN..., replay memory = 269\n",
      "DID NOT TRAIN..., replay memory = 270\n",
      "DID NOT TRAIN..., replay memory = 271\n",
      "DID NOT TRAIN..., replay memory = 272\n",
      "DID NOT TRAIN..., replay memory = 273\n",
      "DID NOT TRAIN..., replay memory = 274\n",
      "DID NOT TRAIN..., replay memory = 275\n",
      "DID NOT TRAIN..., replay memory = 276\n",
      "DID NOT TRAIN..., replay memory = 277\n",
      "DID NOT TRAIN..., replay memory = 278\n",
      "DID NOT TRAIN..., replay memory = 279\n",
      "DID NOT TRAIN..., replay memory = 280\n",
      "DID NOT TRAIN..., replay memory = 281\n",
      "DID NOT TRAIN..., replay memory = 282\n",
      "DID NOT TRAIN..., replay memory = 283\n",
      "DID NOT TRAIN..., replay memory = 284\n",
      "DID NOT TRAIN..., replay memory = 285\n",
      "DID NOT TRAIN..., replay memory = 286\n",
      "DID NOT TRAIN..., replay memory = 287\n",
      "DID NOT TRAIN..., replay memory = 288\n",
      "DID NOT TRAIN..., replay memory = 289\n",
      "DID NOT TRAIN..., replay memory = 290\n",
      "DID NOT TRAIN..., replay memory = 291\n",
      "DID NOT TRAIN..., replay memory = 292\n",
      "DID NOT TRAIN..., replay memory = 293\n",
      "DID NOT TRAIN..., replay memory = 294\n",
      "DID NOT TRAIN..., replay memory = 295\n",
      "DID NOT TRAIN..., replay memory = 296\n",
      "DID NOT TRAIN..., replay memory = 297\n",
      "DID NOT TRAIN..., replay memory = 298\n",
      "DID NOT TRAIN..., replay memory = 299\n",
      "DID NOT TRAIN..., replay memory = 300\n",
      "DID NOT TRAIN..., replay memory = 301\n",
      "DID NOT TRAIN..., replay memory = 302\n",
      "DID NOT TRAIN..., replay memory = 303\n",
      "DID NOT TRAIN..., replay memory = 304\n",
      "DID NOT TRAIN..., replay memory = 305\n",
      "DID NOT TRAIN..., replay memory = 306\n",
      "DID NOT TRAIN..., replay memory = 307\n",
      "DID NOT TRAIN..., replay memory = 308\n",
      "DID NOT TRAIN..., replay memory = 309\n",
      "DID NOT TRAIN..., replay memory = 310\n",
      "DID NOT TRAIN..., replay memory = 311\n",
      "DID NOT TRAIN..., replay memory = 312\n",
      "DID NOT TRAIN..., replay memory = 313\n",
      "DID NOT TRAIN..., replay memory = 314\n",
      "DID NOT TRAIN..., replay memory = 315\n",
      "DID NOT TRAIN..., replay memory = 316\n",
      "DID NOT TRAIN..., replay memory = 317\n",
      "DID NOT TRAIN..., replay memory = 318\n",
      "DID NOT TRAIN..., replay memory = 319\n",
      "DID NOT TRAIN..., replay memory = 320\n",
      "DID NOT TRAIN..., replay memory = 321\n",
      "DID NOT TRAIN..., replay memory = 322\n",
      "DID NOT TRAIN..., replay memory = 323\n",
      "DID NOT TRAIN..., replay memory = 324\n",
      "DID NOT TRAIN..., replay memory = 325\n",
      "DID NOT TRAIN..., replay memory = 326\n",
      "DID NOT TRAIN..., replay memory = 327\n",
      "DID NOT TRAIN..., replay memory = 328\n",
      "DID NOT TRAIN..., replay memory = 329\n",
      "DID NOT TRAIN..., replay memory = 330\n",
      "DID NOT TRAIN..., replay memory = 331\n",
      "DID NOT TRAIN..., replay memory = 332\n",
      "DID NOT TRAIN..., replay memory = 333\n",
      "DID NOT TRAIN..., replay memory = 334\n",
      "DID NOT TRAIN..., replay memory = 335\n",
      "DID NOT TRAIN..., replay memory = 336\n",
      "DID NOT TRAIN..., replay memory = 337\n",
      "DID NOT TRAIN..., replay memory = 338\n",
      "DID NOT TRAIN..., replay memory = 339\n",
      "DID NOT TRAIN..., replay memory = 340\n",
      "DID NOT TRAIN..., replay memory = 341\n",
      "DID NOT TRAIN..., replay memory = 342\n",
      "DID NOT TRAIN..., replay memory = 343\n",
      "DID NOT TRAIN..., replay memory = 344\n",
      "DID NOT TRAIN..., replay memory = 345\n",
      "DID NOT TRAIN..., replay memory = 346\n",
      "DID NOT TRAIN..., replay memory = 347\n",
      "DID NOT TRAIN..., replay memory = 348\n",
      "DID NOT TRAIN..., replay memory = 349\n",
      "DID NOT TRAIN..., replay memory = 350\n",
      "DID NOT TRAIN..., replay memory = 351\n",
      "DID NOT TRAIN..., replay memory = 352\n",
      "DID NOT TRAIN..., replay memory = 353\n",
      "DID NOT TRAIN..., replay memory = 354\n",
      "DID NOT TRAIN..., replay memory = 355\n",
      "DID NOT TRAIN..., replay memory = 356\n",
      "DID NOT TRAIN..., replay memory = 357\n",
      "DID NOT TRAIN..., replay memory = 358\n",
      "DID NOT TRAIN..., replay memory = 359\n",
      "DID NOT TRAIN..., replay memory = 360\n",
      "DID NOT TRAIN..., replay memory = 361\n",
      "DID NOT TRAIN..., replay memory = 362\n",
      "DID NOT TRAIN..., replay memory = 363\n",
      "DID NOT TRAIN..., replay memory = 364\n",
      "DID NOT TRAIN..., replay memory = 365\n",
      "DID NOT TRAIN..., replay memory = 366\n",
      "DID NOT TRAIN..., replay memory = 367\n",
      "DID NOT TRAIN..., replay memory = 368\n",
      "DID NOT TRAIN..., replay memory = 369\n",
      "DID NOT TRAIN..., replay memory = 370\n",
      "DID NOT TRAIN..., replay memory = 371\n",
      "DID NOT TRAIN..., replay memory = 372\n",
      "DID NOT TRAIN..., replay memory = 373\n",
      "DID NOT TRAIN..., replay memory = 374\n",
      "DID NOT TRAIN..., replay memory = 375\n",
      "DID NOT TRAIN..., replay memory = 376\n",
      "DID NOT TRAIN..., replay memory = 377\n",
      "DID NOT TRAIN..., replay memory = 378\n",
      "DID NOT TRAIN..., replay memory = 379\n",
      "DID NOT TRAIN..., replay memory = 380\n",
      "DID NOT TRAIN..., replay memory = 381\n",
      "DID NOT TRAIN..., replay memory = 382\n",
      "DID NOT TRAIN..., replay memory = 383\n",
      "DID NOT TRAIN..., replay memory = 384\n",
      "DID NOT TRAIN..., replay memory = 385\n",
      "DID NOT TRAIN..., replay memory = 386\n",
      "DID NOT TRAIN..., replay memory = 387\n",
      "DID NOT TRAIN..., replay memory = 388\n",
      "DID NOT TRAIN..., replay memory = 389\n",
      "DID NOT TRAIN..., replay memory = 390\n",
      "DID NOT TRAIN..., replay memory = 391\n",
      "DID NOT TRAIN..., replay memory = 392\n",
      "DID NOT TRAIN..., replay memory = 393\n",
      "DID NOT TRAIN..., replay memory = 394\n",
      "DID NOT TRAIN..., replay memory = 395\n",
      "DID NOT TRAIN..., replay memory = 396\n",
      "DID NOT TRAIN..., replay memory = 397\n",
      "DID NOT TRAIN..., replay memory = 398\n",
      "DID NOT TRAIN..., replay memory = 399\n",
      "DID NOT TRAIN..., replay memory = 400\n",
      "Finished! | Return: -976.2440173007544 | average reward: -4.881220086503772\n",
      "Episode 2\n",
      "DID NOT TRAIN..., replay memory = 401\n",
      "DID NOT TRAIN..., replay memory = 402\n",
      "DID NOT TRAIN..., replay memory = 403\n",
      "DID NOT TRAIN..., replay memory = 404\n",
      "DID NOT TRAIN..., replay memory = 405\n",
      "DID NOT TRAIN..., replay memory = 406\n",
      "DID NOT TRAIN..., replay memory = 407\n",
      "DID NOT TRAIN..., replay memory = 408\n",
      "DID NOT TRAIN..., replay memory = 409\n",
      "DID NOT TRAIN..., replay memory = 410\n",
      "DID NOT TRAIN..., replay memory = 411\n",
      "DID NOT TRAIN..., replay memory = 412\n",
      "DID NOT TRAIN..., replay memory = 413\n",
      "DID NOT TRAIN..., replay memory = 414\n",
      "DID NOT TRAIN..., replay memory = 415\n",
      "DID NOT TRAIN..., replay memory = 416\n",
      "DID NOT TRAIN..., replay memory = 417\n",
      "DID NOT TRAIN..., replay memory = 418\n",
      "DID NOT TRAIN..., replay memory = 419\n",
      "DID NOT TRAIN..., replay memory = 420\n",
      "DID NOT TRAIN..., replay memory = 421\n",
      "DID NOT TRAIN..., replay memory = 422\n",
      "DID NOT TRAIN..., replay memory = 423\n",
      "DID NOT TRAIN..., replay memory = 424\n",
      "DID NOT TRAIN..., replay memory = 425\n",
      "DID NOT TRAIN..., replay memory = 426\n",
      "DID NOT TRAIN..., replay memory = 427\n",
      "DID NOT TRAIN..., replay memory = 428\n",
      "DID NOT TRAIN..., replay memory = 429\n",
      "DID NOT TRAIN..., replay memory = 430\n",
      "DID NOT TRAIN..., replay memory = 431\n",
      "DID NOT TRAIN..., replay memory = 432\n",
      "DID NOT TRAIN..., replay memory = 433\n",
      "DID NOT TRAIN..., replay memory = 434\n",
      "DID NOT TRAIN..., replay memory = 435\n",
      "DID NOT TRAIN..., replay memory = 436\n",
      "DID NOT TRAIN..., replay memory = 437\n",
      "DID NOT TRAIN..., replay memory = 438\n",
      "DID NOT TRAIN..., replay memory = 439\n",
      "DID NOT TRAIN..., replay memory = 440\n",
      "DID NOT TRAIN..., replay memory = 441\n",
      "DID NOT TRAIN..., replay memory = 442\n",
      "DID NOT TRAIN..., replay memory = 443\n",
      "DID NOT TRAIN..., replay memory = 444\n",
      "DID NOT TRAIN..., replay memory = 445\n",
      "DID NOT TRAIN..., replay memory = 446\n",
      "DID NOT TRAIN..., replay memory = 447\n",
      "DID NOT TRAIN..., replay memory = 448\n",
      "DID NOT TRAIN..., replay memory = 449\n",
      "DID NOT TRAIN..., replay memory = 450\n",
      "DID NOT TRAIN..., replay memory = 451\n",
      "DID NOT TRAIN..., replay memory = 452\n",
      "DID NOT TRAIN..., replay memory = 453\n",
      "DID NOT TRAIN..., replay memory = 454\n",
      "DID NOT TRAIN..., replay memory = 455\n",
      "DID NOT TRAIN..., replay memory = 456\n",
      "DID NOT TRAIN..., replay memory = 457\n",
      "DID NOT TRAIN..., replay memory = 458\n",
      "DID NOT TRAIN..., replay memory = 459\n",
      "DID NOT TRAIN..., replay memory = 460\n",
      "DID NOT TRAIN..., replay memory = 461\n",
      "DID NOT TRAIN..., replay memory = 462\n",
      "DID NOT TRAIN..., replay memory = 463\n",
      "DID NOT TRAIN..., replay memory = 464\n",
      "DID NOT TRAIN..., replay memory = 465\n",
      "DID NOT TRAIN..., replay memory = 466\n",
      "DID NOT TRAIN..., replay memory = 467\n",
      "DID NOT TRAIN..., replay memory = 468\n",
      "DID NOT TRAIN..., replay memory = 469\n",
      "DID NOT TRAIN..., replay memory = 470\n",
      "DID NOT TRAIN..., replay memory = 471\n",
      "DID NOT TRAIN..., replay memory = 472\n",
      "DID NOT TRAIN..., replay memory = 473\n",
      "DID NOT TRAIN..., replay memory = 474\n",
      "DID NOT TRAIN..., replay memory = 475\n",
      "DID NOT TRAIN..., replay memory = 476\n",
      "DID NOT TRAIN..., replay memory = 477\n",
      "DID NOT TRAIN..., replay memory = 478\n",
      "DID NOT TRAIN..., replay memory = 479\n",
      "DID NOT TRAIN..., replay memory = 480\n",
      "DID NOT TRAIN..., replay memory = 481\n",
      "DID NOT TRAIN..., replay memory = 482\n",
      "DID NOT TRAIN..., replay memory = 483\n",
      "DID NOT TRAIN..., replay memory = 484\n",
      "DID NOT TRAIN..., replay memory = 485\n",
      "DID NOT TRAIN..., replay memory = 486\n",
      "DID NOT TRAIN..., replay memory = 487\n",
      "DID NOT TRAIN..., replay memory = 488\n",
      "DID NOT TRAIN..., replay memory = 489\n",
      "DID NOT TRAIN..., replay memory = 490\n",
      "DID NOT TRAIN..., replay memory = 491\n",
      "DID NOT TRAIN..., replay memory = 492\n",
      "DID NOT TRAIN..., replay memory = 493\n",
      "DID NOT TRAIN..., replay memory = 494\n",
      "DID NOT TRAIN..., replay memory = 495\n",
      "DID NOT TRAIN..., replay memory = 496\n",
      "DID NOT TRAIN..., replay memory = 497\n",
      "DID NOT TRAIN..., replay memory = 498\n",
      "DID NOT TRAIN..., replay memory = 499\n",
      "DID NOT TRAIN..., replay memory = 500\n",
      "DID NOT TRAIN..., replay memory = 501\n",
      "DID NOT TRAIN..., replay memory = 502\n",
      "DID NOT TRAIN..., replay memory = 503\n",
      "DID NOT TRAIN..., replay memory = 504\n",
      "DID NOT TRAIN..., replay memory = 505\n",
      "DID NOT TRAIN..., replay memory = 506\n",
      "DID NOT TRAIN..., replay memory = 507\n",
      "DID NOT TRAIN..., replay memory = 508\n",
      "DID NOT TRAIN..., replay memory = 509\n",
      "DID NOT TRAIN..., replay memory = 510\n",
      "DID NOT TRAIN..., replay memory = 511\n",
      "DID NOT TRAIN..., replay memory = 512\n",
      "DID NOT TRAIN..., replay memory = 513\n",
      "DID NOT TRAIN..., replay memory = 514\n",
      "DID NOT TRAIN..., replay memory = 515\n",
      "DID NOT TRAIN..., replay memory = 516\n",
      "DID NOT TRAIN..., replay memory = 517\n",
      "DID NOT TRAIN..., replay memory = 518\n",
      "DID NOT TRAIN..., replay memory = 519\n",
      "DID NOT TRAIN..., replay memory = 520\n",
      "DID NOT TRAIN..., replay memory = 521\n",
      "DID NOT TRAIN..., replay memory = 522\n",
      "DID NOT TRAIN..., replay memory = 523\n",
      "DID NOT TRAIN..., replay memory = 524\n",
      "DID NOT TRAIN..., replay memory = 525\n",
      "DID NOT TRAIN..., replay memory = 526\n",
      "DID NOT TRAIN..., replay memory = 527\n",
      "DID NOT TRAIN..., replay memory = 528\n",
      "DID NOT TRAIN..., replay memory = 529\n",
      "DID NOT TRAIN..., replay memory = 530\n",
      "DID NOT TRAIN..., replay memory = 531\n",
      "DID NOT TRAIN..., replay memory = 532\n",
      "DID NOT TRAIN..., replay memory = 533\n",
      "DID NOT TRAIN..., replay memory = 534\n",
      "DID NOT TRAIN..., replay memory = 535\n",
      "DID NOT TRAIN..., replay memory = 536\n",
      "DID NOT TRAIN..., replay memory = 537\n",
      "DID NOT TRAIN..., replay memory = 538\n",
      "DID NOT TRAIN..., replay memory = 539\n",
      "DID NOT TRAIN..., replay memory = 540\n",
      "DID NOT TRAIN..., replay memory = 541\n",
      "DID NOT TRAIN..., replay memory = 542\n",
      "DID NOT TRAIN..., replay memory = 543\n",
      "DID NOT TRAIN..., replay memory = 544\n",
      "DID NOT TRAIN..., replay memory = 545\n",
      "DID NOT TRAIN..., replay memory = 546\n",
      "DID NOT TRAIN..., replay memory = 547\n",
      "DID NOT TRAIN..., replay memory = 548\n",
      "DID NOT TRAIN..., replay memory = 549\n",
      "DID NOT TRAIN..., replay memory = 550\n",
      "DID NOT TRAIN..., replay memory = 551\n",
      "DID NOT TRAIN..., replay memory = 552\n",
      "DID NOT TRAIN..., replay memory = 553\n",
      "DID NOT TRAIN..., replay memory = 554\n",
      "DID NOT TRAIN..., replay memory = 555\n",
      "DID NOT TRAIN..., replay memory = 556\n",
      "DID NOT TRAIN..., replay memory = 557\n",
      "DID NOT TRAIN..., replay memory = 558\n",
      "DID NOT TRAIN..., replay memory = 559\n",
      "DID NOT TRAIN..., replay memory = 560\n",
      "DID NOT TRAIN..., replay memory = 561\n",
      "DID NOT TRAIN..., replay memory = 562\n",
      "DID NOT TRAIN..., replay memory = 563\n",
      "DID NOT TRAIN..., replay memory = 564\n",
      "DID NOT TRAIN..., replay memory = 565\n",
      "DID NOT TRAIN..., replay memory = 566\n",
      "DID NOT TRAIN..., replay memory = 567\n",
      "DID NOT TRAIN..., replay memory = 568\n",
      "DID NOT TRAIN..., replay memory = 569\n",
      "DID NOT TRAIN..., replay memory = 570\n",
      "DID NOT TRAIN..., replay memory = 571\n",
      "DID NOT TRAIN..., replay memory = 572\n",
      "DID NOT TRAIN..., replay memory = 573\n",
      "DID NOT TRAIN..., replay memory = 574\n",
      "DID NOT TRAIN..., replay memory = 575\n",
      "DID NOT TRAIN..., replay memory = 576\n",
      "DID NOT TRAIN..., replay memory = 577\n",
      "DID NOT TRAIN..., replay memory = 578\n",
      "DID NOT TRAIN..., replay memory = 579\n",
      "DID NOT TRAIN..., replay memory = 580\n",
      "DID NOT TRAIN..., replay memory = 581\n",
      "DID NOT TRAIN..., replay memory = 582\n",
      "DID NOT TRAIN..., replay memory = 583\n",
      "DID NOT TRAIN..., replay memory = 584\n",
      "DID NOT TRAIN..., replay memory = 585\n",
      "DID NOT TRAIN..., replay memory = 586\n",
      "DID NOT TRAIN..., replay memory = 587\n",
      "DID NOT TRAIN..., replay memory = 588\n",
      "DID NOT TRAIN..., replay memory = 589\n",
      "DID NOT TRAIN..., replay memory = 590\n",
      "DID NOT TRAIN..., replay memory = 591\n",
      "DID NOT TRAIN..., replay memory = 592\n",
      "DID NOT TRAIN..., replay memory = 593\n",
      "DID NOT TRAIN..., replay memory = 594\n",
      "DID NOT TRAIN..., replay memory = 595\n",
      "DID NOT TRAIN..., replay memory = 596\n",
      "DID NOT TRAIN..., replay memory = 597\n",
      "DID NOT TRAIN..., replay memory = 598\n",
      "DID NOT TRAIN..., replay memory = 599\n",
      "DID NOT TRAIN..., replay memory = 600\n",
      "Finished! | Return: -1457.8993012996948 | average reward: -7.289496506498474\n",
      "Episode 3\n",
      "DID NOT TRAIN..., replay memory = 601\n",
      "DID NOT TRAIN..., replay memory = 602\n",
      "DID NOT TRAIN..., replay memory = 603\n",
      "DID NOT TRAIN..., replay memory = 604\n",
      "DID NOT TRAIN..., replay memory = 605\n",
      "DID NOT TRAIN..., replay memory = 606\n",
      "DID NOT TRAIN..., replay memory = 607\n",
      "DID NOT TRAIN..., replay memory = 608\n",
      "DID NOT TRAIN..., replay memory = 609\n",
      "DID NOT TRAIN..., replay memory = 610\n",
      "DID NOT TRAIN..., replay memory = 611\n",
      "DID NOT TRAIN..., replay memory = 612\n",
      "DID NOT TRAIN..., replay memory = 613\n",
      "DID NOT TRAIN..., replay memory = 614\n",
      "DID NOT TRAIN..., replay memory = 615\n",
      "DID NOT TRAIN..., replay memory = 616\n",
      "DID NOT TRAIN..., replay memory = 617\n",
      "DID NOT TRAIN..., replay memory = 618\n",
      "DID NOT TRAIN..., replay memory = 619\n",
      "DID NOT TRAIN..., replay memory = 620\n",
      "DID NOT TRAIN..., replay memory = 621\n",
      "DID NOT TRAIN..., replay memory = 622\n",
      "DID NOT TRAIN..., replay memory = 623\n",
      "DID NOT TRAIN..., replay memory = 624\n",
      "DID NOT TRAIN..., replay memory = 625\n",
      "DID NOT TRAIN..., replay memory = 626\n",
      "DID NOT TRAIN..., replay memory = 627\n",
      "DID NOT TRAIN..., replay memory = 628\n",
      "DID NOT TRAIN..., replay memory = 629\n",
      "DID NOT TRAIN..., replay memory = 630\n",
      "DID NOT TRAIN..., replay memory = 631\n",
      "DID NOT TRAIN..., replay memory = 632\n",
      "DID NOT TRAIN..., replay memory = 633\n",
      "DID NOT TRAIN..., replay memory = 634\n",
      "DID NOT TRAIN..., replay memory = 635\n",
      "DID NOT TRAIN..., replay memory = 636\n",
      "DID NOT TRAIN..., replay memory = 637\n",
      "DID NOT TRAIN..., replay memory = 638\n",
      "DID NOT TRAIN..., replay memory = 639\n",
      "DID NOT TRAIN..., replay memory = 640\n",
      "DID NOT TRAIN..., replay memory = 641\n",
      "DID NOT TRAIN..., replay memory = 642\n",
      "DID NOT TRAIN..., replay memory = 643\n",
      "DID NOT TRAIN..., replay memory = 644\n",
      "DID NOT TRAIN..., replay memory = 645\n",
      "DID NOT TRAIN..., replay memory = 646\n",
      "DID NOT TRAIN..., replay memory = 647\n",
      "DID NOT TRAIN..., replay memory = 648\n",
      "DID NOT TRAIN..., replay memory = 649\n",
      "DID NOT TRAIN..., replay memory = 650\n",
      "DID NOT TRAIN..., replay memory = 651\n",
      "DID NOT TRAIN..., replay memory = 652\n",
      "DID NOT TRAIN..., replay memory = 653\n",
      "DID NOT TRAIN..., replay memory = 654\n",
      "DID NOT TRAIN..., replay memory = 655\n",
      "DID NOT TRAIN..., replay memory = 656\n",
      "DID NOT TRAIN..., replay memory = 657\n",
      "DID NOT TRAIN..., replay memory = 658\n",
      "DID NOT TRAIN..., replay memory = 659\n",
      "DID NOT TRAIN..., replay memory = 660\n",
      "DID NOT TRAIN..., replay memory = 661\n",
      "DID NOT TRAIN..., replay memory = 662\n",
      "DID NOT TRAIN..., replay memory = 663\n",
      "DID NOT TRAIN..., replay memory = 664\n",
      "DID NOT TRAIN..., replay memory = 665\n",
      "DID NOT TRAIN..., replay memory = 666\n",
      "DID NOT TRAIN..., replay memory = 667\n",
      "DID NOT TRAIN..., replay memory = 668\n",
      "DID NOT TRAIN..., replay memory = 669\n",
      "DID NOT TRAIN..., replay memory = 670\n",
      "DID NOT TRAIN..., replay memory = 671\n",
      "DID NOT TRAIN..., replay memory = 672\n",
      "DID NOT TRAIN..., replay memory = 673\n",
      "DID NOT TRAIN..., replay memory = 674\n",
      "DID NOT TRAIN..., replay memory = 675\n",
      "DID NOT TRAIN..., replay memory = 676\n",
      "DID NOT TRAIN..., replay memory = 677\n",
      "DID NOT TRAIN..., replay memory = 678\n",
      "DID NOT TRAIN..., replay memory = 679\n",
      "DID NOT TRAIN..., replay memory = 680\n",
      "DID NOT TRAIN..., replay memory = 681\n",
      "DID NOT TRAIN..., replay memory = 682\n",
      "DID NOT TRAIN..., replay memory = 683\n",
      "DID NOT TRAIN..., replay memory = 684\n",
      "DID NOT TRAIN..., replay memory = 685\n",
      "DID NOT TRAIN..., replay memory = 686\n",
      "DID NOT TRAIN..., replay memory = 687\n",
      "DID NOT TRAIN..., replay memory = 688\n",
      "DID NOT TRAIN..., replay memory = 689\n",
      "DID NOT TRAIN..., replay memory = 690\n",
      "DID NOT TRAIN..., replay memory = 691\n",
      "DID NOT TRAIN..., replay memory = 692\n",
      "DID NOT TRAIN..., replay memory = 693\n",
      "DID NOT TRAIN..., replay memory = 694\n",
      "DID NOT TRAIN..., replay memory = 695\n",
      "DID NOT TRAIN..., replay memory = 696\n",
      "DID NOT TRAIN..., replay memory = 697\n",
      "DID NOT TRAIN..., replay memory = 698\n",
      "DID NOT TRAIN..., replay memory = 699\n",
      "DID NOT TRAIN..., replay memory = 700\n",
      "DID NOT TRAIN..., replay memory = 701\n",
      "DID NOT TRAIN..., replay memory = 702\n",
      "DID NOT TRAIN..., replay memory = 703\n",
      "DID NOT TRAIN..., replay memory = 704\n",
      "DID NOT TRAIN..., replay memory = 705\n",
      "DID NOT TRAIN..., replay memory = 706\n",
      "DID NOT TRAIN..., replay memory = 707\n",
      "DID NOT TRAIN..., replay memory = 708\n",
      "DID NOT TRAIN..., replay memory = 709\n",
      "DID NOT TRAIN..., replay memory = 710\n",
      "DID NOT TRAIN..., replay memory = 711\n",
      "DID NOT TRAIN..., replay memory = 712\n",
      "DID NOT TRAIN..., replay memory = 713\n",
      "DID NOT TRAIN..., replay memory = 714\n",
      "DID NOT TRAIN..., replay memory = 715\n",
      "DID NOT TRAIN..., replay memory = 716\n",
      "DID NOT TRAIN..., replay memory = 717\n",
      "DID NOT TRAIN..., replay memory = 718\n",
      "DID NOT TRAIN..., replay memory = 719\n",
      "DID NOT TRAIN..., replay memory = 720\n",
      "DID NOT TRAIN..., replay memory = 721\n",
      "DID NOT TRAIN..., replay memory = 722\n",
      "DID NOT TRAIN..., replay memory = 723\n",
      "DID NOT TRAIN..., replay memory = 724\n",
      "DID NOT TRAIN..., replay memory = 725\n",
      "DID NOT TRAIN..., replay memory = 726\n",
      "DID NOT TRAIN..., replay memory = 727\n",
      "DID NOT TRAIN..., replay memory = 728\n",
      "DID NOT TRAIN..., replay memory = 729\n",
      "DID NOT TRAIN..., replay memory = 730\n",
      "DID NOT TRAIN..., replay memory = 731\n",
      "DID NOT TRAIN..., replay memory = 732\n",
      "DID NOT TRAIN..., replay memory = 733\n",
      "DID NOT TRAIN..., replay memory = 734\n",
      "DID NOT TRAIN..., replay memory = 735\n",
      "DID NOT TRAIN..., replay memory = 736\n",
      "DID NOT TRAIN..., replay memory = 737\n",
      "DID NOT TRAIN..., replay memory = 738\n",
      "DID NOT TRAIN..., replay memory = 739\n",
      "DID NOT TRAIN..., replay memory = 740\n",
      "DID NOT TRAIN..., replay memory = 741\n",
      "DID NOT TRAIN..., replay memory = 742\n",
      "DID NOT TRAIN..., replay memory = 743\n",
      "DID NOT TRAIN..., replay memory = 744\n",
      "DID NOT TRAIN..., replay memory = 745\n",
      "DID NOT TRAIN..., replay memory = 746\n",
      "DID NOT TRAIN..., replay memory = 747\n",
      "DID NOT TRAIN..., replay memory = 748\n",
      "DID NOT TRAIN..., replay memory = 749\n",
      "DID NOT TRAIN..., replay memory = 750\n",
      "DID NOT TRAIN..., replay memory = 751\n",
      "DID NOT TRAIN..., replay memory = 752\n",
      "DID NOT TRAIN..., replay memory = 753\n",
      "DID NOT TRAIN..., replay memory = 754\n",
      "DID NOT TRAIN..., replay memory = 755\n",
      "DID NOT TRAIN..., replay memory = 756\n",
      "DID NOT TRAIN..., replay memory = 757\n",
      "DID NOT TRAIN..., replay memory = 758\n",
      "DID NOT TRAIN..., replay memory = 759\n",
      "DID NOT TRAIN..., replay memory = 760\n",
      "DID NOT TRAIN..., replay memory = 761\n",
      "DID NOT TRAIN..., replay memory = 762\n",
      "DID NOT TRAIN..., replay memory = 763\n",
      "DID NOT TRAIN..., replay memory = 764\n",
      "DID NOT TRAIN..., replay memory = 765\n",
      "DID NOT TRAIN..., replay memory = 766\n",
      "DID NOT TRAIN..., replay memory = 767\n",
      "DID NOT TRAIN..., replay memory = 768\n",
      "DID NOT TRAIN..., replay memory = 769\n",
      "DID NOT TRAIN..., replay memory = 770\n",
      "DID NOT TRAIN..., replay memory = 771\n",
      "DID NOT TRAIN..., replay memory = 772\n",
      "DID NOT TRAIN..., replay memory = 773\n",
      "DID NOT TRAIN..., replay memory = 774\n",
      "DID NOT TRAIN..., replay memory = 775\n",
      "DID NOT TRAIN..., replay memory = 776\n",
      "DID NOT TRAIN..., replay memory = 777\n",
      "DID NOT TRAIN..., replay memory = 778\n",
      "DID NOT TRAIN..., replay memory = 779\n",
      "DID NOT TRAIN..., replay memory = 780\n",
      "DID NOT TRAIN..., replay memory = 781\n",
      "DID NOT TRAIN..., replay memory = 782\n",
      "DID NOT TRAIN..., replay memory = 783\n",
      "DID NOT TRAIN..., replay memory = 784\n",
      "DID NOT TRAIN..., replay memory = 785\n",
      "DID NOT TRAIN..., replay memory = 786\n",
      "DID NOT TRAIN..., replay memory = 787\n",
      "DID NOT TRAIN..., replay memory = 788\n",
      "DID NOT TRAIN..., replay memory = 789\n",
      "DID NOT TRAIN..., replay memory = 790\n",
      "DID NOT TRAIN..., replay memory = 791\n",
      "DID NOT TRAIN..., replay memory = 792\n",
      "DID NOT TRAIN..., replay memory = 793\n",
      "DID NOT TRAIN..., replay memory = 794\n",
      "DID NOT TRAIN..., replay memory = 795\n",
      "DID NOT TRAIN..., replay memory = 796\n",
      "DID NOT TRAIN..., replay memory = 797\n",
      "DID NOT TRAIN..., replay memory = 798\n",
      "DID NOT TRAIN..., replay memory = 799\n",
      "DID NOT TRAIN..., replay memory = 800\n",
      "Finished! | Return: -1287.142275478191 | average reward: -6.435711377390955\n",
      "Episode 4\n",
      "DID NOT TRAIN..., replay memory = 801\n",
      "DID NOT TRAIN..., replay memory = 802\n",
      "DID NOT TRAIN..., replay memory = 803\n",
      "DID NOT TRAIN..., replay memory = 804\n",
      "DID NOT TRAIN..., replay memory = 805\n",
      "DID NOT TRAIN..., replay memory = 806\n",
      "DID NOT TRAIN..., replay memory = 807\n",
      "DID NOT TRAIN..., replay memory = 808\n",
      "DID NOT TRAIN..., replay memory = 809\n",
      "DID NOT TRAIN..., replay memory = 810\n",
      "DID NOT TRAIN..., replay memory = 811\n",
      "DID NOT TRAIN..., replay memory = 812\n",
      "DID NOT TRAIN..., replay memory = 813\n",
      "DID NOT TRAIN..., replay memory = 814\n",
      "DID NOT TRAIN..., replay memory = 815\n",
      "DID NOT TRAIN..., replay memory = 816\n",
      "DID NOT TRAIN..., replay memory = 817\n",
      "DID NOT TRAIN..., replay memory = 818\n",
      "DID NOT TRAIN..., replay memory = 819\n",
      "DID NOT TRAIN..., replay memory = 820\n",
      "DID NOT TRAIN..., replay memory = 821\n",
      "DID NOT TRAIN..., replay memory = 822\n",
      "DID NOT TRAIN..., replay memory = 823\n",
      "DID NOT TRAIN..., replay memory = 824\n",
      "DID NOT TRAIN..., replay memory = 825\n",
      "DID NOT TRAIN..., replay memory = 826\n",
      "DID NOT TRAIN..., replay memory = 827\n",
      "DID NOT TRAIN..., replay memory = 828\n",
      "DID NOT TRAIN..., replay memory = 829\n",
      "DID NOT TRAIN..., replay memory = 830\n",
      "DID NOT TRAIN..., replay memory = 831\n",
      "DID NOT TRAIN..., replay memory = 832\n",
      "DID NOT TRAIN..., replay memory = 833\n",
      "DID NOT TRAIN..., replay memory = 834\n",
      "DID NOT TRAIN..., replay memory = 835\n",
      "DID NOT TRAIN..., replay memory = 836\n",
      "DID NOT TRAIN..., replay memory = 837\n",
      "DID NOT TRAIN..., replay memory = 838\n",
      "DID NOT TRAIN..., replay memory = 839\n",
      "DID NOT TRAIN..., replay memory = 840\n",
      "DID NOT TRAIN..., replay memory = 841\n",
      "DID NOT TRAIN..., replay memory = 842\n",
      "DID NOT TRAIN..., replay memory = 843\n",
      "DID NOT TRAIN..., replay memory = 844\n",
      "DID NOT TRAIN..., replay memory = 845\n",
      "DID NOT TRAIN..., replay memory = 846\n",
      "DID NOT TRAIN..., replay memory = 847\n",
      "DID NOT TRAIN..., replay memory = 848\n",
      "DID NOT TRAIN..., replay memory = 849\n",
      "DID NOT TRAIN..., replay memory = 850\n",
      "DID NOT TRAIN..., replay memory = 851\n",
      "DID NOT TRAIN..., replay memory = 852\n",
      "DID NOT TRAIN..., replay memory = 853\n",
      "DID NOT TRAIN..., replay memory = 854\n",
      "DID NOT TRAIN..., replay memory = 855\n",
      "DID NOT TRAIN..., replay memory = 856\n",
      "DID NOT TRAIN..., replay memory = 857\n",
      "DID NOT TRAIN..., replay memory = 858\n",
      "DID NOT TRAIN..., replay memory = 859\n",
      "DID NOT TRAIN..., replay memory = 860\n",
      "DID NOT TRAIN..., replay memory = 861\n",
      "DID NOT TRAIN..., replay memory = 862\n",
      "DID NOT TRAIN..., replay memory = 863\n",
      "DID NOT TRAIN..., replay memory = 864\n",
      "DID NOT TRAIN..., replay memory = 865\n",
      "DID NOT TRAIN..., replay memory = 866\n",
      "DID NOT TRAIN..., replay memory = 867\n",
      "DID NOT TRAIN..., replay memory = 868\n",
      "DID NOT TRAIN..., replay memory = 869\n",
      "DID NOT TRAIN..., replay memory = 870\n",
      "DID NOT TRAIN..., replay memory = 871\n",
      "DID NOT TRAIN..., replay memory = 872\n",
      "DID NOT TRAIN..., replay memory = 873\n",
      "DID NOT TRAIN..., replay memory = 874\n",
      "DID NOT TRAIN..., replay memory = 875\n",
      "DID NOT TRAIN..., replay memory = 876\n",
      "DID NOT TRAIN..., replay memory = 877\n",
      "DID NOT TRAIN..., replay memory = 878\n",
      "DID NOT TRAIN..., replay memory = 879\n",
      "DID NOT TRAIN..., replay memory = 880\n",
      "DID NOT TRAIN..., replay memory = 881\n",
      "DID NOT TRAIN..., replay memory = 882\n",
      "DID NOT TRAIN..., replay memory = 883\n",
      "DID NOT TRAIN..., replay memory = 884\n",
      "DID NOT TRAIN..., replay memory = 885\n",
      "DID NOT TRAIN..., replay memory = 886\n",
      "DID NOT TRAIN..., replay memory = 887\n",
      "DID NOT TRAIN..., replay memory = 888\n",
      "DID NOT TRAIN..., replay memory = 889\n",
      "DID NOT TRAIN..., replay memory = 890\n",
      "DID NOT TRAIN..., replay memory = 891\n",
      "DID NOT TRAIN..., replay memory = 892\n",
      "DID NOT TRAIN..., replay memory = 893\n",
      "DID NOT TRAIN..., replay memory = 894\n",
      "DID NOT TRAIN..., replay memory = 895\n",
      "DID NOT TRAIN..., replay memory = 896\n",
      "DID NOT TRAIN..., replay memory = 897\n",
      "DID NOT TRAIN..., replay memory = 898\n",
      "DID NOT TRAIN..., replay memory = 899\n",
      "DID NOT TRAIN..., replay memory = 900\n",
      "DID NOT TRAIN..., replay memory = 901\n",
      "DID NOT TRAIN..., replay memory = 902\n",
      "DID NOT TRAIN..., replay memory = 903\n",
      "DID NOT TRAIN..., replay memory = 904\n",
      "DID NOT TRAIN..., replay memory = 905\n",
      "DID NOT TRAIN..., replay memory = 906\n",
      "DID NOT TRAIN..., replay memory = 907\n",
      "DID NOT TRAIN..., replay memory = 908\n",
      "DID NOT TRAIN..., replay memory = 909\n",
      "DID NOT TRAIN..., replay memory = 910\n",
      "DID NOT TRAIN..., replay memory = 911\n",
      "DID NOT TRAIN..., replay memory = 912\n",
      "DID NOT TRAIN..., replay memory = 913\n",
      "DID NOT TRAIN..., replay memory = 914\n",
      "DID NOT TRAIN..., replay memory = 915\n",
      "DID NOT TRAIN..., replay memory = 916\n",
      "DID NOT TRAIN..., replay memory = 917\n",
      "DID NOT TRAIN..., replay memory = 918\n",
      "DID NOT TRAIN..., replay memory = 919\n",
      "DID NOT TRAIN..., replay memory = 920\n",
      "DID NOT TRAIN..., replay memory = 921\n",
      "DID NOT TRAIN..., replay memory = 922\n",
      "DID NOT TRAIN..., replay memory = 923\n",
      "DID NOT TRAIN..., replay memory = 924\n",
      "DID NOT TRAIN..., replay memory = 925\n",
      "DID NOT TRAIN..., replay memory = 926\n",
      "DID NOT TRAIN..., replay memory = 927\n",
      "DID NOT TRAIN..., replay memory = 928\n",
      "DID NOT TRAIN..., replay memory = 929\n",
      "DID NOT TRAIN..., replay memory = 930\n",
      "DID NOT TRAIN..., replay memory = 931\n",
      "DID NOT TRAIN..., replay memory = 932\n",
      "DID NOT TRAIN..., replay memory = 933\n",
      "DID NOT TRAIN..., replay memory = 934\n",
      "DID NOT TRAIN..., replay memory = 935\n",
      "DID NOT TRAIN..., replay memory = 936\n",
      "DID NOT TRAIN..., replay memory = 937\n",
      "DID NOT TRAIN..., replay memory = 938\n",
      "DID NOT TRAIN..., replay memory = 939\n",
      "DID NOT TRAIN..., replay memory = 940\n",
      "DID NOT TRAIN..., replay memory = 941\n",
      "DID NOT TRAIN..., replay memory = 942\n",
      "DID NOT TRAIN..., replay memory = 943\n",
      "DID NOT TRAIN..., replay memory = 944\n",
      "DID NOT TRAIN..., replay memory = 945\n",
      "DID NOT TRAIN..., replay memory = 946\n",
      "DID NOT TRAIN..., replay memory = 947\n",
      "DID NOT TRAIN..., replay memory = 948\n",
      "DID NOT TRAIN..., replay memory = 949\n",
      "DID NOT TRAIN..., replay memory = 950\n",
      "DID NOT TRAIN..., replay memory = 951\n",
      "DID NOT TRAIN..., replay memory = 952\n",
      "DID NOT TRAIN..., replay memory = 953\n",
      "DID NOT TRAIN..., replay memory = 954\n",
      "DID NOT TRAIN..., replay memory = 955\n",
      "DID NOT TRAIN..., replay memory = 956\n",
      "DID NOT TRAIN..., replay memory = 957\n",
      "DID NOT TRAIN..., replay memory = 958\n",
      "DID NOT TRAIN..., replay memory = 959\n",
      "DID NOT TRAIN..., replay memory = 960\n",
      "DID NOT TRAIN..., replay memory = 961\n",
      "DID NOT TRAIN..., replay memory = 962\n",
      "DID NOT TRAIN..., replay memory = 963\n",
      "DID NOT TRAIN..., replay memory = 964\n",
      "DID NOT TRAIN..., replay memory = 965\n",
      "DID NOT TRAIN..., replay memory = 966\n",
      "DID NOT TRAIN..., replay memory = 967\n",
      "DID NOT TRAIN..., replay memory = 968\n",
      "DID NOT TRAIN..., replay memory = 969\n",
      "DID NOT TRAIN..., replay memory = 970\n",
      "DID NOT TRAIN..., replay memory = 971\n",
      "DID NOT TRAIN..., replay memory = 972\n",
      "DID NOT TRAIN..., replay memory = 973\n",
      "DID NOT TRAIN..., replay memory = 974\n",
      "DID NOT TRAIN..., replay memory = 975\n",
      "DID NOT TRAIN..., replay memory = 976\n",
      "DID NOT TRAIN..., replay memory = 977\n",
      "DID NOT TRAIN..., replay memory = 978\n",
      "DID NOT TRAIN..., replay memory = 979\n",
      "DID NOT TRAIN..., replay memory = 980\n",
      "DID NOT TRAIN..., replay memory = 981\n",
      "DID NOT TRAIN..., replay memory = 982\n",
      "DID NOT TRAIN..., replay memory = 983\n",
      "DID NOT TRAIN..., replay memory = 984\n",
      "DID NOT TRAIN..., replay memory = 985\n",
      "DID NOT TRAIN..., replay memory = 986\n",
      "DID NOT TRAIN..., replay memory = 987\n",
      "DID NOT TRAIN..., replay memory = 988\n",
      "DID NOT TRAIN..., replay memory = 989\n",
      "DID NOT TRAIN..., replay memory = 990\n",
      "DID NOT TRAIN..., replay memory = 991\n",
      "DID NOT TRAIN..., replay memory = 992\n",
      "DID NOT TRAIN..., replay memory = 993\n",
      "DID NOT TRAIN..., replay memory = 994\n",
      "DID NOT TRAIN..., replay memory = 995\n",
      "DID NOT TRAIN..., replay memory = 996\n",
      "DID NOT TRAIN..., replay memory = 997\n",
      "DID NOT TRAIN..., replay memory = 998\n",
      "DID NOT TRAIN..., replay memory = 999\n",
      "epsilon: 0.995\n",
      "Finished! | Return: -1081.3809457920656 | average reward: -5.4069047289603285\n",
      "Episode 5\n",
      "epsilon: 0.990025\n",
      "epsilon: 0.985074875\n",
      "epsilon: 0.9801495006250001\n",
      "epsilon: 0.9752487531218751\n",
      "epsilon: 0.9703725093562657\n",
      "epsilon: 0.9655206468094844\n",
      "epsilon: 0.960693043575437\n",
      "epsilon: 0.9558895783575597\n",
      "epsilon: 0.9511101304657719\n",
      "epsilon: 0.946354579813443\n",
      "epsilon: 0.9416228069143757\n",
      "epsilon: 0.9369146928798039\n",
      "epsilon: 0.9322301194154049\n",
      "epsilon: 0.9275689688183278\n",
      "epsilon: 0.9229311239742362\n",
      "epsilon: 0.918316468354365\n",
      "epsilon: 0.9137248860125932\n",
      "epsilon: 0.9091562615825302\n",
      "epsilon: 0.9046104802746175\n",
      "epsilon: 0.9000874278732445\n",
      "epsilon: 0.8955869907338783\n",
      "epsilon: 0.8911090557802088\n",
      "epsilon: 0.8866535105013078\n",
      "epsilon: 0.8822202429488013\n",
      "epsilon: 0.8778091417340573\n",
      "epsilon: 0.8734200960253871\n",
      "epsilon: 0.8690529955452602\n",
      "epsilon: 0.8647077305675338\n",
      "epsilon: 0.8603841919146962\n",
      "epsilon: 0.8560822709551227\n",
      "epsilon: 0.851801859600347\n",
      "epsilon: 0.8475428503023453\n",
      "epsilon: 0.8433051360508336\n",
      "epsilon: 0.8390886103705794\n",
      "epsilon: 0.8348931673187264\n",
      "epsilon: 0.8307187014821328\n",
      "epsilon: 0.8265651079747222\n",
      "epsilon: 0.8224322824348486\n",
      "epsilon: 0.8183201210226743\n",
      "epsilon: 0.8142285204175609\n",
      "epsilon: 0.810157377815473\n",
      "epsilon: 0.8061065909263957\n",
      "epsilon: 0.8020760579717637\n",
      "epsilon: 0.798065677681905\n",
      "epsilon: 0.7940753492934954\n",
      "epsilon: 0.7901049725470279\n",
      "epsilon: 0.7861544476842928\n",
      "epsilon: 0.7822236754458713\n",
      "epsilon: 0.778312557068642\n",
      "epsilon: 0.7744209942832988\n",
      "epsilon: 0.7705488893118823\n",
      "epsilon: 0.7666961448653229\n",
      "epsilon: 0.7628626641409962\n",
      "epsilon: 0.7590483508202912\n",
      "epsilon: 0.7552531090661897\n",
      "epsilon: 0.7514768435208588\n",
      "epsilon: 0.7477194593032545\n",
      "epsilon: 0.7439808620067382\n",
      "epsilon: 0.7402609576967045\n",
      "epsilon: 0.736559652908221\n",
      "epsilon: 0.7328768546436799\n",
      "epsilon: 0.7292124703704616\n",
      "epsilon: 0.7255664080186093\n",
      "epsilon: 0.7219385759785162\n",
      "epsilon: 0.7183288830986236\n",
      "epsilon: 0.7147372386831305\n",
      "epsilon: 0.7111635524897149\n",
      "epsilon: 0.7076077347272662\n",
      "epsilon: 0.7040696960536299\n",
      "epsilon: 0.7005493475733617\n",
      "epsilon: 0.697046600835495\n",
      "epsilon: 0.6935613678313175\n",
      "epsilon: 0.6900935609921609\n",
      "epsilon: 0.6866430931872001\n",
      "epsilon: 0.6832098777212641\n",
      "epsilon: 0.6797938283326578\n",
      "epsilon: 0.6763948591909945\n",
      "epsilon: 0.6730128848950395\n",
      "epsilon: 0.6696478204705644\n",
      "epsilon: 0.6662995813682115\n",
      "epsilon: 0.6629680834613705\n",
      "epsilon: 0.6596532430440636\n",
      "epsilon: 0.6563549768288433\n",
      "epsilon: 0.653073201944699\n",
      "epsilon: 0.6498078359349755\n",
      "epsilon: 0.6465587967553006\n",
      "epsilon: 0.6433260027715241\n",
      "epsilon: 0.6401093727576664\n",
      "epsilon: 0.6369088258938781\n",
      "epsilon: 0.6337242817644086\n",
      "epsilon: 0.6305556603555866\n",
      "epsilon: 0.6274028820538087\n",
      "epsilon: 0.6242658676435396\n",
      "epsilon: 0.6211445383053219\n",
      "epsilon: 0.6180388156137953\n",
      "epsilon: 0.6149486215357263\n",
      "epsilon: 0.6118738784280476\n",
      "epsilon: 0.6088145090359074\n",
      "epsilon: 0.6057704364907278\n",
      "epsilon: 0.6027415843082742\n",
      "epsilon: 0.5997278763867329\n",
      "epsilon: 0.5967292370047992\n",
      "epsilon: 0.5937455908197752\n",
      "epsilon: 0.5907768628656763\n",
      "epsilon: 0.5878229785513479\n",
      "epsilon: 0.5848838636585911\n",
      "epsilon: 0.5819594443402982\n",
      "epsilon: 0.5790496471185967\n",
      "epsilon: 0.5761543988830038\n",
      "epsilon: 0.5732736268885887\n",
      "epsilon: 0.5704072587541458\n",
      "epsilon: 0.567555222460375\n",
      "epsilon: 0.5647174463480732\n",
      "epsilon: 0.5618938591163328\n",
      "epsilon: 0.5590843898207511\n",
      "epsilon: 0.5562889678716474\n",
      "epsilon: 0.5535075230322891\n",
      "epsilon: 0.5507399854171277\n",
      "epsilon: 0.547986285490042\n",
      "epsilon: 0.5452463540625918\n",
      "epsilon: 0.5425201222922789\n",
      "epsilon: 0.5398075216808175\n",
      "epsilon: 0.5371084840724134\n",
      "epsilon: 0.5344229416520513\n",
      "epsilon: 0.531750826943791\n",
      "epsilon: 0.5290920728090721\n",
      "epsilon: 0.5264466124450268\n",
      "epsilon: 0.5238143793828016\n",
      "epsilon: 0.5211953074858876\n",
      "epsilon: 0.5185893309484582\n",
      "epsilon: 0.5159963842937159\n",
      "epsilon: 0.5134164023722473\n",
      "epsilon: 0.510849320360386\n",
      "epsilon: 0.5082950737585841\n",
      "epsilon: 0.5057535983897912\n",
      "epsilon: 0.5032248303978422\n",
      "epsilon: 0.500708706245853\n",
      "epsilon: 0.4982051627146237\n",
      "epsilon: 0.49571413690105054\n",
      "epsilon: 0.4932355662165453\n",
      "epsilon: 0.4907693883854626\n",
      "epsilon: 0.4883155414435353\n",
      "epsilon: 0.4858739637363176\n",
      "epsilon: 0.483444593917636\n",
      "epsilon: 0.4810273709480478\n",
      "epsilon: 0.47862223409330756\n",
      "epsilon: 0.47622912292284103\n",
      "epsilon: 0.4738479773082268\n",
      "epsilon: 0.47147873742168567\n",
      "epsilon: 0.46912134373457726\n",
      "epsilon: 0.46677573701590436\n",
      "epsilon: 0.46444185833082485\n",
      "epsilon: 0.46211964903917074\n",
      "epsilon: 0.4598090507939749\n",
      "epsilon: 0.457510005540005\n",
      "epsilon: 0.45522245551230495\n",
      "epsilon: 0.4529463432347434\n",
      "epsilon: 0.4506816115185697\n",
      "epsilon: 0.4484282034609769\n",
      "epsilon: 0.446186062443672\n",
      "epsilon: 0.4439551321314536\n",
      "epsilon: 0.4417353564707963\n",
      "epsilon: 0.43952667968844233\n",
      "epsilon: 0.43732904629000013\n",
      "epsilon: 0.4351424010585501\n",
      "epsilon: 0.43296668905325736\n",
      "epsilon: 0.43080185560799106\n",
      "epsilon: 0.4286478463299511\n",
      "epsilon: 0.42650460709830135\n",
      "epsilon: 0.42437208406280985\n",
      "epsilon: 0.4222502236424958\n",
      "epsilon: 0.42013897252428334\n",
      "epsilon: 0.4180382776616619\n",
      "epsilon: 0.4159480862733536\n",
      "epsilon: 0.41386834584198684\n",
      "epsilon: 0.4117990041127769\n",
      "epsilon: 0.40974000909221303\n",
      "epsilon: 0.40769130904675194\n",
      "epsilon: 0.40565285250151817\n",
      "epsilon: 0.4036245882390106\n",
      "epsilon: 0.4016064652978155\n",
      "epsilon: 0.3995984329713264\n",
      "epsilon: 0.3976004408064698\n",
      "epsilon: 0.39561243860243744\n",
      "epsilon: 0.3936343764094253\n",
      "epsilon: 0.39166620452737816\n",
      "epsilon: 0.3897078735047413\n",
      "epsilon: 0.3877593341372176\n",
      "epsilon: 0.3858205374665315\n",
      "epsilon: 0.38389143477919885\n",
      "epsilon: 0.3819719776053028\n",
      "epsilon: 0.3800621177172763\n",
      "epsilon: 0.37816180712868996\n",
      "epsilon: 0.37627099809304654\n",
      "epsilon: 0.3743896431025813\n",
      "epsilon: 0.37251769488706843\n",
      "epsilon: 0.3706551064126331\n",
      "epsilon: 0.36880183088056995\n",
      "epsilon: 0.3669578217261671\n",
      "epsilon: 0.36512303261753626\n",
      "Finished! | Return: -1677.4635592869017 | average reward: -8.387317796434509\n",
      "Episode 6\n",
      "epsilon: 0.3632974174544486\n",
      "epsilon: 0.3614809303671764\n",
      "epsilon: 0.3596735257153405\n",
      "epsilon: 0.3578751580867638\n",
      "epsilon: 0.35608578229633\n",
      "epsilon: 0.3543053533848483\n",
      "epsilon: 0.35253382661792404\n",
      "epsilon: 0.3507711574848344\n",
      "epsilon: 0.34901730169741024\n",
      "epsilon: 0.3472722151889232\n",
      "epsilon: 0.3455358541129786\n",
      "epsilon: 0.3438081748424137\n",
      "epsilon: 0.3420891339682016\n",
      "epsilon: 0.3403786882983606\n",
      "epsilon: 0.3386767948568688\n",
      "epsilon: 0.33698341088258443\n",
      "epsilon: 0.3352984938281715\n",
      "epsilon: 0.33362200135903064\n",
      "epsilon: 0.33195389135223546\n",
      "epsilon: 0.3302941218954743\n",
      "epsilon: 0.32864265128599696\n",
      "epsilon: 0.326999438029567\n",
      "epsilon: 0.3253644408394192\n",
      "epsilon: 0.3237376186352221\n",
      "epsilon: 0.322118930542046\n",
      "epsilon: 0.32050833588933575\n",
      "epsilon: 0.31890579420988907\n",
      "epsilon: 0.3173112652388396\n",
      "epsilon: 0.3157247089126454\n",
      "epsilon: 0.3141460853680822\n",
      "epsilon: 0.3125753549412418\n",
      "epsilon: 0.31101247816653554\n",
      "epsilon: 0.30945741577570285\n",
      "epsilon: 0.3079101286968243\n",
      "epsilon: 0.3063705780533402\n",
      "epsilon: 0.30483872516307353\n",
      "epsilon: 0.3033145315372582\n",
      "epsilon: 0.3017979588795719\n",
      "epsilon: 0.30028896908517405\n",
      "epsilon: 0.2987875242397482\n",
      "epsilon: 0.29729358661854943\n",
      "epsilon: 0.29580711868545667\n",
      "epsilon: 0.2943280830920294\n",
      "epsilon: 0.29285644267656924\n",
      "epsilon: 0.2913921604631864\n",
      "epsilon: 0.28993519966087045\n",
      "epsilon: 0.2884855236625661\n",
      "epsilon: 0.28704309604425327\n",
      "epsilon: 0.285607880564032\n",
      "epsilon: 0.28417984116121187\n",
      "epsilon: 0.2827589419554058\n",
      "epsilon: 0.28134514724562876\n",
      "epsilon: 0.2799384215094006\n",
      "epsilon: 0.27853872940185365\n",
      "epsilon: 0.27714603575484437\n",
      "epsilon: 0.2757603055760701\n",
      "epsilon: 0.2743815040481898\n",
      "epsilon: 0.2730095965279488\n",
      "epsilon: 0.27164454854530906\n",
      "epsilon: 0.2702863258025825\n",
      "epsilon: 0.2689348941735696\n",
      "epsilon: 0.26759021970270175\n",
      "epsilon: 0.2662522686041882\n",
      "epsilon: 0.2649210072611673\n",
      "epsilon: 0.26359640222486147\n",
      "epsilon: 0.26227842021373715\n",
      "epsilon: 0.2609670281126685\n",
      "epsilon: 0.25966219297210513\n",
      "epsilon: 0.2583638820072446\n",
      "epsilon: 0.2570720625972084\n",
      "epsilon: 0.25578670228422234\n",
      "epsilon: 0.25450776877280124\n",
      "epsilon: 0.2532352299289372\n",
      "epsilon: 0.2519690537792925\n",
      "epsilon: 0.2507092085103961\n",
      "epsilon: 0.2494556624678441\n",
      "epsilon: 0.24820838415550486\n",
      "epsilon: 0.24696734223472733\n",
      "epsilon: 0.2457325055235537\n",
      "epsilon: 0.24450384299593592\n",
      "epsilon: 0.24328132378095624\n",
      "epsilon: 0.24206491716205145\n",
      "epsilon: 0.2408545925762412\n",
      "epsilon: 0.23965031961336\n",
      "epsilon: 0.2384520680152932\n",
      "epsilon: 0.23725980767521673\n",
      "epsilon: 0.23607350863684065\n",
      "epsilon: 0.23489314109365644\n",
      "epsilon: 0.23371867538818816\n",
      "epsilon: 0.23255008201124722\n",
      "epsilon: 0.231387331601191\n",
      "epsilon: 0.23023039494318503\n",
      "epsilon: 0.2290792429684691\n",
      "epsilon: 0.22793384675362674\n",
      "epsilon: 0.22679417751985861\n",
      "epsilon: 0.22566020663225933\n",
      "epsilon: 0.22453190559909803\n",
      "epsilon: 0.22340924607110255\n",
      "epsilon: 0.22229219984074702\n",
      "epsilon: 0.2211807388415433\n",
      "epsilon: 0.22007483514733558\n",
      "epsilon: 0.2189744609715989\n",
      "epsilon: 0.2178795886667409\n",
      "epsilon: 0.2167901907234072\n",
      "epsilon: 0.21570623976979014\n",
      "epsilon: 0.21462770857094118\n",
      "epsilon: 0.21355457002808648\n",
      "epsilon: 0.21248679717794605\n",
      "epsilon: 0.21142436319205632\n",
      "epsilon: 0.21036724137609603\n",
      "epsilon: 0.20931540516921554\n",
      "epsilon: 0.20826882814336947\n",
      "epsilon: 0.20722748400265262\n",
      "epsilon: 0.20619134658263935\n",
      "epsilon: 0.20516038984972615\n",
      "epsilon: 0.2041345879004775\n",
      "epsilon: 0.2031139149609751\n",
      "epsilon: 0.20209834538617025\n",
      "epsilon: 0.2010878536592394\n",
      "epsilon: 0.2000824143909432\n",
      "epsilon: 0.19908200231898848\n",
      "epsilon: 0.19808659230739353\n",
      "epsilon: 0.19709615934585656\n",
      "epsilon: 0.19611067854912728\n",
      "epsilon: 0.19513012515638165\n",
      "epsilon: 0.19415447453059972\n",
      "epsilon: 0.19318370215794672\n",
      "epsilon: 0.192217783647157\n",
      "epsilon: 0.1912566947289212\n",
      "epsilon: 0.1903004112552766\n",
      "epsilon: 0.18934890919900021\n",
      "epsilon: 0.18840216465300522\n",
      "epsilon: 0.18746015382974018\n",
      "epsilon: 0.1865228530605915\n",
      "epsilon: 0.18559023879528855\n",
      "epsilon: 0.1846622876013121\n",
      "epsilon: 0.18373897616330553\n",
      "epsilon: 0.182820281282489\n",
      "epsilon: 0.18190617987607657\n",
      "epsilon: 0.18099664897669618\n",
      "epsilon: 0.1800916657318127\n",
      "epsilon: 0.17919120740315364\n",
      "epsilon: 0.17829525136613786\n",
      "epsilon: 0.17740377510930716\n",
      "epsilon: 0.17651675623376062\n",
      "epsilon: 0.1756341724525918\n",
      "epsilon: 0.17475600159032884\n",
      "epsilon: 0.17388222158237718\n",
      "epsilon: 0.1730128104744653\n",
      "epsilon: 0.17214774642209296\n",
      "epsilon: 0.1712870076899825\n",
      "epsilon: 0.17043057265153258\n",
      "epsilon: 0.16957841978827493\n",
      "epsilon: 0.16873052768933355\n",
      "epsilon: 0.1678868750508869\n",
      "epsilon: 0.16704744067563246\n",
      "epsilon: 0.1662122034722543\n",
      "epsilon: 0.16538114245489302\n",
      "epsilon: 0.16455423674261854\n",
      "epsilon: 0.16373146555890544\n",
      "epsilon: 0.16291280823111093\n",
      "epsilon: 0.16209824418995536\n",
      "epsilon: 0.16128775296900558\n",
      "epsilon: 0.16048131420416054\n",
      "epsilon: 0.15967890763313974\n",
      "epsilon: 0.15888051309497406\n",
      "epsilon: 0.1580861105294992\n",
      "epsilon: 0.1572956799768517\n",
      "epsilon: 0.15650920157696743\n",
      "epsilon: 0.1557266555690826\n",
      "epsilon: 0.1549480222912372\n",
      "epsilon: 0.15417328217978102\n",
      "epsilon: 0.1534024157688821\n",
      "epsilon: 0.1526354036900377\n",
      "epsilon: 0.1518722266715875\n",
      "epsilon: 0.15111286553822956\n",
      "epsilon: 0.15035730121053842\n",
      "epsilon: 0.14960551470448571\n",
      "epsilon: 0.14885748713096328\n",
      "epsilon: 0.14811319969530845\n",
      "epsilon: 0.1473726336968319\n",
      "epsilon: 0.14663577052834775\n",
      "epsilon: 0.14590259167570602\n",
      "epsilon: 0.1451730787173275\n",
      "epsilon: 0.14444721332374086\n",
      "epsilon: 0.14372497725712216\n",
      "epsilon: 0.14300635237083656\n",
      "epsilon: 0.14229132060898236\n",
      "epsilon: 0.14157986400593744\n",
      "epsilon: 0.14087196468590776\n",
      "epsilon: 0.14016760486247823\n",
      "epsilon: 0.13946676683816583\n",
      "epsilon: 0.138769433003975\n",
      "epsilon: 0.13807558583895513\n",
      "epsilon: 0.13738520790976036\n",
      "epsilon: 0.13669828187021155\n",
      "epsilon: 0.13601479046086049\n",
      "epsilon: 0.1353347165085562\n",
      "epsilon: 0.1346580429260134\n",
      "epsilon: 0.13398475271138335\n",
      "Finished! | Return: -980.5113594352986 | average reward: -4.9025567971764925\n",
      "Episode 7\n",
      "epsilon: 0.13331482894782642\n",
      "epsilon: 0.13264825480308728\n",
      "epsilon: 0.13198501352907185\n",
      "epsilon: 0.1313250884614265\n",
      "epsilon: 0.13066846301911936\n",
      "epsilon: 0.13001512070402377\n",
      "epsilon: 0.12936504510050365\n",
      "epsilon: 0.12871821987500112\n",
      "epsilon: 0.12807462877562611\n",
      "epsilon: 0.12743425563174798\n",
      "epsilon: 0.12679708435358925\n",
      "epsilon: 0.1261630989318213\n",
      "epsilon: 0.1255322834371622\n",
      "epsilon: 0.12490462201997637\n",
      "epsilon: 0.1242800989098765\n",
      "epsilon: 0.12365869841532712\n",
      "epsilon: 0.12304040492325048\n",
      "epsilon: 0.12242520289863423\n",
      "epsilon: 0.12181307688414106\n",
      "epsilon: 0.12120401149972035\n",
      "epsilon: 0.12059799144222175\n",
      "epsilon: 0.11999500148501063\n",
      "epsilon: 0.11939502647758558\n",
      "epsilon: 0.11879805134519765\n",
      "epsilon: 0.11820406108847166\n",
      "epsilon: 0.1176130407830293\n",
      "epsilon: 0.11702497557911415\n",
      "epsilon: 0.11643985070121858\n",
      "epsilon: 0.11585765144771248\n",
      "epsilon: 0.11527836319047392\n",
      "epsilon: 0.11470197137452155\n",
      "epsilon: 0.11412846151764894\n",
      "epsilon: 0.1135578192100607\n",
      "epsilon: 0.11299003011401039\n",
      "epsilon: 0.11242507996344034\n",
      "epsilon: 0.11186295456362313\n",
      "epsilon: 0.11130363979080501\n",
      "epsilon: 0.11074712159185099\n",
      "epsilon: 0.11019338598389174\n",
      "epsilon: 0.10964241905397228\n",
      "epsilon: 0.10909420695870241\n",
      "epsilon: 0.1085487359239089\n",
      "epsilon: 0.10800599224428936\n",
      "epsilon: 0.10746596228306791\n",
      "epsilon: 0.10692863247165257\n",
      "epsilon: 0.1063939893092943\n",
      "epsilon: 0.10586201936274783\n",
      "epsilon: 0.10533270926593409\n",
      "epsilon: 0.10480604571960442\n",
      "epsilon: 0.1042820154910064\n",
      "epsilon: 0.10376060541355137\n",
      "epsilon: 0.1032418023864836\n",
      "epsilon: 0.10272559337455119\n",
      "epsilon: 0.10221196540767843\n",
      "epsilon: 0.10170090558064004\n",
      "epsilon: 0.10119240105273684\n",
      "epsilon: 0.10068643904747315\n",
      "epsilon: 0.10018300685223579\n",
      "epsilon: 0.0996820918179746\n",
      "Finished! | Return: -1246.6361171938136 | average reward: -6.233180585969068\n",
      "Episode 8\n",
      "Finished! | Return: -1179.9033556828244 | average reward: -5.899516778414122\n",
      "Episode 9\n",
      "Finished! | Return: -1241.2613299085463 | average reward: -6.206306649542731\n",
      "Test Rewards: [[-7.937996034365382, -8.224585546847464, -8.669805326347596, -9.185619960914158, -9.67589784874263, -10.067591528352176, -9.601625507254768, -9.076486863055738, -8.641512852652747, -8.2424429701125, -7.895078217159092, -7.665041641141877, -7.457741454596928, -7.368885912580854, -7.37831632446903, -7.437681492864652, -7.58991417659521, -7.838741325383514, -8.16425901063054, -8.576885159035713, -9.160612446063471, -9.599229682763259, -10.043646349442643, -9.68480004018306, -9.144287239003363, -8.724798670806427, -8.41821609840122, -8.218488531378378, -8.140202835225322, -8.125564638692758, -8.202446756424823, -8.413937978070377, -8.586923050097093, -8.748988378767084, -9.013725659604049, -9.29458766739367, -9.690119026265783, -9.952344169156257, -9.603903573267358, -9.250165991467494, -8.874594842558844, -8.526721224307881, -8.234359896499473, -8.03591085180466, -7.976885886904475, -8.008300513242053, -8.194578013425547, -8.525851712029564, -8.931909408402264, -9.521256371058731, -9.9371530963531, -9.780782868708634, -9.255572732670549, -8.771189142062093, -8.314893372764626, -7.915841302639387, -7.674461915081861, -7.482566656741637, -7.383586637100058, -7.355127907602478, -7.502292590143947, -7.859164126321983, -8.43172938297007, -8.85672664954839, -9.36887059227499, -9.758225737042439, -9.9490639238511, -9.460054298025536, -9.051184615921432, -8.66234771432996, -8.288750032380717, -7.930296030222529, -7.698549522725142, -7.493754440075191, -7.385922533189889, -7.434456558540467, -7.643461096925418, -8.004693538516536, -8.507972025504191, -9.021420144547138, -9.435998623247507, -10.00441486567164, -9.78168428205647, -9.206601085269277, -8.713125228461413, -8.285618919451332, -7.897646067354354, -7.6185949128563015, -7.4743972071684475, -7.406555944747631, -7.368891216863247, -7.398243249211496, -7.617359653653624, -7.858780551013783, -8.31998655438964, -8.917927930556134, -9.441156108498857, -10.059930697653297, -9.805480265179252, -9.213848874182222, -8.59218091655239, -7.95283904319667, -7.306999703713005, -6.770927158931871, -6.382847626829574, -6.094938016450478, -5.905396399838355, -5.83556440189958, -5.93319211897986, -6.236629706567205, -6.722865593267434, -7.444779893221204, -8.066516578058698, -8.965144565753457, -9.799896474217292, -10.52027981203084, -9.773492650373804, -8.942196890206503, -8.006132684100221, -7.268748416611625, -6.721060483780079, -6.253047807878469, -5.863025700299152, -5.66263549400196, -5.622021590175583, -5.785858108114298, -5.993457297071524, -6.388465772997473, -6.976761946253234, -7.528412213693595, -8.266371780048285, -9.153343753162336, -10.254611049876527, -10.374739466544675, -9.337734009186475, -8.54195450636472, -7.748945136956831, -6.876748337809406, -6.204507181979186, -5.682413105972812, -5.332880980652475, -5.236459449268371, -5.27397079802487, -5.446240129768718, -5.739933562072026, -6.077898957500097, -6.550983520659009, -7.393467342511223, -8.105984326009501, -8.951719815113343, -9.791910275954862, -10.645106056933429, -9.725042721824616, -8.913591799074592, -8.082341426290226, -7.25424281871737, -6.3571416913649585, -5.711136059525007, -5.308932928777774, -4.990799903640304, -4.832234063182366, -4.949667355067978, -5.160234781909799, -5.743783834993793, -6.672421867960075, -7.490236138324731, -8.659831813743557, -9.907554078992469, -10.959909425717395, -10.168655648318788, -9.107282005096309, -8.217670808864606, -7.30470081004048, -6.31335717402954, -5.565806144002569, -4.97281687716778, -4.511082930775327, -4.256959079482475, -4.134955680684538, -4.201383312624471, -4.532681460753343, -5.096688920935364, -5.783516907014041, -6.678024414753829, -7.846076078641055, -8.891594147879722, -9.92924374220423, -10.934294453656968, -10.187486703473407, -9.077126667508173, -7.947416689729391, -7.170457834689543, -6.304722268298599, -5.73569590549652, -5.282302829670547, -5.130829821876536, -5.165216846944131, -5.389431139727736, -5.688864878659795, -6.3585835854227675], [-0.3810551305205131, -0.3110743457731644, -0.28228665982549817, -0.3443179610330687, -0.42854351657884476, -0.6580985777239861, -0.9965010141029793, -1.426609443737721, -1.9263169828012208, -2.7448466921500914, -4.136928652532686, -5.722478464266661, -7.304401441079378, -9.935582950888696, -12.875169976944266, -15.283846823038147, -14.139359757637342, -11.433708495355315, -9.314504955994778, -7.315485772877828, -5.435294691061164, -3.8819581582863045, -2.9669011872097326, -2.2662828220640177, -1.8037255300282167, -1.3791185749433053, -0.9808525625092516, -0.8833076259912735, -0.6961864369962888, -0.612904502027068, -0.6478142444997272, -0.6616470466515794, -0.7655087805772272, -0.9201036550282627, -1.2567754074519888, -1.7984891869509378, -2.3370950347453743, -3.320368378751604, -4.756649884263806, -6.8493875957506365, -8.686025310820366, -11.140935138640051, -13.833757923318002, -15.426447346860112, -12.749039766433851, -10.254057914425212, -7.9890611850011615, -5.889754553202982, -4.240415146030792, -3.0470278284472188, -2.0596955975352356, -1.4986385552965313, -1.1428396956703384, -0.9529815368854585, -0.9547585435688973, -1.0573344196311898, -1.3201839908786803, -1.7423643372754243, -2.2878012705205615, -3.098610421943362, -3.9848193701588417, -5.359588985313774, -7.391327335616646, -9.394017530303211, -11.341851107183688, -13.524762561621962, -12.683783796888893, -10.614131888173487, -8.731051975543403, -6.762189183606694, -5.286658732782625, -4.096242783833889, -3.251356718777662, -2.564509631805813, -1.983213812482001, -1.527849032490976, -1.2576841386535884, -1.1336443894034793, -1.1246079248389007, -1.2014173108020567, -1.3402586614507825, -1.720568517436408, -2.3590560986768905, -3.2175601406023686, -4.514314391386338, -5.883525396008349, -7.611872603841787, -9.548272631309416, -12.00171593264115, -14.215899517030305, -12.652219418674255, -10.409481101568742, -8.656089649722606, -6.6880129906464765, -5.135864289901713, -3.780744255047046, -2.7214769621839654, -2.027608298844738, -1.5650126955912504, -1.0951863915212188, -0.8196104452148659, -0.7241261485282457, -0.7266004433293691, -0.8468592360037426, -1.1278895069191723, -1.491545479107485, -2.061023558817567, -2.921682328402369, -4.198763004161783, -5.414538386502625, -7.567568535447014, -10.052267183554289, -12.69315537170851, -15.188301140926052, -13.024051963473752, -10.922131355941296, -8.640482739499978, -6.889158366415312, -5.103938565835711, -3.8771553835827515, -2.633687264197385, -1.8171542128752964, -1.3988880184569843, -1.000694494828282, -0.6800312124894136, -0.5446758860378976, -0.4654002796893331, -0.5209515893350108, -0.6718523211553608, -0.9505337590948256, -1.3926702891182372, -1.8298380125074976, -2.606545840557702, -3.5603343206339506, -5.176046214754366, -6.934821447641992, -9.00609841347637, -11.128353439521783, -13.979077455264902, -13.874088776522044, -12.051930178153565, -9.762122294901983, -7.961985303125748, -5.998293472809784, -4.206960727573394, -3.171728773792222, -2.3580532664852094, -1.6564167883422878, -1.1103469537774446, -0.7527297396465418, -0.5068927393706467, -0.433668771439561, -0.4203149278308704, -0.4725608363140947, -0.6170911507864171, -0.8205238668762215, -1.2689356257281021, -1.760390011378199, -2.697791324949095, -3.701685618249134, -5.156866081770337, -7.04011071855351, -8.85897528525418, -11.221589720972368, -14.096088910728254, -14.483768741400889, -12.04074799794018, -9.474588675734488, -7.557959225981038, -5.765511852668783, -4.301433757723887, -2.975125105785523, -2.242450365094329, -1.507810751824167, -1.0227982105718025, -0.7696036587163414, -0.7034495372423721, -0.6886872372133906, -0.7494134830454753, -0.9820447730553411, -1.4705760834716946, -2.017519868814441, -2.6045430764821744, -3.4898220935730837, -4.954026037926426, -6.727177971730001, -9.021308362340829, -11.773023715303843, -14.577098259191313, -14.322773249982651, -11.757668891068967, -9.23784506686825, -7.093127487101884, -5.643494524522826, -4.107035081071832, -3.083456362494028, -2.3059294188875077, -1.5776130178065484, -1.0108846711992043, -0.7243876491765684], [-4.325322199899205, -4.324039870409873, -4.598952124190588, -5.200445582449957, -5.902919697806676, -7.025205943938451, -8.432741289001061, -9.656218431324026, -11.328889531006507, -11.017033878342493, -9.49173238063298, -8.06998225272738, -7.027581388899944, -5.98098493150742, -5.125433290661349, -4.480919366821548, -4.1232231660252765, -4.082440994823608, -4.36211838221147, -5.0256655141601785, -5.850471897636281, -6.840847604876566, -8.134352797346498, -9.296536572567765, -10.38567473048819, -11.038933118810402, -9.900007675166504, -8.808400189582443, -7.753926931581603, -6.7347839701514784, -5.798542162733983, -5.06056201558152, -4.634903186938203, -4.387161145132015, -4.332099182466171, -4.548969096392815, -4.889441411919788, -5.493340155730575, -6.307937183808656, -7.127175310535185, -8.094149675833483, -8.983311004010874, -9.883720967171406, -10.86205593834371, -9.937442784054534, -8.989808070957384, -8.062887367788836, -6.957908334550826, -6.090322290456893, -5.488771030891251, -5.135757175987001, -4.937814085812587, -5.069732861878724, -5.335263423988039, -5.674926705652638, -6.2620273136858975, -6.869670261898155, -7.6398030550254585, -8.324513528876246, -9.141210411315402, -9.88784091988281, -10.46169822096024, -9.509051619252507, -8.663595986292439, -7.944929402564384, -7.334312282513028, -6.9072279359404, -6.614053976201335, -6.4843364943001145, -6.473229070561468, -6.637893204772705, -7.070771643249764, -7.580491574990199, -8.32002771557121, -9.200082729055131, -10.133579123718418, -10.301051241601154, -9.338315610853371, -8.518697142594428, -7.735125569342363, -6.994768641535674, -6.47572016831778, -6.014439690883548, -5.636963250828285, -5.369277580044741, -5.255398443352818, -5.280397998332442, -5.4199340628297366, -5.814717225163545, -6.283346343803611, -7.062291886090383, -7.835480533479988, -8.947344220022924, -10.24821733925979, -10.858833006291245, -9.738757569584829, -8.613298825004573, -7.644861708676713, -6.839266285030786, -6.1725035306855265, -5.603941767492553, -5.2343963744339765, -5.001875037380733, -4.994875617367777, -5.278194669591147, -5.890921298476008, -6.775355535977511, -7.983755914583389, -9.252680106619149, -10.763487600942396, -11.014039610939562, -9.738126178066999, -8.441954242015575, -7.268873819947529, -6.337162241702999, -5.722043056257519, -5.269763674599614, -4.985794309208402, -4.9150520749579325, -4.975109882599174, -5.211888661951031, -5.7960797771152475, -6.543947439439282, -7.26985836761898, -8.11223413506651, -9.07524651246685, -10.032815242813287, -10.62032609077584, -9.617394258565751, -8.8460991414291, -8.024211520048215, -7.2091346001690235, -6.5768917345394335, -6.07293141025221, -5.843145830030039, -5.8194331062121005, -6.016401735775478, -6.371774830726188, -6.79910436161415, -7.299359465477805, -8.080028207782028, -8.87787015926414, -9.668739051260275, -10.5165848398574, -9.795159994661844, -8.98535443268687, -8.170185690137375, -7.576788581274292, -7.009118188980887, -6.541413443160437, -6.223808864696331, -6.141096129768236, -6.209016827495188, -6.426084214196046, -6.827434688438353, -7.434561151536217, -8.231863018560615, -9.22238495555315, -10.080912551979006, -10.358951156485574, -9.494151085494533, -8.632820832666786, -7.765498282807761, -7.038518181478008, -6.338463557536897, -5.850424833255543, -5.48496903146418, -5.344768450103358, -5.397459565484294, -5.686228106050404, -6.262237177482784, -6.9731020284626455, -7.912822009258914, -8.887029992416691, -9.858860373503079, -10.75731594257853, -9.963099287070724, -8.916494167257612, -8.053637739702411, -7.258048280082067, -6.54261057012894, -5.886368984940944, -5.2933875016526315, -5.005283789841943, -4.8885753127866165, -5.004722119709654, -5.4292224879360536, -6.071635842255171, -6.789918991545379, -7.8749324650520105, -8.916055122817827, -10.30408997332235, -11.039009124124815, -9.833716435530368, -8.758651010133935, -7.67904322600711, -6.7502608960060835, -6.002737574676652, -5.462375644555039, -5.2385753015908305], [-2.0276552759731286, -2.3837974556240926, -2.8936299767393323, -3.5772993889103972, -4.733485383891769, -5.855036918282588, -7.665928107732472, -9.165954698323711, -11.184193165324823, -13.520794993728584, -11.43565928609555, -9.618761159696446, -7.8777361972122355, -6.196416675133337, -4.9570350944770185, -4.100165602756743, -3.319653120718012, -2.7961755070743672, -2.613457672272155, -2.701410730444033, -3.02334775112376, -3.5540611865050433, -4.157722736987669, -5.050677169456444, -6.316638125946418, -7.522681619344624, -9.048135303275203, -10.823653613044055, -12.275091860967608, -10.784333302355178, -9.225718343231396, -7.711405240599758, -6.4326777384749025, -5.467492718224287, -4.637107555693527, -3.9684501753737766, -3.3450047105056058, -3.0853045709409077, -3.1219916975862723, -3.289353161971558, -3.715837192002577, -4.218165204178379, -4.84978309011036, -5.71790157269417, -6.790137765062056, -8.192692965228776, -9.430489434659203, -11.124562322410185, -11.31179907787063, -9.782496287594691, -8.631264144438974, -7.393753676427582, -6.34580009950325, -5.285689911366907, -4.518790712607871, -4.088015062246905, -3.8252462881241556, -3.7734477338704253, -4.003085035210776, -4.357405835655688, -5.012528550130097, -5.990648223385955, -7.2269763117971175, -8.87501709772695, -10.29378506714165, -12.190525899976022, -10.955275437273396, -9.50733983356729, -7.909963233411978, -6.711670764381211, -5.577152712086995, -4.38717980897109, -3.539504799576737, -3.053213646649994, -2.7866160241010642, -2.832962103179059, -3.0997083435161974, -3.7516979045849763, -4.415831005081294, -5.209426435636733, -6.465833648266001, -8.029304450187148, -9.577346629297244, -10.922818919982145, -12.049017840688764, -10.59045733512243, -8.992942533369856, -7.527130830529422, -6.3192633912231635, -5.187035798469962, -4.1978455180071395, -3.3423870149987165, -2.835536221960219, -2.478796328528634, -2.2498669007182817, -2.2275952018099714, -2.518548379619026, -2.906561994824184, -3.5748221920108185, -4.489729406653075, -5.857743500992597, -7.277392460418761, -8.80590168748133, -10.533261953186202, -11.987608029445305, -11.624389155355136, -9.99190524918834, -8.253716813531204, -6.678924277234225, -5.453665072814248, -4.586945701582966, -3.872925772412021, -3.3101026023415763, -3.051366773443354, -3.0497752943240988, -3.315766409251485, -3.925953261063688, -4.849530749618152, -5.773646726327166, -7.222571716387362, -8.744509121368539, -10.550349775395862, -12.186426474502154, -10.957669108539859, -9.433957263534879, -8.194628010754824, -6.774150756283476, -5.51541465131463, -4.670211290418937, -4.087763374999052, -3.6660674934027178, -3.3973841964982365, -3.3655421999044774, -3.5588120563855994, -3.9930128554627875, -4.7996773173047, -5.587148231162024, -6.773927049125424, -8.37292624784925, -9.640021292962384, -11.166737265222022, -11.53861799672061, -9.862550774447463, -8.525349184603737, -7.069081813949153, -6.07137610061704, -5.13075246555907, -4.322295616878092, -3.8185463474731316, -3.569669353777731, -3.528046322978412, -3.739105666532154, -4.23342822432037, -5.000440679510907, -5.8420408755476565, -6.802411783266209, -8.229269463311601, -9.641335847753462, -10.946170144234888, -11.215957589243683, -9.775722256592303, -8.602616715708653, -7.377182928512696, -6.145004576875066, -5.196564752784394, -4.541348231322465, -4.10887182136339, -4.0232337010577295, -4.094900328507458, -4.372756737924779, -4.9943452531781505, -5.6030548412866725, -6.67551108020601, -7.600933245736872, -8.886453461392916, -10.062136561067087, -11.557759462876161, -10.368636066993018, -9.129321540564867, -7.743831192123572, -6.659626241550143, -5.680638695952119, -5.005404830898742, -4.373956387113011, -4.069057899341058, -4.011807307184164, -4.28636779055849, -4.892248182282147, -5.802900448090703, -6.970893807520293, -8.294435697034338, -9.709123569323753, -11.015911642840623, -10.928035142802358, -9.63279249226037, -8.572824274364464, -7.367447356011432, -6.308193041206044, -5.398624049947083, -4.724604234594749], [-1.8283747201090363, -1.9441969439344653, -2.1840377651940304, -2.836826307088868, -3.6375131648663053, -4.897854155882718, -6.369150502611117, -7.921531811469751, -9.522792530186898, -11.214178963258291, -12.947389327063346, -11.48749565179987, -9.80187824105069, -8.245941130365681, -6.549000135389065, -4.985514731030362, -3.7530155320564766, -2.994846053627699, -2.377572527375465, -2.010814483081583, -1.9929138143366436, -2.214161242735071, -2.5259597261406395, -3.0906272736152243, -3.9196373847580945, -5.145572617890163, -6.920022704645613, -8.357880347702936, -10.439553549567213, -12.313324584463151, -12.439672301305, -10.85081490958908, -9.100945859744446, -7.349424745017725, -5.934999413167787, -4.689611804044072, -3.6463713798750303, -2.665251509198706, -2.0466992369919734, -1.6055627957886165, -1.2991912539198287, -1.1156763566184948, -1.0738304876739495, -1.2602761898263772, -1.553384174926238, -2.1213064683203178, -2.968135293912601, -3.8118455044047916, -4.848560110241867, -6.6702678794900905, -9.025405165442349, -10.905176520145453, -12.759002611939763, -13.298089290151738, -11.45363982416592, -9.28662694692559, -7.591407986234345, -5.773100788977861, -4.5391905838287085, -3.3723201938163805, -2.436369416660879, -1.8159752320985834, -1.3250137004020948, -1.0303987995770556, -0.9316976753686235, -1.0211461919100155, -1.2892053877055785, -1.8764749658757136, -2.4499143062145325, -3.4440430655214573, -4.912203300584005, -6.572252619262025, -8.714883691425738, -10.70576993269031, -12.643422031661926, -13.721533810377363, -12.0110354487827, -9.75955660868222, -7.654504723456895, -5.886321051286862, -4.429412758533217, -3.2321018123151477, -2.382237526136535, -1.9175839599557354, -1.6179672819873037, -1.412568554084311, -1.301730815792956, -1.3430382317469192, -1.5266608599808793, -1.8291380946542843, -2.419766712767085, -3.439750393257038, -4.6080635789425495, -6.358076209519857, -8.47745409381376, -10.695924760947745, -13.067921549332436, -13.75944905920322, -11.843519598187843, -9.92146610587507, -7.770815238251302, -5.792096086086716, -4.161956057379237, -3.0811266109515385, -2.4161804438532317, -1.8439613750045558, -1.3959441529342769, -1.180750547288232, -1.0363448031611748, -1.0672903435678325, -1.3360271006394482, -1.8049012354039649, -2.549763794388786, -3.4245503213585646, -4.827415684953084, -6.674575673783808, -8.439040078235369, -10.764695323482593, -13.402089120362374, -14.211457863241087, -12.24268821229264, -9.763479070335652, -7.695842028998063, -5.720543449369551, -4.1803094898664925, -3.053325425947786, -2.196949104439081, -1.5883957722864237, -1.2357061688283617, -0.9909189439948349, -0.8016594182362866, -0.7747021064191055, -0.820517731584892, -1.0017904883279534, -1.4042984188859222, -1.9721730513924678, -2.7988449159833437, -3.630639740807989, -4.961055542096109, -6.841418265837972, -8.53160574843952, -10.897362529516592, -13.09204794324236, -13.832762968743529, -11.556924070427803, -9.36136946511216, -7.239298528429175, -5.87332661275501, -4.59786007334715, -3.2509965111091224, -2.402578320248823, -1.7783207667411096, -1.452287041799685, -1.3707392476785243, -1.4816270761814434, -1.790632238709477, -2.443075156204964, -3.1352462130404635, -4.341359932014829, -5.59241123283136, -7.358382197823225, -9.706132404297911, -12.056814118169655, -14.102552087013516, -12.202147222618327, -10.073244190675094, -8.291856257737265, -6.759577302423717, -5.114875605744376, -3.773554845178061, -2.7160196845809437, -2.1247458712569105, -1.764940160169233, -1.533190428324167, -1.459169858775973, -1.5213056892707812, -1.7013662706091224, -2.01962791469691, -2.5876887645369804, -3.3517431633407133, -4.218040228301149, -5.346213746568327, -7.196532585211935, -9.051257215971349, -10.76279380816266, -13.256205100709687, -12.252657731710183, -10.184720927071972, -8.338785832624161, -6.665953803364908, -5.312582222500964, -4.104338940987829, -3.2866818559763065, -2.796913691492458, -2.4881344092300384, -2.356125740794459, -2.4328387418426263, -2.829494605832686, -3.510815757943302, -4.621934506134511], [-7.21857496690934, -7.249412688514928, -7.354828120353363, -7.5137008516810635, -7.874239405191423, -8.375918615617403, -8.859737707830284, -9.613684198617213, -10.127143873382945, -9.730807140193528, -9.134845534357224, -8.572582773110812, -8.125269605652184, -7.74820053664311, -7.458253770414723, -7.211190378897075, -7.070018920102322, -7.094125594409906, -7.257387205154667, -7.587083995406575, -8.073339334908065, -8.627231111582352, -9.1974602049324, -9.662365376290316, -10.128220715909366, -9.546238019308324, -9.081283646117951, -8.652211720486624, -8.31963775136857, -8.03001016385151, -7.8372782228260975, -7.640419024240968, -7.4913541313118905, -7.376887243622024, -7.351014757873768, -7.450379226911132, -7.6312305388859345, -7.824191536010095, -8.129263893642444, -8.634825154862229, -9.095137873820972, -9.76789669055301, -10.096215430346556, -9.439096213936102, -8.908333876275274, -8.472565124683127, -8.058870077145396, -7.818346014488798, -7.749484418721525, -7.696612296272251, -7.691312496312029, -7.806928856008697, -8.048621023188616, -8.375370357114086, -8.642946923223313, -8.873391333981115, -9.125193793191434, -9.389017488066644, -9.622081888232211, -9.852688532195263, -9.760194870048952, -9.527377950749063, -9.28011583959629, -9.012974584973524, -8.732161601984549, -8.427022344496498, -8.150977222977643, -7.963848840886508, -7.7999492937046915, -7.6871398246750955, -7.699531446902506, -7.7245219950458255, -7.780721764273231, -7.850772365127569, -8.078726993186464, -8.276782433353224, -8.574201787882034, -8.91187686750252, -9.247895620269388, -9.51673747021177, -9.729874262969643, -9.854751298457193, -9.516270075433544, -9.185052260927078, -8.886126163754842, -8.592371709367667, -8.339304354484513, -8.09735938979374, -7.979420872060504, -7.903641516317346, -7.841178112599039, -7.9381113512231805, -8.223573612969314, -8.473912809818602, -8.876873636721312, -9.45686859683575, -9.964313066816034, -9.809610681270064, -9.211165814069227, -8.737958294908237, -8.261248652808346, -7.910244387915329, -7.5753030570477735, -7.3019925283546145, -7.078066219001676, -6.9002572695263025, -6.836438408020918, -6.987214894613688, -7.299928993491843, -7.693098798059226, -8.249342540660184, -8.737962222652405, -9.243160127943002, -10.010114905184654, -9.937800923795884, -9.316869887767083, -8.656612217264222, -8.164847716387282, -7.6962651465009655, -7.388773401963351, -7.272319919338396, -7.311757978079431, -7.41880517642255, -7.623814323356124, -7.923725647012393, -8.34401773538899, -8.797790496363717, -9.368013050701245, -9.830327971387087, -9.921316225450756, -9.486476906038726, -9.095043986736275, -8.72216071212891, -8.361422585909013, -8.057375952829869, -7.807801740792903, -7.585757991410688, -7.483499132924576, -7.452977169194885, -7.541031988891204, -7.782294899804719, -8.208647573159583, -8.649549550217639, -9.238649021529401, -9.962501041824504, -9.962737422006386, -9.307527049494514, -8.791133735404163, -8.3938817313536, -8.139418402035943, -7.971532061020024, -7.809978531729969, -7.7524426922987475, -7.755340720975735, -7.775945094546461, -7.900824507153002, -8.000879042914539, -8.293465487660827, -8.65104279594011, -9.159382385391401, -9.640580677280942, -10.08570709672943, -9.59548419506046, -9.076867996253178, -8.614432918150511, -8.119042383619748, -7.727819579094554, -7.400140801621972, -7.235071644714416, -7.178926543419905, -7.141935361079083, -7.1990082439853476, -7.281240144741307, -7.5975806827197205, -8.137239024072683, -8.600635632502446, -9.34624615722966, -9.853416209075704, -10.011359884868822, -9.372850815238001, -8.87193878778581, -8.404094425944118, -7.988514617303727, -7.602190676350195, -7.370738532885403, -7.215245753846108, -7.108560594595495, -7.031472443930289, -7.091439110477283, -7.2035119094481646, -7.440715214134524, -7.830558453005931, -8.38642053865903, -9.132752689168212, -9.943639931633792, -10.106632356055732, -9.484088325576831, -8.872338861269409, -8.236037647718248, -7.7557023260950215], [-0.9586416902569572, -0.9790149200324404, -1.1640002540300103, -1.4915564842524758, -1.9389878869584922, -2.6499082298763588, -3.552329126890087, -5.041753448019096, -6.457380592844222, -8.225677060505861, -10.570999858017359, -12.634341559658232, -13.484990182550135, -11.56399481285782, -9.628171512949676, -7.667561360663732, -6.165419781590526, -4.75143776871931, -3.4443155973054975, -2.676328755831951, -1.9676029247202544, -1.5503704872718254, -1.340801152996851, -1.2552296126433582, -1.3756613868761436, -1.6515308142064276, -2.2255601117453114, -2.8676077958985227, -3.894098765212931, -5.5158777208174765, -7.168349957417332, -9.29884231850486, -11.42596136091659, -13.551278924637339, -12.635895821636668, -10.933678034953623, -9.003876794112836, -6.933444039101419, -5.389283890498552, -4.177187457150923, -2.9368285216690735, -2.1136096741967267, -1.665230567096524, -1.4157977292054822, -1.2803503438573607, -1.375190489045578, -1.7225086601647441, -2.357768966472742, -3.163128901359197, -4.450533251597525, -6.281023761934247, -8.121160577761177, -10.677898263736932, -12.649595415416782, -13.956276036309172, -11.856713691364014, -9.86166116322387, -8.122465974158398, -6.488206006954859, -4.790355823958479, -3.5269734578540075, -2.56412364462837, -1.7921776161719838, -1.3896599546666764, -1.0968509377908866, -0.986724469516978, -0.9470165444232715, -1.0433233699154298, -1.3642363487695952, -1.7874741822178415, -2.5118523500129615, -3.4874288987901383, -4.9277522073850655, -6.692786186461496, -8.364458339186639, -10.99758764014769, -13.763337677635272, -13.99962933319431, -12.04704608972696, -9.976331907077341, -8.157156710190437, -6.392140410138092, -4.492545098890366, -3.272027288964261, -2.221022217535816, -1.4212738662681004, -1.0387022271205089, -0.6765242068126168, -0.5285348262700819, -0.4205530536222873, -0.3028443078758238, -0.2691500016802628, -0.3127507295764855, -0.36952428370718926, -0.5664972694366036, -0.8815516524186343, -1.3843756917123287, -2.20503538798167, -3.1609673024072955, -4.167189299664214, -6.072250151330467, -7.920623503217813, -9.970405991116213, -12.884790665391547, -15.99571948636954, -13.812845614533558, -11.517560107728047, -8.903415702626301, -6.88079345261696, -5.175873872300718, -3.765881351657352, -2.9062363649411105, -1.9039809927646498, -1.288852671343875, -0.8472477807741294, -0.6176863875774287, -0.53191868025874, -0.30766201464817944, -0.24998826504826693, -0.2662349517338737, -0.2610104232949559, -0.32028362687278006, -0.3826132018047007, -0.513446439521342, -0.6014884866330625, -0.9746259016552827, -1.3230710383949358, -2.0481780806565753, -2.7162093277970882, -3.830764740458782, -5.28203970351065, -7.309891469579411, -9.316529370706048, -12.060112445003034, -14.566563707399556, -14.991037762173635, -12.814000497174273, -10.291764124676805, -8.245132426548002, -5.916104217854869, -4.5120755977654365, -3.293504415554078, -2.456453442939399, -1.7103420041861435, -1.1940907424894216, -0.8125168149736379, -0.6539659480163497, -0.653272343535734, -0.7353611593593551, -0.8489388731951971, -1.0891058771374966, -1.5885032767640763, -2.2405133112705706, -2.8171008526119103, -3.995655638285381, -5.222885891237899, -6.968913125609036, -9.486532892717179, -11.649116007767956, -14.732916233848199, -15.07153261772142, -12.95114792567431, -10.892022666798217, -8.241679180794577, -6.460633522980114, -4.605374626408918, -3.0824912662551034, -2.0478993941147863, -1.3921260964186035, -0.9393997081398403, -0.6984173451637151, -0.5918182951739479, -0.3919080744387542, -0.2587497967617691, -0.16866868832824758, -0.08955396145519047, -0.09841358618779013, -0.07638367217460659, -0.10661424212639962, -0.17986559501459742, -0.26009301180946326, -0.463910160054516, -0.5860666176496971, -0.9369750070717915, -1.4167290626122022, -1.9394460897315207, -2.6478839658233095, -3.5334469503209833, -4.8500274483279515, -6.597487968082501, -9.025663332004013, -11.323714604938313, -13.60279014973525, -15.182788313439145, -13.2502772115431, -10.773202603949457, -8.750514784736598, -6.768729828703313, -4.710520250537614, -3.297401300679603], [-5.274140288693984, -5.534464880718971, -5.99963003776869, -6.8354728231319895, -7.5161351767194695, -8.50455735995571, -9.406782198831362, -10.493488975263222, -10.215586629862425, -9.388628420196664, -8.378925092320417, -7.580922819559963, -6.778300857579819, -6.1464788003310735, -5.544755093843576, -5.2106220625191275, -5.1049637946008435, -5.203573373996619, -5.472111713606922, -5.948261857021485, -6.5922327149041395, -7.5222011663913975, -8.777581754735007, -9.692737309658876, -10.88209868388346, -10.275963926258395, -9.154774610268568, -8.057696885864058, -7.179224737046683, -6.1798656293321335, -5.468985126888527, -4.949033405761142, -4.60833349666495, -4.378159188715031, -4.269701331976015, -4.351865467256808, -4.552576200559114, -5.071804609602818, -5.885774339192888, -6.9888743370013025, -8.23918719817188, -9.830277773548715, -11.076497896947947, -10.771330236034238, -9.701862459932322, -8.354781566334113, -7.113070738882627, -6.1381325738602905, -5.409211696972416, -4.792361269586991, -4.431597622081362, -4.229051934676179, -4.312340502496781, -4.684722036715078, -5.186987847521366, -5.790129518115093, -6.49838148268965, -7.583402870243827, -8.685581540443414, -9.815619480416656, -11.181603233215984, -10.1918715985996, -9.171408052846159, -8.17317511077456, -7.04311452325441, -6.1604884012631915, -5.520321559895644, -4.898971463782217, -4.603506769417844, -4.492414042246443, -4.507087375966805, -4.757733445560711, -5.281309651624108, -5.9905611247390285, -7.036559683358614, -8.329766846522455, -9.878379687370256, -11.185138832839463, -10.817498002753421, -9.380934378896606, -8.32146502627798, -7.154486220027484, -6.024926231684321, -5.160027707858705, -4.483039405437693, -3.929392664609463, -3.7064243353985167, -3.713718259088515, -3.94884183862412, -4.44806961301589, -5.277581301726786, -6.2400137549128045, -7.704862317144901, -9.454426710311093, -11.209771734461349, -11.673316544449042, -10.413934531611998, -8.816100643357041, -7.445548255926359, -6.333904517693403, -5.269134913430996, -4.350935538206898, -3.7007315673925163, -3.22292825795779, -3.0411380112246027, -2.999964966508444, -3.088234230879307, -3.496077231616856, -4.011378284842914, -4.816175277914694, -5.879138883636709, -7.02844387150956, -8.742889632944266, -10.358181379783025, -12.110258094233208, -11.396135136528061, -9.900086982085858, -8.241175676021847, -6.902499828228977, -5.438771119836425, -4.431050924468888, -3.4270225493753426, -2.830074131202562, -2.510538193739217, -2.3486852184976668, -2.348537559528955, -2.52396365188269, -2.985776379705899, -3.6663438061135194, -4.758060992343426, -5.970557512828815, -7.78918772848824, -9.86394480634349, -11.737675962545552, -12.927195607415891, -11.31307996362519, -9.529291458262659, -7.875561407939947, -6.260736913683281, -4.950870969035638, -3.762323113135066, -2.9735476472517095, -2.319403074374891, -1.775707180820827, -1.4127712863890562, -1.2692731890138604, -1.3026280069032783, -1.5472999600623845, -2.0610736057704018, -2.9528172621275677, -4.131700514146835, -5.548246485474241, -6.996782324544098, -9.156543373666407, -11.770320073269101, -14.147216626736167, -12.917301146367167, -10.684830871541823, -8.63636890753092, -7.0005577466194095, -5.256673504104264, -4.006003701394354, -2.922070536887029, -2.1179533522088345, -1.5682586593032786, -1.3087923264469579, -1.1619793843293968, -1.1733542153305943, -1.2864854588542656, -1.5741082555971062, -1.923059630141871, -2.3956970968280924, -3.2880335056573706, -4.4078360845036535, -5.802292323107335, -7.917730144258527, -10.196820056925546, -12.535230687432547, -14.167539642557568, -11.888121735014073, -9.872396039724235, -7.871485809312985, -5.9818680134797555, -4.48016442521309, -3.5318188252619103, -2.7996096958765415, -2.2129850974005363, -1.7870914507618116, -1.5036439259614254, -1.3830138040435211, -1.4453710770736188, -1.6481139057267136, -1.9889666858154824, -2.5998213146164755, -3.267921317210348, -4.423632063002684, -5.691536378292324, -7.428093740154269, -9.560772006271305, -11.767113477477126], [-3.611456468610041, -3.8320470313546053, -4.255976525667906, -4.842605642241513, -5.6854783896868994, -6.601641479503047, -7.81532549709153, -9.114320034133842, -10.653837548340091, -11.652150181232722, -10.079850694357184, -8.754359750819718, -7.506885625678924, -6.352345413848021, -5.481152528705432, -4.692119046348503, -4.104861186211061, -3.772516258709298, -3.752152323789503, -4.029380949960828, -4.631920597853822, -5.354428039551499, -6.315519613909663, -7.6442048624169505, -9.034060519494217, -10.45598651463036, -11.761933456569334, -10.393917196813371, -9.130128311745693, -7.971313008159472, -6.584191797145072, -5.635337427178676, -4.581082057361853, -3.9205377579166965, -3.481466681754027, -3.278021980771358, -3.290922791027721, -3.5112140829680456, -4.12906497888814, -4.751989935464641, -5.668788319401052, -7.063419549960807, -8.229944675460422, -9.442791602575776, -11.228614760091178, -11.386325608196605, -10.042121420381552, -8.801798731683416, -7.53171982170543, -6.153634139256335, -5.030365320039221, -4.130627890729395, -3.3192859402271093, -2.8363121921252694, -2.5513978295411803, -2.458660668862431, -2.5125565407621977, -2.8554960381851564, -3.524982053137355, -4.360751480750563, -5.388347556575928, -6.807122140328339, -8.705457088194763, -10.506018608884641, -12.279787678084869, -11.829685662602087, -10.02676412270152, -8.300289922013231, -6.7963839868375615, -5.5977617880957835, -4.6158861471743045, -3.8239003046490354, -3.1567183506039416, -2.846316328284041, -2.892138175625846, -3.2967859646792426, -3.9252951242509964, -4.9878832697339215, -6.145227476040091, -7.325135654276635, -8.892177724707352, -10.483403029234456, -12.223505357586276, -11.062458694995755, -9.712899598571921, -8.37221082658702, -6.992528193244804, -5.682425316949267, -4.524041586849089, -3.629150738786295, -2.76615041170296, -2.262663516460126, -1.9064642756219086, -1.7766547904630319, -1.967168154190664, -2.3880359049837634, -3.1588712279388127, -4.19133219854215, -5.619166315197445, -7.425238689478605, -9.38696220870747, -11.9316120547241, -13.887948788232604, -12.154937677993502, -10.222026416200436, -8.369806302854116, -6.5539495821881815, -5.1023886764885695, -3.8359500926548495, -2.944823099485935, -2.1673351255470417, -1.7544957934210186, -1.4436256909861955, -1.2097138419509723, -1.1449404329578228, -1.294706454117771, -1.7315673478955675, -2.278421865522055, -3.2788300015221856, -4.448959965906492, -5.785114934380565, -7.43586257704876, -9.377102069487377, -11.656529954002124, -14.27979602618176, -12.752190489563002, -10.673340902410875, -8.865694471603359, -6.985778490091965, -5.217142342268754, -3.7993638472591638, -2.8606606118367797, -2.000513357897458, -1.4835343749721235, -1.0268056836096835, -0.8050046501645658, -0.6460853316683072, -0.6388665636398018, -0.8039549850827443, -1.1777351262861213, -1.5520774403448, -2.3726818687661764, -3.1559274266647668, -4.190520159823794, -5.7260802758613245, -7.574789653538821, -9.3525437861659, -11.549772405901548, -14.017721744928389, -13.280081301068906, -11.212674181818093, -9.021734485996186, -7.160645919151298, -5.410716351568336, -3.879300769611613, -2.6596824216759694, -1.811741476453565, -1.3484307064583354, -1.072284064962747, -0.9612209893157524, -0.9683911616582436, -1.145957632534885, -1.5869324104598403, -2.051358312000589, -2.718031084249189, -3.783257502704312, -4.891977635026897, -6.2793633968049365, -7.989751345741472, -10.419678962657386, -12.299498026908555, -13.313550591189767, -11.44119417171777, -9.789237942715355, -7.80171911327705, -6.043129424741639, -4.76226821580047, -3.5423878035964824, -2.8234825071914686, -2.2707002723813834, -1.9107835774501518, -1.8337804541259173, -1.9035168528965618, -2.1608826941595902, -2.7912243021489065, -3.752682266195174, -4.897488291355811, -6.470619236606018, -7.893072755755783, -9.483264194520292, -11.329783146961189, -13.207153827122957, -11.47240473496981, -9.82758195221747, -8.133243448966558, -6.3181049848790005, -4.912435555789143, -3.923452400780035, -2.9714300073953543, -2.197127173570242], [-3.71137530948018, -3.6089760938517723, -3.731880511736348, -4.206994435109154, -4.865068831959444, -5.986983392570313, -6.978405734014253, -8.475458709674662, -9.736148163846384, -11.325136174829527, -11.092068385799656, -9.902527344428496, -8.600048986340914, -7.020907654221882, -5.902791696745756, -5.0094336261590104, -4.184993167468521, -3.4608918215599798, -3.073127837319079, -2.9912732355327454, -3.226874338706909, -3.665030052430969, -4.343476297237533, -5.367193341584028, -6.363613445335912, -7.957179884005435, -9.611308231694792, -11.670348513721992, -12.220821977783755, -10.512569737254308, -9.023880510763831, -7.51980332299039, -5.9425786194423695, -4.527592963491864, -3.6053448059505744, -2.9021160886362654, -2.4993395576995168, -2.401695954959449, -2.481227299310293, -2.8257155742992786, -3.5847502296837126, -4.673003628663808, -5.735227462688029, -7.417335159656299, -9.40160420899137, -11.751381124541993, -13.294061094041933, -11.385818457266332, -9.399744694031085, -7.686680571835893, -6.210764061191807, -5.011941002514593, -3.961984320533376, -3.135124804031528, -2.57009241402301, -2.3444759813021694, -2.4146926312318855, -2.7866129711461816, -3.3533312129221504, -4.1324901154402145, -5.319392168814077, -6.729898052739676, -8.665700702594663, -10.557332021763846, -12.253453528207746, -11.79999970992329, -10.008110603937794, -8.63424583152651, -6.977377831892439, -5.815827781319987, -4.6985007749347485, -3.73345968045257, -3.175763631113985, -2.8937309281648353, -2.940363748553775, -3.2725294901043136, -3.857381240661335, -4.692914207885676, -5.7416395108576355, -7.1628698707542355, -8.776607610026957, -10.537657395946137, -12.285462117612417, -11.357304755258909, -9.804104225136793, -8.070358274602079, -6.582986213341501, -5.385143173740862, -4.472931606850619, -3.7370846423722712, -3.136328498850193, -2.884669717120378, -2.9057471253523133, -3.0983687679624534, -3.665879454097934, -4.356761494063588, -5.3517273449179195, -6.826888698307067, -8.307847518504188, -10.035983878060803, -11.957790030314367, -11.900514546918021, -10.102472879575005, -8.384550722735609, -6.9692747124955, -5.602432267595406, -4.654244974822323, -3.8710694868218174, -3.373561751293543, -3.1619315789509708, -3.0814598595440237, -3.1234350544211558, -3.402479241339096, -3.919593040684504, -4.698681289692663, -5.649382797447614, -7.126813769405066, -8.358423460659802, -9.92964904587442, -11.870209447981715, -11.348190837483493, -9.78145542654521, -8.425680417579134, -7.062339628777794, -5.679395698114798, -4.808957178260781, -3.996004522345722, -3.4341433163695037, -3.1685321357476615, -3.088161124751075, -3.322565100835875, -3.7325966463307596, -4.6000085679295815, -5.79501695510295, -7.4468303158902165, -9.07648886292294, -11.193093263191091, -12.823115247855043, -11.139134972423827, -9.71825075610808, -8.069899291324736, -6.504221387940293, -5.289076431237981, -4.177738086014502, -3.1854632650069434, -2.5402188896694002, -2.108457060674862, -1.7417719048895497, -1.693332459911771, -1.8952396132705203, -2.186620476689995, -2.638642623791578, -3.5284538513039134, -4.45878233974099, -5.599383547214229, -7.132100501494374, -8.763002836170303, -10.559894078308487, -12.882396210501057, -12.094584202248903, -10.468552091165531, -8.451553725760316, -6.67442751540784, -5.257377310058261, -4.159755499188678, -3.321174022201179, -2.7014047126414096, -2.349871276482993, -2.3430077566216565, -2.634883110696648, -3.316824649981137, -4.1602859620552675, -5.464369279255656, -7.042359881764166, -9.110153782659124, -11.104031893450182, -13.17530552454787, -11.768772749131205, -9.878872015175949, -8.328527086698791, -6.815801286518453, -5.471735753927012, -4.4226314278798355, -3.4373141688563904, -2.7223973117701266, -2.133502627443127, -1.7723995310260563, -1.5723555514042833, -1.5716996718136842, -1.837589717799204, -2.2248411763869402, -2.83256206671172, -3.8134603665718836, -4.973487808977735, -6.683887803641925, -8.893824782230986, -11.015153682610103, -12.834868734104376, -12.60388840595307, -10.79555659341954]]\n",
      "Average Test Reward: -6.347450174270565\n"
     ]
    }
   ],
   "source": [
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "\n",
    "# Test the best agent by loading the best weights\n",
    "dir_path = 'best_dqn_weights'\n",
    "\n",
    "dqn.load_weights(path=dir_path)\n",
    "test_episodes = 10\n",
    "test_rewards = []\n",
    "for _ in range(test_episodes):\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    test_rewards.append(reward)\n",
    "\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env = gym.make(f'{EnvName}')\n",
    "state = env.reset()\n",
    "ListOfRewards = []\n",
    "Done = False\n",
    "while not Done:\n",
    "    Q = dqn.Main(state.reshape(-1, state.shape[0]))\n",
    "    action = np.argmax(Q)\n",
    "    action = PendulumActionConverter(action)\n",
    "    AStep = np.array([action])\n",
    "    action = PendulumInverseActionConverter(action)\n",
    "    env.render()\n",
    "    SNext, reward, Done, Info = env.step(AStep)\n",
    "    # DQN.UpdateReplayMemory((state, action, reward, SNext, Done))\n",
    "    # DQN.Train(Done, reward)\n",
    "    # ListOfRewards.append(reward)\n",
    "    # all_rewards.append(reward)\n",
    "    # all_sum_rewards.append(np.sum(ListOfRewards))\n",
    "    state = SNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab646d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_dqn_weights\n",
      "Episode 0\n",
      "DID NOT TRAIN..., replay memory = 1\n",
      "DID NOT TRAIN..., replay memory = 2\n",
      "DID NOT TRAIN..., replay memory = 3\n",
      "DID NOT TRAIN..., replay memory = 4\n",
      "DID NOT TRAIN..., replay memory = 5\n",
      "DID NOT TRAIN..., replay memory = 6\n",
      "DID NOT TRAIN..., replay memory = 7\n",
      "DID NOT TRAIN..., replay memory = 8\n",
      "DID NOT TRAIN..., replay memory = 9\n",
      "DID NOT TRAIN..., replay memory = 10\n",
      "DID NOT TRAIN..., replay memory = 11\n",
      "DID NOT TRAIN..., replay memory = 12\n",
      "DID NOT TRAIN..., replay memory = 13\n",
      "DID NOT TRAIN..., replay memory = 14\n",
      "DID NOT TRAIN..., replay memory = 15\n",
      "DID NOT TRAIN..., replay memory = 16\n",
      "DID NOT TRAIN..., replay memory = 17\n",
      "DID NOT TRAIN..., replay memory = 18\n",
      "DID NOT TRAIN..., replay memory = 19\n",
      "DID NOT TRAIN..., replay memory = 20\n",
      "DID NOT TRAIN..., replay memory = 21\n",
      "DID NOT TRAIN..., replay memory = 22\n",
      "DID NOT TRAIN..., replay memory = 23\n",
      "DID NOT TRAIN..., replay memory = 24\n",
      "DID NOT TRAIN..., replay memory = 25\n",
      "DID NOT TRAIN..., replay memory = 26\n",
      "DID NOT TRAIN..., replay memory = 27\n",
      "DID NOT TRAIN..., replay memory = 28\n",
      "DID NOT TRAIN..., replay memory = 29\n",
      "DID NOT TRAIN..., replay memory = 30\n",
      "DID NOT TRAIN..., replay memory = 31\n",
      "DID NOT TRAIN..., replay memory = 32\n",
      "DID NOT TRAIN..., replay memory = 33\n",
      "DID NOT TRAIN..., replay memory = 34\n",
      "DID NOT TRAIN..., replay memory = 35\n",
      "DID NOT TRAIN..., replay memory = 36\n",
      "DID NOT TRAIN..., replay memory = 37\n",
      "DID NOT TRAIN..., replay memory = 38\n",
      "DID NOT TRAIN..., replay memory = 39\n",
      "DID NOT TRAIN..., replay memory = 40\n",
      "DID NOT TRAIN..., replay memory = 41\n",
      "DID NOT TRAIN..., replay memory = 42\n",
      "DID NOT TRAIN..., replay memory = 43\n",
      "DID NOT TRAIN..., replay memory = 44\n",
      "DID NOT TRAIN..., replay memory = 45\n",
      "DID NOT TRAIN..., replay memory = 46\n",
      "DID NOT TRAIN..., replay memory = 47\n",
      "DID NOT TRAIN..., replay memory = 48\n",
      "DID NOT TRAIN..., replay memory = 49\n",
      "DID NOT TRAIN..., replay memory = 50\n",
      "DID NOT TRAIN..., replay memory = 51\n",
      "DID NOT TRAIN..., replay memory = 52\n",
      "DID NOT TRAIN..., replay memory = 53\n",
      "DID NOT TRAIN..., replay memory = 54\n",
      "DID NOT TRAIN..., replay memory = 55\n",
      "DID NOT TRAIN..., replay memory = 56\n",
      "DID NOT TRAIN..., replay memory = 57\n",
      "DID NOT TRAIN..., replay memory = 58\n",
      "DID NOT TRAIN..., replay memory = 59\n",
      "DID NOT TRAIN..., replay memory = 60\n",
      "DID NOT TRAIN..., replay memory = 61\n",
      "DID NOT TRAIN..., replay memory = 62\n",
      "DID NOT TRAIN..., replay memory = 63\n",
      "DID NOT TRAIN..., replay memory = 64\n",
      "DID NOT TRAIN..., replay memory = 65\n",
      "DID NOT TRAIN..., replay memory = 66\n",
      "DID NOT TRAIN..., replay memory = 67\n",
      "DID NOT TRAIN..., replay memory = 68\n",
      "DID NOT TRAIN..., replay memory = 69\n",
      "DID NOT TRAIN..., replay memory = 70\n",
      "DID NOT TRAIN..., replay memory = 71\n",
      "DID NOT TRAIN..., replay memory = 72\n",
      "DID NOT TRAIN..., replay memory = 73\n",
      "DID NOT TRAIN..., replay memory = 74\n",
      "DID NOT TRAIN..., replay memory = 75\n",
      "DID NOT TRAIN..., replay memory = 76\n",
      "DID NOT TRAIN..., replay memory = 77\n",
      "DID NOT TRAIN..., replay memory = 78\n",
      "DID NOT TRAIN..., replay memory = 79\n",
      "DID NOT TRAIN..., replay memory = 80\n",
      "DID NOT TRAIN..., replay memory = 81\n",
      "DID NOT TRAIN..., replay memory = 82\n",
      "DID NOT TRAIN..., replay memory = 83\n",
      "DID NOT TRAIN..., replay memory = 84\n",
      "DID NOT TRAIN..., replay memory = 85\n",
      "DID NOT TRAIN..., replay memory = 86\n",
      "DID NOT TRAIN..., replay memory = 87\n",
      "DID NOT TRAIN..., replay memory = 88\n",
      "DID NOT TRAIN..., replay memory = 89\n",
      "DID NOT TRAIN..., replay memory = 90\n",
      "DID NOT TRAIN..., replay memory = 91\n",
      "DID NOT TRAIN..., replay memory = 92\n",
      "DID NOT TRAIN..., replay memory = 93\n",
      "DID NOT TRAIN..., replay memory = 94\n",
      "DID NOT TRAIN..., replay memory = 95\n",
      "DID NOT TRAIN..., replay memory = 96\n",
      "DID NOT TRAIN..., replay memory = 97\n",
      "DID NOT TRAIN..., replay memory = 98\n",
      "DID NOT TRAIN..., replay memory = 99\n",
      "DID NOT TRAIN..., replay memory = 100\n",
      "DID NOT TRAIN..., replay memory = 101\n",
      "DID NOT TRAIN..., replay memory = 102\n",
      "DID NOT TRAIN..., replay memory = 103\n",
      "DID NOT TRAIN..., replay memory = 104\n",
      "DID NOT TRAIN..., replay memory = 105\n",
      "DID NOT TRAIN..., replay memory = 106\n",
      "DID NOT TRAIN..., replay memory = 107\n",
      "DID NOT TRAIN..., replay memory = 108\n",
      "DID NOT TRAIN..., replay memory = 109\n",
      "DID NOT TRAIN..., replay memory = 110\n",
      "DID NOT TRAIN..., replay memory = 111\n",
      "DID NOT TRAIN..., replay memory = 112\n",
      "DID NOT TRAIN..., replay memory = 113\n",
      "DID NOT TRAIN..., replay memory = 114\n",
      "DID NOT TRAIN..., replay memory = 115\n",
      "DID NOT TRAIN..., replay memory = 116\n",
      "DID NOT TRAIN..., replay memory = 117\n",
      "DID NOT TRAIN..., replay memory = 118\n",
      "DID NOT TRAIN..., replay memory = 119\n",
      "DID NOT TRAIN..., replay memory = 120\n",
      "DID NOT TRAIN..., replay memory = 121\n",
      "DID NOT TRAIN..., replay memory = 122\n",
      "DID NOT TRAIN..., replay memory = 123\n",
      "DID NOT TRAIN..., replay memory = 124\n",
      "DID NOT TRAIN..., replay memory = 125\n",
      "DID NOT TRAIN..., replay memory = 126\n",
      "DID NOT TRAIN..., replay memory = 127\n",
      "DID NOT TRAIN..., replay memory = 128\n",
      "DID NOT TRAIN..., replay memory = 129\n",
      "DID NOT TRAIN..., replay memory = 130\n",
      "DID NOT TRAIN..., replay memory = 131\n",
      "DID NOT TRAIN..., replay memory = 132\n",
      "DID NOT TRAIN..., replay memory = 133\n",
      "DID NOT TRAIN..., replay memory = 134\n",
      "DID NOT TRAIN..., replay memory = 135\n",
      "DID NOT TRAIN..., replay memory = 136\n",
      "DID NOT TRAIN..., replay memory = 137\n",
      "DID NOT TRAIN..., replay memory = 138\n",
      "DID NOT TRAIN..., replay memory = 139\n",
      "DID NOT TRAIN..., replay memory = 140\n",
      "DID NOT TRAIN..., replay memory = 141\n",
      "DID NOT TRAIN..., replay memory = 142\n",
      "DID NOT TRAIN..., replay memory = 143\n",
      "DID NOT TRAIN..., replay memory = 144\n",
      "DID NOT TRAIN..., replay memory = 145\n",
      "DID NOT TRAIN..., replay memory = 146\n",
      "DID NOT TRAIN..., replay memory = 147\n",
      "DID NOT TRAIN..., replay memory = 148\n",
      "DID NOT TRAIN..., replay memory = 149\n",
      "DID NOT TRAIN..., replay memory = 150\n",
      "DID NOT TRAIN..., replay memory = 151\n",
      "DID NOT TRAIN..., replay memory = 152\n",
      "DID NOT TRAIN..., replay memory = 153\n",
      "DID NOT TRAIN..., replay memory = 154\n",
      "DID NOT TRAIN..., replay memory = 155\n",
      "DID NOT TRAIN..., replay memory = 156\n",
      "DID NOT TRAIN..., replay memory = 157\n",
      "DID NOT TRAIN..., replay memory = 158\n",
      "DID NOT TRAIN..., replay memory = 159\n",
      "DID NOT TRAIN..., replay memory = 160\n",
      "DID NOT TRAIN..., replay memory = 161\n",
      "DID NOT TRAIN..., replay memory = 162\n",
      "DID NOT TRAIN..., replay memory = 163\n",
      "DID NOT TRAIN..., replay memory = 164\n",
      "DID NOT TRAIN..., replay memory = 165\n",
      "DID NOT TRAIN..., replay memory = 166\n",
      "DID NOT TRAIN..., replay memory = 167\n",
      "DID NOT TRAIN..., replay memory = 168\n",
      "DID NOT TRAIN..., replay memory = 169\n",
      "DID NOT TRAIN..., replay memory = 170\n",
      "DID NOT TRAIN..., replay memory = 171\n",
      "DID NOT TRAIN..., replay memory = 172\n",
      "DID NOT TRAIN..., replay memory = 173\n",
      "DID NOT TRAIN..., replay memory = 174\n",
      "DID NOT TRAIN..., replay memory = 175\n",
      "DID NOT TRAIN..., replay memory = 176\n",
      "DID NOT TRAIN..., replay memory = 177\n",
      "DID NOT TRAIN..., replay memory = 178\n",
      "DID NOT TRAIN..., replay memory = 179\n",
      "DID NOT TRAIN..., replay memory = 180\n",
      "DID NOT TRAIN..., replay memory = 181\n",
      "DID NOT TRAIN..., replay memory = 182\n",
      "DID NOT TRAIN..., replay memory = 183\n",
      "DID NOT TRAIN..., replay memory = 184\n",
      "DID NOT TRAIN..., replay memory = 185\n",
      "DID NOT TRAIN..., replay memory = 186\n",
      "DID NOT TRAIN..., replay memory = 187\n",
      "DID NOT TRAIN..., replay memory = 188\n",
      "DID NOT TRAIN..., replay memory = 189\n",
      "DID NOT TRAIN..., replay memory = 190\n",
      "DID NOT TRAIN..., replay memory = 191\n",
      "DID NOT TRAIN..., replay memory = 192\n",
      "DID NOT TRAIN..., replay memory = 193\n",
      "DID NOT TRAIN..., replay memory = 194\n",
      "DID NOT TRAIN..., replay memory = 195\n",
      "DID NOT TRAIN..., replay memory = 196\n",
      "DID NOT TRAIN..., replay memory = 197\n",
      "DID NOT TRAIN..., replay memory = 198\n",
      "DID NOT TRAIN..., replay memory = 199\n",
      "DID NOT TRAIN..., replay memory = 200\n",
      "Finished! | Return: -1159.6299188728904 | average reward: -5.798149594364451\n",
      "Episode 1\n",
      "DID NOT TRAIN..., replay memory = 201\n",
      "DID NOT TRAIN..., replay memory = 202\n",
      "DID NOT TRAIN..., replay memory = 203\n",
      "DID NOT TRAIN..., replay memory = 204\n",
      "DID NOT TRAIN..., replay memory = 205\n",
      "DID NOT TRAIN..., replay memory = 206\n",
      "DID NOT TRAIN..., replay memory = 207\n",
      "DID NOT TRAIN..., replay memory = 208\n",
      "DID NOT TRAIN..., replay memory = 209\n",
      "DID NOT TRAIN..., replay memory = 210\n",
      "DID NOT TRAIN..., replay memory = 211\n",
      "DID NOT TRAIN..., replay memory = 212\n",
      "DID NOT TRAIN..., replay memory = 213\n",
      "DID NOT TRAIN..., replay memory = 214\n",
      "DID NOT TRAIN..., replay memory = 215\n",
      "DID NOT TRAIN..., replay memory = 216\n",
      "DID NOT TRAIN..., replay memory = 217\n",
      "DID NOT TRAIN..., replay memory = 218\n",
      "DID NOT TRAIN..., replay memory = 219\n",
      "DID NOT TRAIN..., replay memory = 220\n",
      "DID NOT TRAIN..., replay memory = 221\n",
      "DID NOT TRAIN..., replay memory = 222\n",
      "DID NOT TRAIN..., replay memory = 223\n",
      "DID NOT TRAIN..., replay memory = 224\n",
      "DID NOT TRAIN..., replay memory = 225\n",
      "DID NOT TRAIN..., replay memory = 226\n",
      "DID NOT TRAIN..., replay memory = 227\n",
      "DID NOT TRAIN..., replay memory = 228\n",
      "DID NOT TRAIN..., replay memory = 229\n",
      "DID NOT TRAIN..., replay memory = 230\n",
      "DID NOT TRAIN..., replay memory = 231\n",
      "DID NOT TRAIN..., replay memory = 232\n",
      "DID NOT TRAIN..., replay memory = 233\n",
      "DID NOT TRAIN..., replay memory = 234\n",
      "DID NOT TRAIN..., replay memory = 235\n",
      "DID NOT TRAIN..., replay memory = 236\n",
      "DID NOT TRAIN..., replay memory = 237\n",
      "DID NOT TRAIN..., replay memory = 238\n",
      "DID NOT TRAIN..., replay memory = 239\n",
      "DID NOT TRAIN..., replay memory = 240\n",
      "DID NOT TRAIN..., replay memory = 241\n",
      "DID NOT TRAIN..., replay memory = 242\n",
      "DID NOT TRAIN..., replay memory = 243\n",
      "DID NOT TRAIN..., replay memory = 244\n",
      "DID NOT TRAIN..., replay memory = 245\n",
      "DID NOT TRAIN..., replay memory = 246\n",
      "DID NOT TRAIN..., replay memory = 247\n",
      "DID NOT TRAIN..., replay memory = 248\n",
      "DID NOT TRAIN..., replay memory = 249\n",
      "DID NOT TRAIN..., replay memory = 250\n",
      "DID NOT TRAIN..., replay memory = 251\n",
      "DID NOT TRAIN..., replay memory = 252\n",
      "DID NOT TRAIN..., replay memory = 253\n",
      "DID NOT TRAIN..., replay memory = 254\n",
      "DID NOT TRAIN..., replay memory = 255\n",
      "DID NOT TRAIN..., replay memory = 256\n",
      "DID NOT TRAIN..., replay memory = 257\n",
      "DID NOT TRAIN..., replay memory = 258\n",
      "DID NOT TRAIN..., replay memory = 259\n",
      "DID NOT TRAIN..., replay memory = 260\n",
      "DID NOT TRAIN..., replay memory = 261\n",
      "DID NOT TRAIN..., replay memory = 262\n",
      "DID NOT TRAIN..., replay memory = 263\n",
      "DID NOT TRAIN..., replay memory = 264\n",
      "DID NOT TRAIN..., replay memory = 265\n",
      "DID NOT TRAIN..., replay memory = 266\n",
      "DID NOT TRAIN..., replay memory = 267\n",
      "DID NOT TRAIN..., replay memory = 268\n",
      "DID NOT TRAIN..., replay memory = 269\n",
      "DID NOT TRAIN..., replay memory = 270\n",
      "DID NOT TRAIN..., replay memory = 271\n",
      "DID NOT TRAIN..., replay memory = 272\n",
      "DID NOT TRAIN..., replay memory = 273\n",
      "DID NOT TRAIN..., replay memory = 274\n",
      "DID NOT TRAIN..., replay memory = 275\n",
      "DID NOT TRAIN..., replay memory = 276\n",
      "DID NOT TRAIN..., replay memory = 277\n",
      "DID NOT TRAIN..., replay memory = 278\n",
      "DID NOT TRAIN..., replay memory = 279\n",
      "DID NOT TRAIN..., replay memory = 280\n",
      "DID NOT TRAIN..., replay memory = 281\n",
      "DID NOT TRAIN..., replay memory = 282\n",
      "DID NOT TRAIN..., replay memory = 283\n",
      "DID NOT TRAIN..., replay memory = 284\n",
      "DID NOT TRAIN..., replay memory = 285\n",
      "DID NOT TRAIN..., replay memory = 286\n",
      "DID NOT TRAIN..., replay memory = 287\n",
      "DID NOT TRAIN..., replay memory = 288\n",
      "DID NOT TRAIN..., replay memory = 289\n",
      "DID NOT TRAIN..., replay memory = 290\n",
      "DID NOT TRAIN..., replay memory = 291\n",
      "DID NOT TRAIN..., replay memory = 292\n",
      "DID NOT TRAIN..., replay memory = 293\n",
      "DID NOT TRAIN..., replay memory = 294\n",
      "DID NOT TRAIN..., replay memory = 295\n",
      "DID NOT TRAIN..., replay memory = 296\n",
      "DID NOT TRAIN..., replay memory = 297\n",
      "DID NOT TRAIN..., replay memory = 298\n",
      "DID NOT TRAIN..., replay memory = 299\n",
      "DID NOT TRAIN..., replay memory = 300\n",
      "DID NOT TRAIN..., replay memory = 301\n",
      "DID NOT TRAIN..., replay memory = 302\n",
      "DID NOT TRAIN..., replay memory = 303\n",
      "DID NOT TRAIN..., replay memory = 304\n",
      "DID NOT TRAIN..., replay memory = 305\n",
      "DID NOT TRAIN..., replay memory = 306\n",
      "DID NOT TRAIN..., replay memory = 307\n",
      "DID NOT TRAIN..., replay memory = 308\n",
      "DID NOT TRAIN..., replay memory = 309\n",
      "DID NOT TRAIN..., replay memory = 310\n",
      "DID NOT TRAIN..., replay memory = 311\n",
      "DID NOT TRAIN..., replay memory = 312\n",
      "DID NOT TRAIN..., replay memory = 313\n",
      "DID NOT TRAIN..., replay memory = 314\n",
      "DID NOT TRAIN..., replay memory = 315\n",
      "DID NOT TRAIN..., replay memory = 316\n",
      "DID NOT TRAIN..., replay memory = 317\n",
      "DID NOT TRAIN..., replay memory = 318\n",
      "DID NOT TRAIN..., replay memory = 319\n",
      "DID NOT TRAIN..., replay memory = 320\n",
      "DID NOT TRAIN..., replay memory = 321\n",
      "DID NOT TRAIN..., replay memory = 322\n",
      "DID NOT TRAIN..., replay memory = 323\n",
      "DID NOT TRAIN..., replay memory = 324\n",
      "DID NOT TRAIN..., replay memory = 325\n",
      "DID NOT TRAIN..., replay memory = 326\n",
      "DID NOT TRAIN..., replay memory = 327\n",
      "DID NOT TRAIN..., replay memory = 328\n",
      "DID NOT TRAIN..., replay memory = 329\n",
      "DID NOT TRAIN..., replay memory = 330\n",
      "DID NOT TRAIN..., replay memory = 331\n",
      "DID NOT TRAIN..., replay memory = 332\n",
      "DID NOT TRAIN..., replay memory = 333\n",
      "DID NOT TRAIN..., replay memory = 334\n",
      "DID NOT TRAIN..., replay memory = 335\n",
      "DID NOT TRAIN..., replay memory = 336\n",
      "DID NOT TRAIN..., replay memory = 337\n",
      "DID NOT TRAIN..., replay memory = 338\n",
      "DID NOT TRAIN..., replay memory = 339\n",
      "DID NOT TRAIN..., replay memory = 340\n",
      "DID NOT TRAIN..., replay memory = 341\n",
      "DID NOT TRAIN..., replay memory = 342\n",
      "DID NOT TRAIN..., replay memory = 343\n",
      "DID NOT TRAIN..., replay memory = 344\n",
      "DID NOT TRAIN..., replay memory = 345\n",
      "DID NOT TRAIN..., replay memory = 346\n",
      "DID NOT TRAIN..., replay memory = 347\n",
      "DID NOT TRAIN..., replay memory = 348\n",
      "DID NOT TRAIN..., replay memory = 349\n",
      "DID NOT TRAIN..., replay memory = 350\n",
      "DID NOT TRAIN..., replay memory = 351\n",
      "DID NOT TRAIN..., replay memory = 352\n",
      "DID NOT TRAIN..., replay memory = 353\n",
      "DID NOT TRAIN..., replay memory = 354\n",
      "DID NOT TRAIN..., replay memory = 355\n",
      "DID NOT TRAIN..., replay memory = 356\n",
      "DID NOT TRAIN..., replay memory = 357\n",
      "DID NOT TRAIN..., replay memory = 358\n",
      "DID NOT TRAIN..., replay memory = 359\n",
      "DID NOT TRAIN..., replay memory = 360\n",
      "DID NOT TRAIN..., replay memory = 361\n",
      "DID NOT TRAIN..., replay memory = 362\n",
      "DID NOT TRAIN..., replay memory = 363\n",
      "DID NOT TRAIN..., replay memory = 364\n",
      "DID NOT TRAIN..., replay memory = 365\n",
      "DID NOT TRAIN..., replay memory = 366\n",
      "DID NOT TRAIN..., replay memory = 367\n",
      "DID NOT TRAIN..., replay memory = 368\n",
      "DID NOT TRAIN..., replay memory = 369\n",
      "DID NOT TRAIN..., replay memory = 370\n",
      "DID NOT TRAIN..., replay memory = 371\n",
      "DID NOT TRAIN..., replay memory = 372\n",
      "DID NOT TRAIN..., replay memory = 373\n",
      "DID NOT TRAIN..., replay memory = 374\n",
      "DID NOT TRAIN..., replay memory = 375\n",
      "DID NOT TRAIN..., replay memory = 376\n",
      "DID NOT TRAIN..., replay memory = 377\n",
      "DID NOT TRAIN..., replay memory = 378\n",
      "DID NOT TRAIN..., replay memory = 379\n",
      "DID NOT TRAIN..., replay memory = 380\n",
      "DID NOT TRAIN..., replay memory = 381\n",
      "DID NOT TRAIN..., replay memory = 382\n",
      "DID NOT TRAIN..., replay memory = 383\n",
      "DID NOT TRAIN..., replay memory = 384\n",
      "DID NOT TRAIN..., replay memory = 385\n",
      "DID NOT TRAIN..., replay memory = 386\n",
      "DID NOT TRAIN..., replay memory = 387\n",
      "DID NOT TRAIN..., replay memory = 388\n",
      "DID NOT TRAIN..., replay memory = 389\n",
      "DID NOT TRAIN..., replay memory = 390\n",
      "DID NOT TRAIN..., replay memory = 391\n",
      "DID NOT TRAIN..., replay memory = 392\n",
      "DID NOT TRAIN..., replay memory = 393\n",
      "DID NOT TRAIN..., replay memory = 394\n",
      "DID NOT TRAIN..., replay memory = 395\n",
      "DID NOT TRAIN..., replay memory = 396\n",
      "DID NOT TRAIN..., replay memory = 397\n",
      "DID NOT TRAIN..., replay memory = 398\n",
      "DID NOT TRAIN..., replay memory = 399\n",
      "DID NOT TRAIN..., replay memory = 400\n",
      "Finished! | Return: -1342.3281968869135 | average reward: -6.711640984434568\n",
      "Episode 2\n",
      "DID NOT TRAIN..., replay memory = 401\n",
      "DID NOT TRAIN..., replay memory = 402\n",
      "DID NOT TRAIN..., replay memory = 403\n",
      "DID NOT TRAIN..., replay memory = 404\n",
      "DID NOT TRAIN..., replay memory = 405\n",
      "DID NOT TRAIN..., replay memory = 406\n",
      "DID NOT TRAIN..., replay memory = 407\n",
      "DID NOT TRAIN..., replay memory = 408\n",
      "DID NOT TRAIN..., replay memory = 409\n",
      "DID NOT TRAIN..., replay memory = 410\n",
      "DID NOT TRAIN..., replay memory = 411\n",
      "DID NOT TRAIN..., replay memory = 412\n",
      "DID NOT TRAIN..., replay memory = 413\n",
      "DID NOT TRAIN..., replay memory = 414\n",
      "DID NOT TRAIN..., replay memory = 415\n",
      "DID NOT TRAIN..., replay memory = 416\n",
      "DID NOT TRAIN..., replay memory = 417\n",
      "DID NOT TRAIN..., replay memory = 418\n",
      "DID NOT TRAIN..., replay memory = 419\n",
      "DID NOT TRAIN..., replay memory = 420\n",
      "DID NOT TRAIN..., replay memory = 421\n",
      "DID NOT TRAIN..., replay memory = 422\n",
      "DID NOT TRAIN..., replay memory = 423\n",
      "DID NOT TRAIN..., replay memory = 424\n",
      "DID NOT TRAIN..., replay memory = 425\n",
      "DID NOT TRAIN..., replay memory = 426\n",
      "DID NOT TRAIN..., replay memory = 427\n",
      "DID NOT TRAIN..., replay memory = 428\n",
      "DID NOT TRAIN..., replay memory = 429\n",
      "DID NOT TRAIN..., replay memory = 430\n",
      "DID NOT TRAIN..., replay memory = 431\n",
      "DID NOT TRAIN..., replay memory = 432\n",
      "DID NOT TRAIN..., replay memory = 433\n",
      "DID NOT TRAIN..., replay memory = 434\n",
      "DID NOT TRAIN..., replay memory = 435\n",
      "DID NOT TRAIN..., replay memory = 436\n",
      "DID NOT TRAIN..., replay memory = 437\n",
      "DID NOT TRAIN..., replay memory = 438\n",
      "DID NOT TRAIN..., replay memory = 439\n",
      "DID NOT TRAIN..., replay memory = 440\n",
      "DID NOT TRAIN..., replay memory = 441\n",
      "DID NOT TRAIN..., replay memory = 442\n",
      "DID NOT TRAIN..., replay memory = 443\n",
      "DID NOT TRAIN..., replay memory = 444\n",
      "DID NOT TRAIN..., replay memory = 445\n",
      "DID NOT TRAIN..., replay memory = 446\n",
      "DID NOT TRAIN..., replay memory = 447\n",
      "DID NOT TRAIN..., replay memory = 448\n",
      "DID NOT TRAIN..., replay memory = 449\n",
      "DID NOT TRAIN..., replay memory = 450\n",
      "DID NOT TRAIN..., replay memory = 451\n",
      "DID NOT TRAIN..., replay memory = 452\n",
      "DID NOT TRAIN..., replay memory = 453\n",
      "DID NOT TRAIN..., replay memory = 454\n",
      "DID NOT TRAIN..., replay memory = 455\n",
      "DID NOT TRAIN..., replay memory = 456\n",
      "DID NOT TRAIN..., replay memory = 457\n",
      "DID NOT TRAIN..., replay memory = 458\n",
      "DID NOT TRAIN..., replay memory = 459\n",
      "DID NOT TRAIN..., replay memory = 460\n",
      "DID NOT TRAIN..., replay memory = 461\n",
      "DID NOT TRAIN..., replay memory = 462\n",
      "DID NOT TRAIN..., replay memory = 463\n",
      "DID NOT TRAIN..., replay memory = 464\n",
      "DID NOT TRAIN..., replay memory = 465\n",
      "DID NOT TRAIN..., replay memory = 466\n",
      "DID NOT TRAIN..., replay memory = 467\n",
      "DID NOT TRAIN..., replay memory = 468\n",
      "DID NOT TRAIN..., replay memory = 469\n",
      "DID NOT TRAIN..., replay memory = 470\n",
      "DID NOT TRAIN..., replay memory = 471\n",
      "DID NOT TRAIN..., replay memory = 472\n",
      "DID NOT TRAIN..., replay memory = 473\n",
      "DID NOT TRAIN..., replay memory = 474\n",
      "DID NOT TRAIN..., replay memory = 475\n",
      "DID NOT TRAIN..., replay memory = 476\n",
      "DID NOT TRAIN..., replay memory = 477\n",
      "DID NOT TRAIN..., replay memory = 478\n",
      "DID NOT TRAIN..., replay memory = 479\n",
      "DID NOT TRAIN..., replay memory = 480\n",
      "DID NOT TRAIN..., replay memory = 481\n",
      "DID NOT TRAIN..., replay memory = 482\n",
      "DID NOT TRAIN..., replay memory = 483\n",
      "DID NOT TRAIN..., replay memory = 484\n",
      "DID NOT TRAIN..., replay memory = 485\n",
      "DID NOT TRAIN..., replay memory = 486\n",
      "DID NOT TRAIN..., replay memory = 487\n",
      "DID NOT TRAIN..., replay memory = 488\n",
      "DID NOT TRAIN..., replay memory = 489\n",
      "DID NOT TRAIN..., replay memory = 490\n",
      "DID NOT TRAIN..., replay memory = 491\n",
      "DID NOT TRAIN..., replay memory = 492\n",
      "DID NOT TRAIN..., replay memory = 493\n",
      "DID NOT TRAIN..., replay memory = 494\n",
      "DID NOT TRAIN..., replay memory = 495\n",
      "DID NOT TRAIN..., replay memory = 496\n",
      "DID NOT TRAIN..., replay memory = 497\n",
      "DID NOT TRAIN..., replay memory = 498\n",
      "DID NOT TRAIN..., replay memory = 499\n",
      "DID NOT TRAIN..., replay memory = 500\n",
      "DID NOT TRAIN..., replay memory = 501\n",
      "DID NOT TRAIN..., replay memory = 502\n",
      "DID NOT TRAIN..., replay memory = 503\n",
      "DID NOT TRAIN..., replay memory = 504\n",
      "DID NOT TRAIN..., replay memory = 505\n",
      "DID NOT TRAIN..., replay memory = 506\n",
      "DID NOT TRAIN..., replay memory = 507\n",
      "DID NOT TRAIN..., replay memory = 508\n",
      "DID NOT TRAIN..., replay memory = 509\n",
      "DID NOT TRAIN..., replay memory = 510\n",
      "DID NOT TRAIN..., replay memory = 511\n",
      "DID NOT TRAIN..., replay memory = 512\n",
      "DID NOT TRAIN..., replay memory = 513\n",
      "DID NOT TRAIN..., replay memory = 514\n",
      "DID NOT TRAIN..., replay memory = 515\n",
      "DID NOT TRAIN..., replay memory = 516\n",
      "DID NOT TRAIN..., replay memory = 517\n",
      "DID NOT TRAIN..., replay memory = 518\n",
      "DID NOT TRAIN..., replay memory = 519\n",
      "DID NOT TRAIN..., replay memory = 520\n",
      "DID NOT TRAIN..., replay memory = 521\n",
      "DID NOT TRAIN..., replay memory = 522\n",
      "DID NOT TRAIN..., replay memory = 523\n",
      "DID NOT TRAIN..., replay memory = 524\n",
      "DID NOT TRAIN..., replay memory = 525\n",
      "DID NOT TRAIN..., replay memory = 526\n",
      "DID NOT TRAIN..., replay memory = 527\n",
      "DID NOT TRAIN..., replay memory = 528\n",
      "DID NOT TRAIN..., replay memory = 529\n",
      "DID NOT TRAIN..., replay memory = 530\n",
      "DID NOT TRAIN..., replay memory = 531\n",
      "DID NOT TRAIN..., replay memory = 532\n",
      "DID NOT TRAIN..., replay memory = 533\n",
      "DID NOT TRAIN..., replay memory = 534\n",
      "DID NOT TRAIN..., replay memory = 535\n",
      "DID NOT TRAIN..., replay memory = 536\n",
      "DID NOT TRAIN..., replay memory = 537\n",
      "DID NOT TRAIN..., replay memory = 538\n",
      "DID NOT TRAIN..., replay memory = 539\n",
      "DID NOT TRAIN..., replay memory = 540\n",
      "DID NOT TRAIN..., replay memory = 541\n",
      "DID NOT TRAIN..., replay memory = 542\n",
      "DID NOT TRAIN..., replay memory = 543\n",
      "DID NOT TRAIN..., replay memory = 544\n",
      "DID NOT TRAIN..., replay memory = 545\n",
      "DID NOT TRAIN..., replay memory = 546\n",
      "DID NOT TRAIN..., replay memory = 547\n",
      "DID NOT TRAIN..., replay memory = 548\n",
      "DID NOT TRAIN..., replay memory = 549\n",
      "DID NOT TRAIN..., replay memory = 550\n",
      "DID NOT TRAIN..., replay memory = 551\n",
      "DID NOT TRAIN..., replay memory = 552\n",
      "DID NOT TRAIN..., replay memory = 553\n",
      "DID NOT TRAIN..., replay memory = 554\n",
      "DID NOT TRAIN..., replay memory = 555\n",
      "DID NOT TRAIN..., replay memory = 556\n",
      "DID NOT TRAIN..., replay memory = 557\n",
      "DID NOT TRAIN..., replay memory = 558\n",
      "DID NOT TRAIN..., replay memory = 559\n",
      "DID NOT TRAIN..., replay memory = 560\n",
      "DID NOT TRAIN..., replay memory = 561\n",
      "DID NOT TRAIN..., replay memory = 562\n",
      "DID NOT TRAIN..., replay memory = 563\n",
      "DID NOT TRAIN..., replay memory = 564\n",
      "DID NOT TRAIN..., replay memory = 565\n",
      "DID NOT TRAIN..., replay memory = 566\n",
      "DID NOT TRAIN..., replay memory = 567\n",
      "DID NOT TRAIN..., replay memory = 568\n",
      "DID NOT TRAIN..., replay memory = 569\n",
      "DID NOT TRAIN..., replay memory = 570\n",
      "DID NOT TRAIN..., replay memory = 571\n",
      "DID NOT TRAIN..., replay memory = 572\n",
      "DID NOT TRAIN..., replay memory = 573\n",
      "DID NOT TRAIN..., replay memory = 574\n",
      "DID NOT TRAIN..., replay memory = 575\n",
      "DID NOT TRAIN..., replay memory = 576\n",
      "DID NOT TRAIN..., replay memory = 577\n",
      "DID NOT TRAIN..., replay memory = 578\n",
      "DID NOT TRAIN..., replay memory = 579\n",
      "DID NOT TRAIN..., replay memory = 580\n",
      "DID NOT TRAIN..., replay memory = 581\n",
      "DID NOT TRAIN..., replay memory = 582\n",
      "DID NOT TRAIN..., replay memory = 583\n",
      "DID NOT TRAIN..., replay memory = 584\n",
      "DID NOT TRAIN..., replay memory = 585\n",
      "DID NOT TRAIN..., replay memory = 586\n",
      "DID NOT TRAIN..., replay memory = 587\n",
      "DID NOT TRAIN..., replay memory = 588\n",
      "DID NOT TRAIN..., replay memory = 589\n",
      "DID NOT TRAIN..., replay memory = 590\n",
      "DID NOT TRAIN..., replay memory = 591\n",
      "DID NOT TRAIN..., replay memory = 592\n",
      "DID NOT TRAIN..., replay memory = 593\n",
      "DID NOT TRAIN..., replay memory = 594\n",
      "DID NOT TRAIN..., replay memory = 595\n",
      "DID NOT TRAIN..., replay memory = 596\n",
      "DID NOT TRAIN..., replay memory = 597\n",
      "DID NOT TRAIN..., replay memory = 598\n",
      "DID NOT TRAIN..., replay memory = 599\n",
      "DID NOT TRAIN..., replay memory = 600\n",
      "Finished! | Return: -971.9667804424469 | average reward: -4.859833902212234\n",
      "Episode 3\n",
      "DID NOT TRAIN..., replay memory = 601\n",
      "DID NOT TRAIN..., replay memory = 602\n",
      "DID NOT TRAIN..., replay memory = 603\n",
      "DID NOT TRAIN..., replay memory = 604\n",
      "DID NOT TRAIN..., replay memory = 605\n",
      "DID NOT TRAIN..., replay memory = 606\n",
      "DID NOT TRAIN..., replay memory = 607\n",
      "DID NOT TRAIN..., replay memory = 608\n",
      "DID NOT TRAIN..., replay memory = 609\n",
      "DID NOT TRAIN..., replay memory = 610\n",
      "DID NOT TRAIN..., replay memory = 611\n",
      "DID NOT TRAIN..., replay memory = 612\n",
      "DID NOT TRAIN..., replay memory = 613\n",
      "DID NOT TRAIN..., replay memory = 614\n",
      "DID NOT TRAIN..., replay memory = 615\n",
      "DID NOT TRAIN..., replay memory = 616\n",
      "DID NOT TRAIN..., replay memory = 617\n",
      "DID NOT TRAIN..., replay memory = 618\n",
      "DID NOT TRAIN..., replay memory = 619\n",
      "DID NOT TRAIN..., replay memory = 620\n",
      "DID NOT TRAIN..., replay memory = 621\n",
      "DID NOT TRAIN..., replay memory = 622\n",
      "DID NOT TRAIN..., replay memory = 623\n",
      "DID NOT TRAIN..., replay memory = 624\n",
      "DID NOT TRAIN..., replay memory = 625\n",
      "DID NOT TRAIN..., replay memory = 626\n",
      "DID NOT TRAIN..., replay memory = 627\n",
      "DID NOT TRAIN..., replay memory = 628\n",
      "DID NOT TRAIN..., replay memory = 629\n",
      "DID NOT TRAIN..., replay memory = 630\n",
      "DID NOT TRAIN..., replay memory = 631\n",
      "DID NOT TRAIN..., replay memory = 632\n",
      "DID NOT TRAIN..., replay memory = 633\n",
      "DID NOT TRAIN..., replay memory = 634\n",
      "DID NOT TRAIN..., replay memory = 635\n",
      "DID NOT TRAIN..., replay memory = 636\n",
      "DID NOT TRAIN..., replay memory = 637\n",
      "DID NOT TRAIN..., replay memory = 638\n",
      "DID NOT TRAIN..., replay memory = 639\n",
      "DID NOT TRAIN..., replay memory = 640\n",
      "DID NOT TRAIN..., replay memory = 641\n",
      "DID NOT TRAIN..., replay memory = 642\n",
      "DID NOT TRAIN..., replay memory = 643\n",
      "DID NOT TRAIN..., replay memory = 644\n",
      "DID NOT TRAIN..., replay memory = 645\n",
      "DID NOT TRAIN..., replay memory = 646\n",
      "DID NOT TRAIN..., replay memory = 647\n",
      "DID NOT TRAIN..., replay memory = 648\n",
      "DID NOT TRAIN..., replay memory = 649\n",
      "DID NOT TRAIN..., replay memory = 650\n",
      "DID NOT TRAIN..., replay memory = 651\n",
      "DID NOT TRAIN..., replay memory = 652\n",
      "DID NOT TRAIN..., replay memory = 653\n",
      "DID NOT TRAIN..., replay memory = 654\n",
      "DID NOT TRAIN..., replay memory = 655\n",
      "DID NOT TRAIN..., replay memory = 656\n",
      "DID NOT TRAIN..., replay memory = 657\n",
      "DID NOT TRAIN..., replay memory = 658\n",
      "DID NOT TRAIN..., replay memory = 659\n",
      "DID NOT TRAIN..., replay memory = 660\n",
      "DID NOT TRAIN..., replay memory = 661\n",
      "DID NOT TRAIN..., replay memory = 662\n",
      "DID NOT TRAIN..., replay memory = 663\n",
      "DID NOT TRAIN..., replay memory = 664\n",
      "DID NOT TRAIN..., replay memory = 665\n",
      "DID NOT TRAIN..., replay memory = 666\n",
      "DID NOT TRAIN..., replay memory = 667\n",
      "DID NOT TRAIN..., replay memory = 668\n",
      "DID NOT TRAIN..., replay memory = 669\n",
      "DID NOT TRAIN..., replay memory = 670\n",
      "DID NOT TRAIN..., replay memory = 671\n",
      "DID NOT TRAIN..., replay memory = 672\n",
      "DID NOT TRAIN..., replay memory = 673\n",
      "DID NOT TRAIN..., replay memory = 674\n",
      "DID NOT TRAIN..., replay memory = 675\n",
      "DID NOT TRAIN..., replay memory = 676\n",
      "DID NOT TRAIN..., replay memory = 677\n",
      "DID NOT TRAIN..., replay memory = 678\n",
      "DID NOT TRAIN..., replay memory = 679\n",
      "DID NOT TRAIN..., replay memory = 680\n",
      "DID NOT TRAIN..., replay memory = 681\n",
      "DID NOT TRAIN..., replay memory = 682\n",
      "DID NOT TRAIN..., replay memory = 683\n",
      "DID NOT TRAIN..., replay memory = 684\n",
      "DID NOT TRAIN..., replay memory = 685\n",
      "DID NOT TRAIN..., replay memory = 686\n",
      "DID NOT TRAIN..., replay memory = 687\n",
      "DID NOT TRAIN..., replay memory = 688\n",
      "DID NOT TRAIN..., replay memory = 689\n",
      "DID NOT TRAIN..., replay memory = 690\n",
      "DID NOT TRAIN..., replay memory = 691\n",
      "DID NOT TRAIN..., replay memory = 692\n",
      "DID NOT TRAIN..., replay memory = 693\n",
      "DID NOT TRAIN..., replay memory = 694\n",
      "DID NOT TRAIN..., replay memory = 695\n",
      "DID NOT TRAIN..., replay memory = 696\n",
      "DID NOT TRAIN..., replay memory = 697\n",
      "DID NOT TRAIN..., replay memory = 698\n",
      "DID NOT TRAIN..., replay memory = 699\n",
      "DID NOT TRAIN..., replay memory = 700\n",
      "DID NOT TRAIN..., replay memory = 701\n",
      "DID NOT TRAIN..., replay memory = 702\n",
      "DID NOT TRAIN..., replay memory = 703\n",
      "DID NOT TRAIN..., replay memory = 704\n",
      "DID NOT TRAIN..., replay memory = 705\n",
      "DID NOT TRAIN..., replay memory = 706\n",
      "DID NOT TRAIN..., replay memory = 707\n",
      "DID NOT TRAIN..., replay memory = 708\n",
      "DID NOT TRAIN..., replay memory = 709\n",
      "DID NOT TRAIN..., replay memory = 710\n",
      "DID NOT TRAIN..., replay memory = 711\n",
      "DID NOT TRAIN..., replay memory = 712\n",
      "DID NOT TRAIN..., replay memory = 713\n",
      "DID NOT TRAIN..., replay memory = 714\n",
      "DID NOT TRAIN..., replay memory = 715\n",
      "DID NOT TRAIN..., replay memory = 716\n",
      "DID NOT TRAIN..., replay memory = 717\n",
      "DID NOT TRAIN..., replay memory = 718\n",
      "DID NOT TRAIN..., replay memory = 719\n",
      "DID NOT TRAIN..., replay memory = 720\n",
      "DID NOT TRAIN..., replay memory = 721\n",
      "DID NOT TRAIN..., replay memory = 722\n",
      "DID NOT TRAIN..., replay memory = 723\n",
      "DID NOT TRAIN..., replay memory = 724\n",
      "DID NOT TRAIN..., replay memory = 725\n",
      "DID NOT TRAIN..., replay memory = 726\n",
      "DID NOT TRAIN..., replay memory = 727\n",
      "DID NOT TRAIN..., replay memory = 728\n",
      "DID NOT TRAIN..., replay memory = 729\n",
      "DID NOT TRAIN..., replay memory = 730\n",
      "DID NOT TRAIN..., replay memory = 731\n",
      "DID NOT TRAIN..., replay memory = 732\n",
      "DID NOT TRAIN..., replay memory = 733\n",
      "DID NOT TRAIN..., replay memory = 734\n",
      "DID NOT TRAIN..., replay memory = 735\n",
      "DID NOT TRAIN..., replay memory = 736\n",
      "DID NOT TRAIN..., replay memory = 737\n",
      "DID NOT TRAIN..., replay memory = 738\n",
      "DID NOT TRAIN..., replay memory = 739\n",
      "DID NOT TRAIN..., replay memory = 740\n",
      "DID NOT TRAIN..., replay memory = 741\n",
      "DID NOT TRAIN..., replay memory = 742\n",
      "DID NOT TRAIN..., replay memory = 743\n",
      "DID NOT TRAIN..., replay memory = 744\n",
      "DID NOT TRAIN..., replay memory = 745\n",
      "DID NOT TRAIN..., replay memory = 746\n",
      "DID NOT TRAIN..., replay memory = 747\n",
      "DID NOT TRAIN..., replay memory = 748\n",
      "DID NOT TRAIN..., replay memory = 749\n",
      "DID NOT TRAIN..., replay memory = 750\n",
      "DID NOT TRAIN..., replay memory = 751\n",
      "DID NOT TRAIN..., replay memory = 752\n",
      "DID NOT TRAIN..., replay memory = 753\n",
      "DID NOT TRAIN..., replay memory = 754\n",
      "DID NOT TRAIN..., replay memory = 755\n",
      "DID NOT TRAIN..., replay memory = 756\n",
      "DID NOT TRAIN..., replay memory = 757\n",
      "DID NOT TRAIN..., replay memory = 758\n",
      "DID NOT TRAIN..., replay memory = 759\n",
      "DID NOT TRAIN..., replay memory = 760\n",
      "DID NOT TRAIN..., replay memory = 761\n",
      "DID NOT TRAIN..., replay memory = 762\n",
      "DID NOT TRAIN..., replay memory = 763\n",
      "DID NOT TRAIN..., replay memory = 764\n",
      "DID NOT TRAIN..., replay memory = 765\n",
      "DID NOT TRAIN..., replay memory = 766\n",
      "DID NOT TRAIN..., replay memory = 767\n",
      "DID NOT TRAIN..., replay memory = 768\n",
      "DID NOT TRAIN..., replay memory = 769\n",
      "DID NOT TRAIN..., replay memory = 770\n",
      "DID NOT TRAIN..., replay memory = 771\n",
      "DID NOT TRAIN..., replay memory = 772\n",
      "DID NOT TRAIN..., replay memory = 773\n",
      "DID NOT TRAIN..., replay memory = 774\n",
      "DID NOT TRAIN..., replay memory = 775\n",
      "DID NOT TRAIN..., replay memory = 776\n",
      "DID NOT TRAIN..., replay memory = 777\n",
      "DID NOT TRAIN..., replay memory = 778\n",
      "DID NOT TRAIN..., replay memory = 779\n",
      "DID NOT TRAIN..., replay memory = 780\n",
      "DID NOT TRAIN..., replay memory = 781\n",
      "DID NOT TRAIN..., replay memory = 782\n",
      "DID NOT TRAIN..., replay memory = 783\n",
      "DID NOT TRAIN..., replay memory = 784\n",
      "DID NOT TRAIN..., replay memory = 785\n",
      "DID NOT TRAIN..., replay memory = 786\n",
      "DID NOT TRAIN..., replay memory = 787\n",
      "DID NOT TRAIN..., replay memory = 788\n",
      "DID NOT TRAIN..., replay memory = 789\n",
      "DID NOT TRAIN..., replay memory = 790\n",
      "DID NOT TRAIN..., replay memory = 791\n",
      "DID NOT TRAIN..., replay memory = 792\n",
      "DID NOT TRAIN..., replay memory = 793\n",
      "DID NOT TRAIN..., replay memory = 794\n",
      "DID NOT TRAIN..., replay memory = 795\n",
      "DID NOT TRAIN..., replay memory = 796\n",
      "DID NOT TRAIN..., replay memory = 797\n",
      "DID NOT TRAIN..., replay memory = 798\n",
      "DID NOT TRAIN..., replay memory = 799\n",
      "DID NOT TRAIN..., replay memory = 800\n",
      "Finished! | Return: -1297.1733177821113 | average reward: -6.4858665889105565\n",
      "Episode 4\n",
      "DID NOT TRAIN..., replay memory = 801\n",
      "DID NOT TRAIN..., replay memory = 802\n",
      "DID NOT TRAIN..., replay memory = 803\n",
      "DID NOT TRAIN..., replay memory = 804\n",
      "DID NOT TRAIN..., replay memory = 805\n",
      "DID NOT TRAIN..., replay memory = 806\n",
      "DID NOT TRAIN..., replay memory = 807\n",
      "DID NOT TRAIN..., replay memory = 808\n",
      "DID NOT TRAIN..., replay memory = 809\n",
      "DID NOT TRAIN..., replay memory = 810\n",
      "DID NOT TRAIN..., replay memory = 811\n",
      "DID NOT TRAIN..., replay memory = 812\n",
      "DID NOT TRAIN..., replay memory = 813\n",
      "DID NOT TRAIN..., replay memory = 814\n",
      "DID NOT TRAIN..., replay memory = 815\n",
      "DID NOT TRAIN..., replay memory = 816\n",
      "DID NOT TRAIN..., replay memory = 817\n",
      "DID NOT TRAIN..., replay memory = 818\n",
      "DID NOT TRAIN..., replay memory = 819\n",
      "DID NOT TRAIN..., replay memory = 820\n",
      "DID NOT TRAIN..., replay memory = 821\n",
      "DID NOT TRAIN..., replay memory = 822\n",
      "DID NOT TRAIN..., replay memory = 823\n",
      "DID NOT TRAIN..., replay memory = 824\n",
      "DID NOT TRAIN..., replay memory = 825\n",
      "DID NOT TRAIN..., replay memory = 826\n",
      "DID NOT TRAIN..., replay memory = 827\n",
      "DID NOT TRAIN..., replay memory = 828\n",
      "DID NOT TRAIN..., replay memory = 829\n",
      "DID NOT TRAIN..., replay memory = 830\n",
      "DID NOT TRAIN..., replay memory = 831\n",
      "DID NOT TRAIN..., replay memory = 832\n",
      "DID NOT TRAIN..., replay memory = 833\n",
      "DID NOT TRAIN..., replay memory = 834\n",
      "DID NOT TRAIN..., replay memory = 835\n",
      "DID NOT TRAIN..., replay memory = 836\n",
      "DID NOT TRAIN..., replay memory = 837\n",
      "DID NOT TRAIN..., replay memory = 838\n",
      "DID NOT TRAIN..., replay memory = 839\n",
      "DID NOT TRAIN..., replay memory = 840\n",
      "DID NOT TRAIN..., replay memory = 841\n",
      "DID NOT TRAIN..., replay memory = 842\n",
      "DID NOT TRAIN..., replay memory = 843\n",
      "DID NOT TRAIN..., replay memory = 844\n",
      "DID NOT TRAIN..., replay memory = 845\n",
      "DID NOT TRAIN..., replay memory = 846\n",
      "DID NOT TRAIN..., replay memory = 847\n",
      "DID NOT TRAIN..., replay memory = 848\n",
      "DID NOT TRAIN..., replay memory = 849\n",
      "DID NOT TRAIN..., replay memory = 850\n",
      "DID NOT TRAIN..., replay memory = 851\n",
      "DID NOT TRAIN..., replay memory = 852\n",
      "DID NOT TRAIN..., replay memory = 853\n",
      "DID NOT TRAIN..., replay memory = 854\n",
      "DID NOT TRAIN..., replay memory = 855\n",
      "DID NOT TRAIN..., replay memory = 856\n",
      "DID NOT TRAIN..., replay memory = 857\n",
      "DID NOT TRAIN..., replay memory = 858\n",
      "DID NOT TRAIN..., replay memory = 859\n",
      "DID NOT TRAIN..., replay memory = 860\n",
      "DID NOT TRAIN..., replay memory = 861\n",
      "DID NOT TRAIN..., replay memory = 862\n",
      "DID NOT TRAIN..., replay memory = 863\n",
      "DID NOT TRAIN..., replay memory = 864\n",
      "DID NOT TRAIN..., replay memory = 865\n",
      "DID NOT TRAIN..., replay memory = 866\n",
      "DID NOT TRAIN..., replay memory = 867\n",
      "DID NOT TRAIN..., replay memory = 868\n",
      "DID NOT TRAIN..., replay memory = 869\n",
      "DID NOT TRAIN..., replay memory = 870\n",
      "DID NOT TRAIN..., replay memory = 871\n",
      "DID NOT TRAIN..., replay memory = 872\n",
      "DID NOT TRAIN..., replay memory = 873\n",
      "DID NOT TRAIN..., replay memory = 874\n",
      "DID NOT TRAIN..., replay memory = 875\n",
      "DID NOT TRAIN..., replay memory = 876\n",
      "DID NOT TRAIN..., replay memory = 877\n",
      "DID NOT TRAIN..., replay memory = 878\n",
      "DID NOT TRAIN..., replay memory = 879\n",
      "DID NOT TRAIN..., replay memory = 880\n",
      "DID NOT TRAIN..., replay memory = 881\n",
      "DID NOT TRAIN..., replay memory = 882\n",
      "DID NOT TRAIN..., replay memory = 883\n",
      "DID NOT TRAIN..., replay memory = 884\n",
      "DID NOT TRAIN..., replay memory = 885\n",
      "DID NOT TRAIN..., replay memory = 886\n",
      "DID NOT TRAIN..., replay memory = 887\n",
      "DID NOT TRAIN..., replay memory = 888\n",
      "DID NOT TRAIN..., replay memory = 889\n",
      "DID NOT TRAIN..., replay memory = 890\n",
      "DID NOT TRAIN..., replay memory = 891\n",
      "DID NOT TRAIN..., replay memory = 892\n",
      "DID NOT TRAIN..., replay memory = 893\n",
      "DID NOT TRAIN..., replay memory = 894\n",
      "DID NOT TRAIN..., replay memory = 895\n",
      "DID NOT TRAIN..., replay memory = 896\n",
      "DID NOT TRAIN..., replay memory = 897\n",
      "DID NOT TRAIN..., replay memory = 898\n",
      "DID NOT TRAIN..., replay memory = 899\n",
      "DID NOT TRAIN..., replay memory = 900\n",
      "DID NOT TRAIN..., replay memory = 901\n",
      "DID NOT TRAIN..., replay memory = 902\n",
      "DID NOT TRAIN..., replay memory = 903\n",
      "DID NOT TRAIN..., replay memory = 904\n",
      "DID NOT TRAIN..., replay memory = 905\n",
      "DID NOT TRAIN..., replay memory = 906\n",
      "DID NOT TRAIN..., replay memory = 907\n",
      "DID NOT TRAIN..., replay memory = 908\n",
      "DID NOT TRAIN..., replay memory = 909\n",
      "DID NOT TRAIN..., replay memory = 910\n",
      "DID NOT TRAIN..., replay memory = 911\n",
      "DID NOT TRAIN..., replay memory = 912\n",
      "DID NOT TRAIN..., replay memory = 913\n",
      "DID NOT TRAIN..., replay memory = 914\n",
      "DID NOT TRAIN..., replay memory = 915\n",
      "DID NOT TRAIN..., replay memory = 916\n",
      "DID NOT TRAIN..., replay memory = 917\n",
      "DID NOT TRAIN..., replay memory = 918\n",
      "DID NOT TRAIN..., replay memory = 919\n",
      "DID NOT TRAIN..., replay memory = 920\n",
      "DID NOT TRAIN..., replay memory = 921\n",
      "DID NOT TRAIN..., replay memory = 922\n",
      "DID NOT TRAIN..., replay memory = 923\n",
      "DID NOT TRAIN..., replay memory = 924\n",
      "DID NOT TRAIN..., replay memory = 925\n",
      "DID NOT TRAIN..., replay memory = 926\n",
      "DID NOT TRAIN..., replay memory = 927\n",
      "DID NOT TRAIN..., replay memory = 928\n",
      "DID NOT TRAIN..., replay memory = 929\n",
      "DID NOT TRAIN..., replay memory = 930\n",
      "DID NOT TRAIN..., replay memory = 931\n",
      "DID NOT TRAIN..., replay memory = 932\n",
      "DID NOT TRAIN..., replay memory = 933\n",
      "DID NOT TRAIN..., replay memory = 934\n",
      "DID NOT TRAIN..., replay memory = 935\n",
      "DID NOT TRAIN..., replay memory = 936\n",
      "DID NOT TRAIN..., replay memory = 937\n",
      "DID NOT TRAIN..., replay memory = 938\n",
      "DID NOT TRAIN..., replay memory = 939\n",
      "DID NOT TRAIN..., replay memory = 940\n",
      "DID NOT TRAIN..., replay memory = 941\n",
      "DID NOT TRAIN..., replay memory = 942\n",
      "DID NOT TRAIN..., replay memory = 943\n",
      "DID NOT TRAIN..., replay memory = 944\n",
      "DID NOT TRAIN..., replay memory = 945\n",
      "DID NOT TRAIN..., replay memory = 946\n",
      "DID NOT TRAIN..., replay memory = 947\n",
      "DID NOT TRAIN..., replay memory = 948\n",
      "DID NOT TRAIN..., replay memory = 949\n",
      "DID NOT TRAIN..., replay memory = 950\n",
      "DID NOT TRAIN..., replay memory = 951\n",
      "DID NOT TRAIN..., replay memory = 952\n",
      "DID NOT TRAIN..., replay memory = 953\n",
      "DID NOT TRAIN..., replay memory = 954\n",
      "DID NOT TRAIN..., replay memory = 955\n",
      "DID NOT TRAIN..., replay memory = 956\n",
      "DID NOT TRAIN..., replay memory = 957\n",
      "DID NOT TRAIN..., replay memory = 958\n",
      "DID NOT TRAIN..., replay memory = 959\n",
      "DID NOT TRAIN..., replay memory = 960\n",
      "DID NOT TRAIN..., replay memory = 961\n",
      "DID NOT TRAIN..., replay memory = 962\n",
      "DID NOT TRAIN..., replay memory = 963\n",
      "DID NOT TRAIN..., replay memory = 964\n",
      "DID NOT TRAIN..., replay memory = 965\n",
      "DID NOT TRAIN..., replay memory = 966\n",
      "DID NOT TRAIN..., replay memory = 967\n",
      "DID NOT TRAIN..., replay memory = 968\n",
      "DID NOT TRAIN..., replay memory = 969\n",
      "DID NOT TRAIN..., replay memory = 970\n",
      "DID NOT TRAIN..., replay memory = 971\n",
      "DID NOT TRAIN..., replay memory = 972\n",
      "DID NOT TRAIN..., replay memory = 973\n",
      "DID NOT TRAIN..., replay memory = 974\n",
      "DID NOT TRAIN..., replay memory = 975\n",
      "DID NOT TRAIN..., replay memory = 976\n",
      "DID NOT TRAIN..., replay memory = 977\n",
      "DID NOT TRAIN..., replay memory = 978\n",
      "DID NOT TRAIN..., replay memory = 979\n",
      "DID NOT TRAIN..., replay memory = 980\n",
      "DID NOT TRAIN..., replay memory = 981\n",
      "DID NOT TRAIN..., replay memory = 982\n",
      "DID NOT TRAIN..., replay memory = 983\n",
      "DID NOT TRAIN..., replay memory = 984\n",
      "DID NOT TRAIN..., replay memory = 985\n",
      "DID NOT TRAIN..., replay memory = 986\n",
      "DID NOT TRAIN..., replay memory = 987\n",
      "DID NOT TRAIN..., replay memory = 988\n",
      "DID NOT TRAIN..., replay memory = 989\n",
      "DID NOT TRAIN..., replay memory = 990\n",
      "DID NOT TRAIN..., replay memory = 991\n",
      "DID NOT TRAIN..., replay memory = 992\n",
      "DID NOT TRAIN..., replay memory = 993\n",
      "DID NOT TRAIN..., replay memory = 994\n",
      "DID NOT TRAIN..., replay memory = 995\n",
      "DID NOT TRAIN..., replay memory = 996\n",
      "DID NOT TRAIN..., replay memory = 997\n",
      "DID NOT TRAIN..., replay memory = 998\n",
      "DID NOT TRAIN..., replay memory = 999\n",
      "epsilon: 0.995\n",
      "Finished! | Return: -1146.554272884443 | average reward: -5.732771364422215\n",
      "Episode 5\n",
      "epsilon: 0.990025\n",
      "epsilon: 0.985074875\n",
      "epsilon: 0.9801495006250001\n",
      "epsilon: 0.9752487531218751\n",
      "epsilon: 0.9703725093562657\n",
      "epsilon: 0.9655206468094844\n",
      "epsilon: 0.960693043575437\n",
      "epsilon: 0.9558895783575597\n",
      "epsilon: 0.9511101304657719\n",
      "epsilon: 0.946354579813443\n",
      "epsilon: 0.9416228069143757\n",
      "epsilon: 0.9369146928798039\n",
      "epsilon: 0.9322301194154049\n",
      "epsilon: 0.9275689688183278\n",
      "epsilon: 0.9229311239742362\n",
      "epsilon: 0.918316468354365\n",
      "epsilon: 0.9137248860125932\n",
      "epsilon: 0.9091562615825302\n",
      "epsilon: 0.9046104802746175\n",
      "epsilon: 0.9000874278732445\n",
      "epsilon: 0.8955869907338783\n",
      "epsilon: 0.8911090557802088\n",
      "epsilon: 0.8866535105013078\n",
      "epsilon: 0.8822202429488013\n",
      "epsilon: 0.8778091417340573\n",
      "epsilon: 0.8734200960253871\n",
      "epsilon: 0.8690529955452602\n",
      "epsilon: 0.8647077305675338\n",
      "epsilon: 0.8603841919146962\n",
      "epsilon: 0.8560822709551227\n",
      "epsilon: 0.851801859600347\n",
      "epsilon: 0.8475428503023453\n",
      "epsilon: 0.8433051360508336\n",
      "epsilon: 0.8390886103705794\n",
      "epsilon: 0.8348931673187264\n",
      "epsilon: 0.8307187014821328\n",
      "epsilon: 0.8265651079747222\n",
      "epsilon: 0.8224322824348486\n",
      "epsilon: 0.8183201210226743\n",
      "epsilon: 0.8142285204175609\n",
      "epsilon: 0.810157377815473\n",
      "epsilon: 0.8061065909263957\n",
      "epsilon: 0.8020760579717637\n",
      "epsilon: 0.798065677681905\n",
      "epsilon: 0.7940753492934954\n",
      "epsilon: 0.7901049725470279\n",
      "epsilon: 0.7861544476842928\n",
      "epsilon: 0.7822236754458713\n",
      "epsilon: 0.778312557068642\n",
      "epsilon: 0.7744209942832988\n",
      "epsilon: 0.7705488893118823\n",
      "epsilon: 0.7666961448653229\n",
      "epsilon: 0.7628626641409962\n",
      "epsilon: 0.7590483508202912\n",
      "epsilon: 0.7552531090661897\n",
      "epsilon: 0.7514768435208588\n",
      "epsilon: 0.7477194593032545\n",
      "epsilon: 0.7439808620067382\n",
      "epsilon: 0.7402609576967045\n",
      "epsilon: 0.736559652908221\n",
      "epsilon: 0.7328768546436799\n",
      "epsilon: 0.7292124703704616\n",
      "epsilon: 0.7255664080186093\n",
      "epsilon: 0.7219385759785162\n",
      "epsilon: 0.7183288830986236\n",
      "epsilon: 0.7147372386831305\n",
      "epsilon: 0.7111635524897149\n",
      "epsilon: 0.7076077347272662\n",
      "epsilon: 0.7040696960536299\n",
      "epsilon: 0.7005493475733617\n",
      "epsilon: 0.697046600835495\n",
      "epsilon: 0.6935613678313175\n",
      "epsilon: 0.6900935609921609\n",
      "epsilon: 0.6866430931872001\n",
      "epsilon: 0.6832098777212641\n",
      "epsilon: 0.6797938283326578\n",
      "epsilon: 0.6763948591909945\n",
      "epsilon: 0.6730128848950395\n",
      "epsilon: 0.6696478204705644\n",
      "epsilon: 0.6662995813682115\n",
      "epsilon: 0.6629680834613705\n",
      "epsilon: 0.6596532430440636\n",
      "epsilon: 0.6563549768288433\n",
      "epsilon: 0.653073201944699\n",
      "epsilon: 0.6498078359349755\n",
      "epsilon: 0.6465587967553006\n",
      "epsilon: 0.6433260027715241\n",
      "epsilon: 0.6401093727576664\n",
      "epsilon: 0.6369088258938781\n",
      "epsilon: 0.6337242817644086\n",
      "epsilon: 0.6305556603555866\n",
      "epsilon: 0.6274028820538087\n",
      "epsilon: 0.6242658676435396\n",
      "epsilon: 0.6211445383053219\n",
      "epsilon: 0.6180388156137953\n",
      "epsilon: 0.6149486215357263\n",
      "epsilon: 0.6118738784280476\n",
      "epsilon: 0.6088145090359074\n",
      "epsilon: 0.6057704364907278\n",
      "epsilon: 0.6027415843082742\n",
      "epsilon: 0.5997278763867329\n",
      "epsilon: 0.5967292370047992\n",
      "epsilon: 0.5937455908197752\n",
      "epsilon: 0.5907768628656763\n",
      "epsilon: 0.5878229785513479\n",
      "epsilon: 0.5848838636585911\n",
      "epsilon: 0.5819594443402982\n",
      "epsilon: 0.5790496471185967\n",
      "epsilon: 0.5761543988830038\n",
      "epsilon: 0.5732736268885887\n",
      "epsilon: 0.5704072587541458\n",
      "epsilon: 0.567555222460375\n",
      "epsilon: 0.5647174463480732\n",
      "epsilon: 0.5618938591163328\n",
      "epsilon: 0.5590843898207511\n",
      "epsilon: 0.5562889678716474\n",
      "epsilon: 0.5535075230322891\n",
      "epsilon: 0.5507399854171277\n",
      "epsilon: 0.547986285490042\n",
      "epsilon: 0.5452463540625918\n",
      "epsilon: 0.5425201222922789\n",
      "epsilon: 0.5398075216808175\n",
      "epsilon: 0.5371084840724134\n",
      "epsilon: 0.5344229416520513\n",
      "epsilon: 0.531750826943791\n",
      "epsilon: 0.5290920728090721\n",
      "epsilon: 0.5264466124450268\n",
      "epsilon: 0.5238143793828016\n",
      "epsilon: 0.5211953074858876\n",
      "epsilon: 0.5185893309484582\n",
      "epsilon: 0.5159963842937159\n",
      "epsilon: 0.5134164023722473\n",
      "epsilon: 0.510849320360386\n",
      "epsilon: 0.5082950737585841\n",
      "epsilon: 0.5057535983897912\n",
      "epsilon: 0.5032248303978422\n",
      "epsilon: 0.500708706245853\n",
      "epsilon: 0.4982051627146237\n",
      "epsilon: 0.49571413690105054\n",
      "epsilon: 0.4932355662165453\n",
      "epsilon: 0.4907693883854626\n",
      "epsilon: 0.4883155414435353\n",
      "epsilon: 0.4858739637363176\n",
      "epsilon: 0.483444593917636\n",
      "epsilon: 0.4810273709480478\n",
      "epsilon: 0.47862223409330756\n",
      "epsilon: 0.47622912292284103\n",
      "epsilon: 0.4738479773082268\n",
      "epsilon: 0.47147873742168567\n",
      "epsilon: 0.46912134373457726\n",
      "epsilon: 0.46677573701590436\n",
      "epsilon: 0.46444185833082485\n",
      "epsilon: 0.46211964903917074\n",
      "epsilon: 0.4598090507939749\n",
      "epsilon: 0.457510005540005\n",
      "epsilon: 0.45522245551230495\n",
      "epsilon: 0.4529463432347434\n",
      "epsilon: 0.4506816115185697\n",
      "epsilon: 0.4484282034609769\n",
      "epsilon: 0.446186062443672\n",
      "epsilon: 0.4439551321314536\n",
      "epsilon: 0.4417353564707963\n",
      "epsilon: 0.43952667968844233\n",
      "epsilon: 0.43732904629000013\n",
      "epsilon: 0.4351424010585501\n",
      "epsilon: 0.43296668905325736\n",
      "epsilon: 0.43080185560799106\n",
      "epsilon: 0.4286478463299511\n",
      "epsilon: 0.42650460709830135\n",
      "epsilon: 0.42437208406280985\n",
      "epsilon: 0.4222502236424958\n",
      "epsilon: 0.42013897252428334\n",
      "epsilon: 0.4180382776616619\n",
      "epsilon: 0.4159480862733536\n",
      "epsilon: 0.41386834584198684\n",
      "epsilon: 0.4117990041127769\n",
      "epsilon: 0.40974000909221303\n",
      "epsilon: 0.40769130904675194\n",
      "epsilon: 0.40565285250151817\n",
      "epsilon: 0.4036245882390106\n",
      "epsilon: 0.4016064652978155\n",
      "epsilon: 0.3995984329713264\n",
      "epsilon: 0.3976004408064698\n",
      "epsilon: 0.39561243860243744\n",
      "epsilon: 0.3936343764094253\n",
      "epsilon: 0.39166620452737816\n",
      "epsilon: 0.3897078735047413\n",
      "epsilon: 0.3877593341372176\n",
      "epsilon: 0.3858205374665315\n",
      "epsilon: 0.38389143477919885\n",
      "epsilon: 0.3819719776053028\n",
      "epsilon: 0.3800621177172763\n",
      "epsilon: 0.37816180712868996\n",
      "epsilon: 0.37627099809304654\n",
      "epsilon: 0.3743896431025813\n",
      "epsilon: 0.37251769488706843\n",
      "epsilon: 0.3706551064126331\n",
      "epsilon: 0.36880183088056995\n",
      "epsilon: 0.3669578217261671\n",
      "epsilon: 0.36512303261753626\n",
      "Finished! | Return: -1294.4558682277261 | average reward: -6.472279341138631\n",
      "Episode 6\n",
      "epsilon: 0.3632974174544486\n",
      "epsilon: 0.3614809303671764\n",
      "epsilon: 0.3596735257153405\n",
      "epsilon: 0.3578751580867638\n",
      "epsilon: 0.35608578229633\n",
      "epsilon: 0.3543053533848483\n",
      "epsilon: 0.35253382661792404\n",
      "epsilon: 0.3507711574848344\n",
      "epsilon: 0.34901730169741024\n",
      "epsilon: 0.3472722151889232\n",
      "epsilon: 0.3455358541129786\n",
      "epsilon: 0.3438081748424137\n",
      "epsilon: 0.3420891339682016\n",
      "epsilon: 0.3403786882983606\n",
      "epsilon: 0.3386767948568688\n",
      "epsilon: 0.33698341088258443\n",
      "epsilon: 0.3352984938281715\n",
      "epsilon: 0.33362200135903064\n",
      "epsilon: 0.33195389135223546\n",
      "epsilon: 0.3302941218954743\n",
      "epsilon: 0.32864265128599696\n",
      "epsilon: 0.326999438029567\n",
      "epsilon: 0.3253644408394192\n",
      "epsilon: 0.3237376186352221\n",
      "epsilon: 0.322118930542046\n",
      "epsilon: 0.32050833588933575\n",
      "epsilon: 0.31890579420988907\n",
      "epsilon: 0.3173112652388396\n",
      "epsilon: 0.3157247089126454\n",
      "epsilon: 0.3141460853680822\n",
      "epsilon: 0.3125753549412418\n",
      "epsilon: 0.31101247816653554\n",
      "epsilon: 0.30945741577570285\n",
      "epsilon: 0.3079101286968243\n",
      "epsilon: 0.3063705780533402\n",
      "epsilon: 0.30483872516307353\n",
      "epsilon: 0.3033145315372582\n",
      "epsilon: 0.3017979588795719\n",
      "epsilon: 0.30028896908517405\n",
      "epsilon: 0.2987875242397482\n",
      "epsilon: 0.29729358661854943\n",
      "epsilon: 0.29580711868545667\n",
      "epsilon: 0.2943280830920294\n",
      "epsilon: 0.29285644267656924\n",
      "epsilon: 0.2913921604631864\n",
      "epsilon: 0.28993519966087045\n",
      "epsilon: 0.2884855236625661\n",
      "epsilon: 0.28704309604425327\n",
      "epsilon: 0.285607880564032\n",
      "epsilon: 0.28417984116121187\n",
      "epsilon: 0.2827589419554058\n",
      "epsilon: 0.28134514724562876\n",
      "epsilon: 0.2799384215094006\n",
      "epsilon: 0.27853872940185365\n",
      "epsilon: 0.27714603575484437\n",
      "epsilon: 0.2757603055760701\n",
      "epsilon: 0.2743815040481898\n",
      "epsilon: 0.2730095965279488\n",
      "epsilon: 0.27164454854530906\n",
      "epsilon: 0.2702863258025825\n",
      "epsilon: 0.2689348941735696\n",
      "epsilon: 0.26759021970270175\n",
      "epsilon: 0.2662522686041882\n",
      "epsilon: 0.2649210072611673\n",
      "epsilon: 0.26359640222486147\n",
      "epsilon: 0.26227842021373715\n",
      "epsilon: 0.2609670281126685\n",
      "epsilon: 0.25966219297210513\n",
      "epsilon: 0.2583638820072446\n",
      "epsilon: 0.2570720625972084\n",
      "epsilon: 0.25578670228422234\n",
      "epsilon: 0.25450776877280124\n",
      "epsilon: 0.2532352299289372\n",
      "epsilon: 0.2519690537792925\n",
      "epsilon: 0.2507092085103961\n",
      "epsilon: 0.2494556624678441\n",
      "epsilon: 0.24820838415550486\n",
      "epsilon: 0.24696734223472733\n",
      "epsilon: 0.2457325055235537\n",
      "epsilon: 0.24450384299593592\n",
      "epsilon: 0.24328132378095624\n",
      "epsilon: 0.24206491716205145\n",
      "epsilon: 0.2408545925762412\n",
      "epsilon: 0.23965031961336\n",
      "epsilon: 0.2384520680152932\n",
      "epsilon: 0.23725980767521673\n",
      "epsilon: 0.23607350863684065\n",
      "epsilon: 0.23489314109365644\n",
      "epsilon: 0.23371867538818816\n",
      "epsilon: 0.23255008201124722\n",
      "epsilon: 0.231387331601191\n",
      "epsilon: 0.23023039494318503\n",
      "epsilon: 0.2290792429684691\n",
      "epsilon: 0.22793384675362674\n",
      "epsilon: 0.22679417751985861\n",
      "epsilon: 0.22566020663225933\n",
      "epsilon: 0.22453190559909803\n",
      "epsilon: 0.22340924607110255\n",
      "epsilon: 0.22229219984074702\n",
      "epsilon: 0.2211807388415433\n",
      "epsilon: 0.22007483514733558\n",
      "epsilon: 0.2189744609715989\n",
      "epsilon: 0.2178795886667409\n",
      "epsilon: 0.2167901907234072\n",
      "epsilon: 0.21570623976979014\n",
      "epsilon: 0.21462770857094118\n",
      "epsilon: 0.21355457002808648\n",
      "epsilon: 0.21248679717794605\n",
      "epsilon: 0.21142436319205632\n",
      "epsilon: 0.21036724137609603\n",
      "epsilon: 0.20931540516921554\n",
      "epsilon: 0.20826882814336947\n",
      "epsilon: 0.20722748400265262\n",
      "epsilon: 0.20619134658263935\n",
      "epsilon: 0.20516038984972615\n",
      "epsilon: 0.2041345879004775\n",
      "epsilon: 0.2031139149609751\n",
      "epsilon: 0.20209834538617025\n",
      "epsilon: 0.2010878536592394\n",
      "epsilon: 0.2000824143909432\n",
      "epsilon: 0.19908200231898848\n",
      "epsilon: 0.19808659230739353\n",
      "epsilon: 0.19709615934585656\n",
      "epsilon: 0.19611067854912728\n",
      "epsilon: 0.19513012515638165\n",
      "epsilon: 0.19415447453059972\n",
      "epsilon: 0.19318370215794672\n",
      "epsilon: 0.192217783647157\n",
      "epsilon: 0.1912566947289212\n",
      "epsilon: 0.1903004112552766\n",
      "epsilon: 0.18934890919900021\n",
      "epsilon: 0.18840216465300522\n",
      "epsilon: 0.18746015382974018\n",
      "epsilon: 0.1865228530605915\n",
      "epsilon: 0.18559023879528855\n",
      "epsilon: 0.1846622876013121\n",
      "epsilon: 0.18373897616330553\n",
      "epsilon: 0.182820281282489\n",
      "epsilon: 0.18190617987607657\n",
      "epsilon: 0.18099664897669618\n",
      "epsilon: 0.1800916657318127\n",
      "epsilon: 0.17919120740315364\n",
      "epsilon: 0.17829525136613786\n",
      "epsilon: 0.17740377510930716\n",
      "epsilon: 0.17651675623376062\n",
      "epsilon: 0.1756341724525918\n",
      "epsilon: 0.17475600159032884\n",
      "epsilon: 0.17388222158237718\n",
      "epsilon: 0.1730128104744653\n",
      "epsilon: 0.17214774642209296\n",
      "epsilon: 0.1712870076899825\n",
      "epsilon: 0.17043057265153258\n",
      "epsilon: 0.16957841978827493\n",
      "epsilon: 0.16873052768933355\n",
      "epsilon: 0.1678868750508869\n",
      "epsilon: 0.16704744067563246\n",
      "epsilon: 0.1662122034722543\n",
      "epsilon: 0.16538114245489302\n",
      "epsilon: 0.16455423674261854\n",
      "epsilon: 0.16373146555890544\n",
      "epsilon: 0.16291280823111093\n",
      "epsilon: 0.16209824418995536\n",
      "epsilon: 0.16128775296900558\n",
      "epsilon: 0.16048131420416054\n",
      "epsilon: 0.15967890763313974\n",
      "epsilon: 0.15888051309497406\n",
      "epsilon: 0.1580861105294992\n",
      "epsilon: 0.1572956799768517\n",
      "epsilon: 0.15650920157696743\n",
      "epsilon: 0.1557266555690826\n",
      "epsilon: 0.1549480222912372\n",
      "epsilon: 0.15417328217978102\n",
      "epsilon: 0.1534024157688821\n",
      "epsilon: 0.1526354036900377\n",
      "epsilon: 0.1518722266715875\n",
      "epsilon: 0.15111286553822956\n",
      "epsilon: 0.15035730121053842\n",
      "epsilon: 0.14960551470448571\n",
      "epsilon: 0.14885748713096328\n",
      "epsilon: 0.14811319969530845\n",
      "epsilon: 0.1473726336968319\n",
      "epsilon: 0.14663577052834775\n",
      "epsilon: 0.14590259167570602\n",
      "epsilon: 0.1451730787173275\n",
      "epsilon: 0.14444721332374086\n",
      "epsilon: 0.14372497725712216\n",
      "epsilon: 0.14300635237083656\n",
      "epsilon: 0.14229132060898236\n",
      "epsilon: 0.14157986400593744\n",
      "epsilon: 0.14087196468590776\n",
      "epsilon: 0.14016760486247823\n",
      "epsilon: 0.13946676683816583\n",
      "epsilon: 0.138769433003975\n",
      "epsilon: 0.13807558583895513\n",
      "epsilon: 0.13738520790976036\n",
      "epsilon: 0.13669828187021155\n",
      "epsilon: 0.13601479046086049\n",
      "epsilon: 0.1353347165085562\n",
      "epsilon: 0.1346580429260134\n",
      "epsilon: 0.13398475271138335\n",
      "Finished! | Return: -1254.6640574142039 | average reward: -6.273320287071019\n",
      "Episode 7\n",
      "epsilon: 0.13331482894782642\n",
      "epsilon: 0.13264825480308728\n",
      "epsilon: 0.13198501352907185\n",
      "epsilon: 0.1313250884614265\n",
      "epsilon: 0.13066846301911936\n",
      "epsilon: 0.13001512070402377\n",
      "epsilon: 0.12936504510050365\n",
      "epsilon: 0.12871821987500112\n",
      "epsilon: 0.12807462877562611\n",
      "epsilon: 0.12743425563174798\n",
      "epsilon: 0.12679708435358925\n",
      "epsilon: 0.1261630989318213\n",
      "epsilon: 0.1255322834371622\n",
      "epsilon: 0.12490462201997637\n",
      "epsilon: 0.1242800989098765\n",
      "epsilon: 0.12365869841532712\n",
      "epsilon: 0.12304040492325048\n",
      "epsilon: 0.12242520289863423\n",
      "epsilon: 0.12181307688414106\n",
      "epsilon: 0.12120401149972035\n",
      "epsilon: 0.12059799144222175\n",
      "epsilon: 0.11999500148501063\n",
      "epsilon: 0.11939502647758558\n",
      "epsilon: 0.11879805134519765\n",
      "epsilon: 0.11820406108847166\n",
      "epsilon: 0.1176130407830293\n",
      "epsilon: 0.11702497557911415\n",
      "epsilon: 0.11643985070121858\n",
      "epsilon: 0.11585765144771248\n",
      "epsilon: 0.11527836319047392\n",
      "epsilon: 0.11470197137452155\n",
      "epsilon: 0.11412846151764894\n",
      "epsilon: 0.1135578192100607\n",
      "epsilon: 0.11299003011401039\n",
      "epsilon: 0.11242507996344034\n",
      "epsilon: 0.11186295456362313\n",
      "epsilon: 0.11130363979080501\n",
      "epsilon: 0.11074712159185099\n",
      "epsilon: 0.11019338598389174\n",
      "epsilon: 0.10964241905397228\n",
      "epsilon: 0.10909420695870241\n",
      "epsilon: 0.1085487359239089\n",
      "epsilon: 0.10800599224428936\n",
      "epsilon: 0.10746596228306791\n",
      "epsilon: 0.10692863247165257\n",
      "epsilon: 0.1063939893092943\n",
      "epsilon: 0.10586201936274783\n",
      "epsilon: 0.10533270926593409\n",
      "epsilon: 0.10480604571960442\n",
      "epsilon: 0.1042820154910064\n",
      "epsilon: 0.10376060541355137\n",
      "epsilon: 0.1032418023864836\n",
      "epsilon: 0.10272559337455119\n",
      "epsilon: 0.10221196540767843\n",
      "epsilon: 0.10170090558064004\n",
      "epsilon: 0.10119240105273684\n",
      "epsilon: 0.10068643904747315\n",
      "epsilon: 0.10018300685223579\n",
      "epsilon: 0.0996820918179746\n",
      "Finished! | Return: -1191.8073706137714 | average reward: -5.959036853068857\n",
      "Episode 8\n",
      "Finished! | Return: -1154.1257918629303 | average reward: -5.770628959314652\n",
      "Episode 9\n",
      "Finished! | Return: -1522.0358985335477 | average reward: -7.610179492667738\n",
      "Test Rewards: [[-2.1230821880379698, -2.476667010723805, -3.171704939183213, -4.193603396333392, -5.380440492924093, -6.83189619856732, -8.401391326511757, -10.191571671237442, -11.783981740997397, -12.084011492384063, -10.369544235228728, -8.823488157595717, -7.485136587243547, -6.162706249810986, -5.010002438969513, -4.077718635782584, -3.175388397115664, -2.6349690872530136, -2.3619653604356663, -2.302911372907874, -2.4513340395925267, -2.7661307766704066, -3.390221073912573, -4.330201854465575, -5.539606807076132, -7.131803309963037, -8.865532872558981, -10.475826994869273, -12.614037616506424, -11.894096701473407, -10.021457329007156, -8.286371793349932, -6.928946432374311, -5.631064310305666, -4.498781133762407, -3.4065709530099006, -2.7865161594099477, -2.4089504549500482, -2.161759389378854, -2.078804545921758, -2.1831564182937577, -2.440823925295614, -3.10463519835225, -4.042337066943801, -5.394237028203186, -6.881874991551686, -8.727661222391012, -11.12665272212293, -13.076858413669882, -12.408503004078474, -10.62377644118249, -8.66404990967778, -6.831568941953536, -5.445328980820204, -4.277267098744572, -3.3667584686769354, -2.5418557583146253, -1.865677820788533, -1.4324792659448369, -1.256146563749757, -1.2034922200213527, -1.2355681367097702, -1.4557746300090373, -1.9663666012998444, -2.6046978976400057, -3.7208614624845695, -4.851343638164023, -6.571632272816006, -8.659960051539647, -10.451243692515217, -13.0606646104944, -13.635787919964992, -11.442383499023688, -9.301817452441774, -7.6579926239018645, -6.182261541363553, -4.5571815722728255, -3.2156577479989914, -2.5102055774048835, -1.9433873617193116, -1.4099572033582604, -1.1389670902734768, -0.9378051998057698, -0.8106762602755975, -0.7849566093794857, -0.8531771606366508, -1.0516364880489943, -1.457564356057102, -2.1480281826741354, -2.917471782042752, -3.9379724428361995, -5.565222167572961, -7.147095348378819, -8.817243520549532, -10.66813907357401, -12.578703861855313, -12.877398040358537, -10.782082421992161, -9.254926406925266, -7.606088616772453, -5.8948947016445405, -4.570647524993549, -3.6051899962721827, -2.7752607159873426, -2.1710033415355654, -1.7955594557106673, -1.6941534005879457, -1.7908827808666488, -2.1083946399227864, -2.571611963799055, -3.3987210352176738, -4.21750170928851, -5.606604369067877, -7.062622025668043, -8.894994202097049, -10.694770512035857, -12.794949016085692, -12.287742286033613, -10.636460611285932, -8.788258693034779, -7.099035237896042, -5.337780085281624, -4.137283346521478, -3.292590774627582, -2.5639801465847873, -1.9385933911608404, -1.5394203458991602, -1.4358023612883435, -1.4878377821037754, -1.715015019909909, -2.122880228191497, -2.630250509373803, -3.4325866583716573, -4.6169834861322165, -6.107664177224888, -7.689297533496057, -9.390766688670983, -11.659724128534709, -13.483223021869682, -11.777131187459004, -9.949022730149883, -7.920359297310701, -6.335685099497524, -4.88732201406693, -3.822922664168171, -3.084819216805994, -2.5234400619927673, -2.2314943162070096, -2.228743658376746, -2.5712482337132294, -3.064181997085714, -3.703527966787127, -4.565762256022122, -5.867355695700545, -7.252631111817909, -8.688009944727717, -10.44779197632212, -12.151356286112781, -11.377630413575298, -9.993867279187707, -8.415479296883449, -7.1119588913623515, -5.565793385696729, -4.534163739829538, -3.767373825123633, -3.13216678078144, -2.647712969040837, -2.2753633029981217, -2.173749672633864, -2.2966501409181728, -2.655108799346817, -3.298644933052356, -4.057913292287609, -5.203346254455815, -6.755685714128746, -8.247332556353081, -9.827921275449803, -11.302055260320802, -11.96513401774901, -10.51298902017169, -9.007992233459673, -7.46657827479844, -6.160169422298753, -5.105619195503296, -4.229607372243441, -3.7265881647004107, -3.4069996139110903, -3.2322698068775577, -3.2631332726961535, -3.619811777148554, -4.331884376563622, -5.10255824541138, -6.342254392424138, -7.480293993129507, -8.96415785113332, -10.886619332037117, -12.432852604782536, -11.019304220703637, -9.431988521682044, -7.812214249729305], [-5.948097659154959, -6.31594560836893, -7.045544566929719, -7.9751613661693765, -8.961628906403579, -10.06492723674161, -10.716307298581306, -9.66564925898648, -8.857670994285535, -7.897475007901848, -7.140128348568985, -6.455018102119034, -5.923786968199011, -5.571450013004202, -5.460410630892789, -5.5160992163568325, -5.7066906152224695, -6.203029529344735, -6.896889770785366, -7.763910993957431, -8.951174644463771, -9.836878417856981, -10.934271349347513, -9.97109521496865, -8.95347528367224, -8.026102071336492, -7.07564836965851, -6.238071193167317, -5.408669886113155, -4.837158232569916, -4.410885844526654, -4.299054101228219, -4.346372686165641, -4.521394226493163, -4.818023317369813, -5.303999537470983, -6.196111392793876, -7.155129127426032, -8.443791962893618, -9.802551868139712, -11.005056664971276, -10.77518625466326, -9.343314859888766, -8.237644961570716, -7.170060050834287, -6.254342008907798, -5.406632284650117, -4.49784693055954, -3.9376336525133016, -3.6935810883183913, -3.705983761133408, -3.8850476749551577, -4.38400019576072, -5.292076691262096, -6.4457679514697865, -7.623905433494627, -8.971975669805149, -10.629836319786863, -11.999036976078948, -10.54497286274089, -9.227377209779155, -7.603479424003664, -6.246125911675354, -5.174438027550261, -4.507845628997551, -3.9045876868755065, -3.5448983214409613, -3.4226879914090333, -3.5435399725965215, -3.8826895841363993, -4.453383284093586, -5.227761330138325, -6.331400612465712, -7.608527690536606, -8.858158712972228, -10.146243113968916, -11.860267611187576, -10.549661581532916, -9.202355553012316, -7.919685419821985, -6.849153325720086, -5.765687802694777, -4.952888987770395, -4.146186830862398, -3.738193904822603, -3.4622435094310524, -3.410597268821337, -3.6355294542178225, -4.1942809350699095, -5.060319276801367, -5.944506537704096, -7.3666207505954455, -8.517546015916736, -9.980429917520956, -11.854681534245746, -10.914709369854446, -9.395677506522034, -7.964658076968137, -6.858235584526167, -5.858109601627031, -5.12688044260327, -4.474949570689194, -3.944458937605186, -3.6613099556110136, -3.585709082254988, -3.7319050780570397, -4.178370088004249, -4.83161583725403, -5.6229554503364385, -6.815812450637374, -8.049010624143719, -9.316056066476206, -10.682029314921312, -11.224900836582508, -10.023517540647232, -8.664032566785975, -7.600855127151384, -6.630311095535257, -5.709455995181291, -4.947948875593197, -4.380661660185811, -4.075467320044337, -4.053813763444036, -4.316510456704933, -4.689476011330715, -5.151383378269612, -5.888110316166216, -7.040010778665974, -8.273665055093872, -9.565941781450809, -10.65518108674936, -10.994098810145363, -9.886662322831466, -8.418324773252417, -7.317081602107553, -6.251730696341701, -5.317364000876848, -4.615690391296915, -4.211594726595382, -3.9337309068822255, -3.7847349740859397, -3.8654116326336503, -4.259698837467116, -4.939481295832625, -5.946569298282505, -6.855122162869713, -7.899201864699158, -9.220274069677206, -10.911524019233866, -11.167907036888062, -9.84354864386131, -8.623897654167633, -7.610352048333355, -6.472529271931396, -5.654798951293528, -4.892186570375865, -4.332072812506739, -3.8896136468403424, -3.7259862415888043, -3.7871393948571748, -4.015660325864907, -4.54689508885155, -5.227755289359777, -5.941906029170555, -7.052485650580578, -8.373461821990198, -9.7539453027668, -11.308055429236301, -11.043152196594514, -9.523798300752064, -8.169126640513404, -7.060577319473797, -6.040188837796354, -5.027643373456889, -4.4089631133974505, -3.9655035485204144, -3.871903002532351, -3.9684568503786117, -4.33560881693643, -4.990208515371531, -5.907099018905285, -7.199352766247063, -8.72861223860552, -9.915553199588318, -11.360440701536515, -10.962748010138803, -9.645572554249634, -8.093599926754008, -6.932826711014662, -5.763271350158985, -4.892044243827061, -4.2829061826829475, -3.982145928052649, -3.8903420054849827, -3.9780531724059567, -4.4197413263182055, -4.916707655891974, -5.746688209274133, -6.861433825171696, -8.178173232239596], [-1.8511212108804722, -2.1152242583016023, -2.603484838473816, -3.278988403535417, -4.1847837926894735, -5.522880238692851, -7.056317629223888, -8.777555521324787, -11.074372357700431, -13.65569015788678, -12.660657668309893, -10.362164600371736, -8.353858377408867, -6.61752759836679, -5.101296048473608, -4.029291044475629, -3.1657067892081594, -2.485061040588279, -1.8643893981952835, -1.4709297875183622, -1.2817137050962624, -1.270683685440111, -1.5395750127637882, -2.005261876690456, -2.7835878832720664, -3.79805661867767, -4.987278073951105, -6.3456127804496285, -8.403310807627046, -10.822271631713093, -13.479878167764632, -13.558831957280727, -11.688629549209738, -9.84746636726891, -7.545001643713345, -5.982604556645239, -4.604129997421944, -3.3852305919622845, -2.3888054825711404, -1.5953552937490645, -1.1475899001664471, -0.8402025439162247, -0.6061068203740134, -0.4888622438606366, -0.39742956443012567, -0.4263622682205274, -0.5724257230916562, -0.7207147898097332, -0.9202457121823646, -1.456226153701714, -1.960191912124167, -2.918634677721767, -3.9408931580267774, -5.753285952247837, -7.312529647783219, -9.252151020481833, -11.537069172333748, -13.609883602827807, -13.585374458233096, -11.367659429908677, -9.349472813283734, -7.513797252832457, -5.703040567308115, -4.43549673849348, -3.1320408687996175, -2.134396406993545, -1.4733088255309323, -1.0213358455665407, -0.8483807614679245, -0.7156475636095506, -0.7178943488496189, -0.7765920847198888, -0.9236163593681181, -1.175606505158896, -1.7329254991029808, -2.482448800345725, -3.450123340751182, -4.677164831839231, -6.2864093433022346, -7.982291207273055, -9.877409184130578, -12.00869160286078, -13.931547013340813, -12.213881943640661, -10.537122302412751, -8.552685863620994, -6.513691006572106, -4.802045513730084, -3.746063049068853, -2.894377484259202, -2.126756754415253, -1.6774519839541129, -1.2917443916541544, -1.0687150733239708, -1.0896281076451226, -1.2526794094089815, -1.6838548276304917, -2.2522030106078073, -3.1966581567114236, -4.117473126722027, -5.558959480967969, -7.244813276978496, -9.202382386800368, -11.456595623238798, -13.506377526531367, -12.61504181815374, -10.745140122039782, -8.751190953605418, -6.860365512523048, -5.366768961602062, -4.134992860922886, -3.1739721763653104, -2.346737213953712, -1.7641182290232031, -1.4498477991336718, -1.2724664225628348, -1.1777138783096939, -1.149301186987395, -1.2225197896547315, -1.3790832723921298, -1.7265617543804586, -2.353869864429288, -3.1163423162096504, -4.323697043708762, -5.490399193084974, -7.033276920827372, -9.186130438927021, -11.22819671503526, -13.624702713309343, -12.70091193075312, -10.986254322735281, -8.73664444823983, -7.159954784008743, -5.74233557610285, -4.34076067433608, -3.278805779242316, -2.448507526693773, -1.8630796123756408, -1.1826874129317333, -0.8594973404415586, -0.5687570258055942, -0.4671551923392151, -0.40137000529110334, -0.39415962514006847, -0.5016479232693668, -0.7346731328088452, -0.9268490543645422, -1.2224647674157936, -1.643744351530337, -2.2566260844010912, -3.2691797493672627, -4.501876100497448, -6.073078066893324, -7.829513902402921, -9.67723498952677, -11.891087750643628, -13.761858369702294, -12.443545406022263, -10.669020192818701, -8.878465353217022, -7.168820514374424, -5.702769346645278, -4.405229881715895, -3.023069662937464, -2.2990784696357145, -1.5428312873106487, -1.1402424245695997, -0.7929945744113109, -0.5992532676360812, -0.5097837918851577, -0.505651748423526, -0.5247802296424413, -0.6896974787310229, -1.0465499356272403, -1.3617704322008284, -2.05793424687075, -2.9087401846860224, -4.356650954301758, -6.110562334126011, -8.275005530772953, -10.788286189615679, -13.73507630850058, -15.774515533624763, -13.482712271733918, -11.190934387069648, -8.617684777611265, -6.554928332029478, -4.799656847030406, -3.276504996553131, -2.470174151727217, -1.756028322709928, -1.3177984181825388, -0.8021977292965976, -0.6180472935785997, -0.3618653508033708, -0.3288924545771518, -0.32751016835892677, -0.38369389300781087, -0.36741074304237664, -0.3930391072684204], [-4.0518000701175, -4.355628508833538, -4.890413190166138, -5.848745143154957, -7.06967865673471, -8.47943347664248, -10.008257508242043, -11.386788271798997, -10.929556094907634, -9.74916776440985, -8.214465057260895, -6.916201936523462, -5.9450768717180695, -4.893535902983405, -4.299468464267352, -3.780869977238735, -3.5923457913890973, -3.742215923333901, -4.123227281219142, -4.835521378754802, -5.8159010716386375, -6.995691687329774, -8.6158731691763, -10.211284064320289, -11.67879767108244, -11.203352169933824, -9.650372050929711, -8.290810009482225, -7.029527143207202, -5.898591274421595, -4.714322875451945, -3.7563219981399354, -3.1034413738430238, -2.7996258899434547, -2.7584157787904164, -2.913348324869101, -3.23323788928074, -3.722251699441177, -4.38436967075201, -5.426440899152282, -6.661444463353689, -8.370247858316372, -10.234630354442935, -12.098241884853453, -11.769538850682043, -10.036613430525907, -8.562339703819152, -6.868346844141276, -5.685528706840766, -4.653842168704421, -3.814449914324757, -3.1091291530422374, -2.715196150776707, -2.55680316056664, -2.617998039531077, -3.026246009048534, -3.7168448561705723, -4.722275245036719, -5.953664204060657, -7.259431445741804, -8.638063565224776, -10.014062177174695, -11.360766952519102, -11.312498887937815, -9.80544336025616, -8.372079537211762, -7.048219108429753, -5.97994430440785, -5.063575901795212, -4.509716585120279, -4.133475595059582, -3.941689399792582, -3.923765552857326, -4.10540333538852, -4.55307594014736, -5.222732521663827, -6.214802064690352, -7.546529543386389, -8.636652799514637, -9.904477759243845, -11.375636228086135, -10.675920595731384, -9.414305720125078, -8.202578912046409, -6.9170756794771036, -5.737325325041594, -4.959825963036295, -4.35513307881335, -3.999969595419931, -3.9556225525268816, -4.072367185690755, -4.515708398709025, -5.065968923793451, -5.81977789052118, -6.977755839106693, -8.045354512280438, -9.624996007297991, -10.991164848609007, -11.009838807932024, -9.827736937920626, -8.443760471245403, -7.134337703619238, -6.159884588005144, -5.3807867213243465, -4.8116747321774245, -4.4311712443848466, -4.150331141911344, -4.014942006727504, -4.130823142007943, -4.525830883064336, -5.084049630925239, -5.7245463883272745, -6.681200934300388, -7.54255373820081, -8.770500333263335, -10.198724941735247, -11.533314831185349, -10.377553688553425, -8.961518062023442, -7.818505604622308, -6.5444525938898375, -5.642252818883966, -4.967143541093906, -4.397184588020847, -3.9988869909227485, -3.8295287002947407, -3.864675492315643, -4.014223520916364, -4.480889183042815, -5.327290475976039, -6.420624757713497, -7.424365964934336, -8.80609525163735, -10.271272326454305, -11.90253158427639, -10.596859428023366, -9.09336541792667, -7.714467025270352, -6.702535923136646, -5.796564617005123, -4.862420075142258, -4.198909555696911, -3.904183158048105, -3.897537687086072, -4.207602480865564, -4.844621973751257, -5.474955913718867, -6.566747399637587, -7.938324992204575, -9.31683972985657, -10.974466351821464, -11.650273736529766, -10.12458681593401, -8.745339304611376, -7.556693406677769, -6.255016338242946, -5.000916577772665, -4.181637457496971, -3.6038840565375048, -3.142246404487792, -2.8729284657318326, -2.7671967544602456, -2.9006335229774853, -3.2406203978788013, -3.942370172382124, -4.940767278235091, -6.048429586178961, -7.594760156335751, -8.94673666704315, -10.654197913027831, -12.244707793610656, -11.092994038740978, -9.545302187051814, -7.981502028091701, -6.641798488935259, -5.518265922919492, -4.391789403464173, -3.6745537703943176, -3.056698357350222, -2.722943162052687, -2.6354954486819677, -2.7621218830785654, -3.108649689169541, -3.875113165556528, -4.926481443319206, -5.914174302746095, -7.517443614042624, -8.97271036383957, -10.475800897358134, -12.452277464681263, -11.005233805409226, -9.361429000272981, -7.983628884412263, -6.538318747172031, -5.5512284750279095, -4.631167344558444, -4.053848871808976, -3.6687862731335357, -3.5480706246059204, -3.715492692064998], [-1.1212154776314913, -1.1055779703839117, -1.1899323730115228, -1.3844017010796068, -1.78199745532576, -2.244087216704118, -3.1300131876944697, -4.44924524671563, -5.963537693355094, -8.150330489520014, -10.654222900702054, -12.990444883447775, -14.203628222983024, -11.878600408038736, -9.630320718804068, -7.926677582939663, -6.232011404073389, -4.7388932277642075, -3.6606237717952297, -2.6288396411299404, -1.9259591572120993, -1.4837400622702093, -1.1992166493063483, -0.9987647564302047, -1.013469730497072, -1.1868221738397169, -1.5622220899897874, -2.231327110040678, -2.867439020852907, -4.136950985251968, -5.512593594273444, -7.166959274232447, -9.573908587125946, -11.951226367369658, -14.737311541812595, -13.456299152529558, -11.14757462573292, -8.99522594080616, -6.73987992502957, -5.121121707962145, -3.807714485913337, -2.7534018872858774, -1.8710330743562347, -1.3567231411745844, -0.9004646367288323, -0.7034621408051999, -0.5839054101694294, -0.5611719802139364, -0.6164231544579218, -0.779713985547625, -1.0530177756638657, -1.526433838569112, -2.0227433781132227, -2.999128615569855, -4.038949790315673, -5.765771497953423, -7.338975364809733, -9.289771722096665, -12.052739777937454, -14.246802334350475, -13.25797981391701, -10.795150906720384, -8.704638864277616, -7.102628109965177, -5.345901035371558, -4.1978903440583775, -3.2242744414219993, -2.168752092010519, -1.4659476118855925, -1.12598266304801, -0.9253015218563235, -0.8413557135900916, -0.9013884371727696, -1.1441806684358249, -1.519639053895469, -2.0599761062741613, -2.714250621185986, -3.481022501062936, -4.567141339129256, -5.765061180952813, -7.808428732980983, -10.194424233046496, -12.605060045050802, -14.062009321072948, -11.834566547208631, -10.070028116229496, -7.88039364978572, -6.186529083485632, -4.797621027376585, -3.458119545614709, -2.591084376332145, -1.9735837547896666, -1.699706280157326, -1.5728786289413883, -1.689577215393195, -2.1145434073190077, -2.8206014443564107, -3.6925269503190234, -4.687466954571755, -6.044002632981697, -7.671126851239798, -9.262485992191497, -10.85618463182443, -12.613426293179439, -11.331582566110459, -9.954083900136105, -8.32731068180469, -6.753269684874121, -5.349644830526497, -4.19770776406102, -3.524561201133813, -3.0079275025755137, -2.7009582911112733, -2.57073578022578, -2.7036707555718937, -3.0204267156617144, -3.444660484569861, -4.363453066712935, -5.542210903877455, -7.126963498136016, -8.47264212283722, -10.22705563601659, -11.996556265031135, -11.733218920089877, -9.989351209920349, -8.28013511167043, -7.088087367268459, -5.68638512481905, -4.735455924822879, -3.9546688908685916, -3.3175841368863015, -2.8754652774662195, -2.6622860712378786, -2.7396114692271976, -3.0428972525379185, -3.4717536027096894, -4.251674507657276, -5.11794016135245, -6.46870193654252, -8.103315490028322, -10.131872737790522, -12.083853277124364, -11.996692686496587, -10.517332048807697, -8.623033863172877, -7.330161411344134, -5.720185557209315, -4.509322969679798, -3.7318146450977405, -3.170948596670727, -2.731810093187051, -2.584109939702654, -2.7445709392177515, -3.1591331244207694, -3.685522405080356, -4.49232433081086, -5.76238178996892, -7.448774115775402, -9.377274597045822, -11.092230533322157, -12.798362016375744, -11.20177061399114, -9.556578869483817, -7.85602420531099, -6.308556645521729, -5.076011790415848, -4.162515824081601, -3.580084635973417, -3.2694971008235867, -3.200731831527147, -3.3724261820342276, -3.8205031807720204, -4.568183047652645, -5.457804671141039, -6.489092711835844, -7.916265901780029, -9.6138431443822, -11.53322743560812, -11.805607300447686, -10.456709206668902, -8.89108764856277, -7.5362677993850395, -5.884166726719624, -4.7686127526726665, -3.75612093598933, -3.1520996610260235, -2.698809888390529, -2.4777276303435656, -2.5867907816911586, -2.8393781269427856, -3.3519112967694356, -3.9590203804542368, -4.723905147660059, -5.718039549585943, -7.240131030899915, -9.067496806203279, -11.245141042915192, -13.011020339681387, -11.104689628062008, -9.634954867277145], [-2.0761762668371713, -2.091036273974147, -2.420149474095703, -2.9896448396088617, -3.848267569688448, -5.171903038782826, -6.448836642485723, -8.340418663390972, -10.30072281787287, -12.539242115288832, -12.822297412710334, -11.23447997595096, -9.224055368602706, -7.21317694873574, -5.641569308732652, -4.335322265370823, -3.4093121027025983, -2.5926528913818205, -1.9385354002006976, -1.6337376084858355, -1.547197987657786, -1.6118466563484195, -1.856356064790979, -2.2859416146445795, -3.076821010538546, -4.001974726845407, -5.52720786315633, -7.343341725246757, -9.356326531176656, -11.214482457571977, -13.19796576417839, -12.068958170740489, -10.492160987209008, -8.590260649180687, -6.71854062898567, -5.124825222349215, -3.9213008291797395, -3.1296359278902064, -2.6709115880233973, -2.4623574922033895, -2.4496984163556554, -2.750129344076288, -3.440665985165661, -4.402592367766153, -5.3585004691531735, -6.444912048887831, -7.638734086198155, -9.56056625393551, -11.700508751995248, -12.204882736067644, -10.52353354062822, -8.83463795241721, -7.497819796896648, -6.2756060878316555, -5.23206667491124, -4.071309961956474, -3.397723350045719, -2.799127332829153, -2.5504689526324005, -2.511945433723642, -2.7645309236361872, -3.3973377913938494, -4.461267716525512, -5.438562003464849, -6.628060434738419, -8.299362964077826, -9.710359195041905, -11.082268979673119, -11.745759073575416, -10.446200106184751, -9.018658372481944, -7.647220994427401, -6.343186561041553, -5.292933906666064, -4.223205919539063, -3.46901123327279, -3.0899154841332677, -2.9747039699676, -3.135018536463365, -3.4401773456080478, -3.867615321347691, -4.605763523626748, -5.4456350780699, -6.820906506495313, -8.29000853278698, -9.665834528881701, -10.916141246480521, -11.495985471901855, -9.917053755194942, -8.496498119787095, -7.414430941424483, -6.342851218571007, -5.519797880445397, -4.712914186854314, -4.2816740962642195, -4.039092447940153, -4.04761345211838, -4.180778025108275, -4.532100149778626, -5.282377630398154, -6.347857856346831, -7.692511383200834, -9.011061247079882, -10.789252535336367, -11.679612150377697, -10.499013158097329, -9.029144648755235, -7.5501335019217, -6.241880645643778, -5.2278993088845525, -4.578658954416115, -4.165603812988629, -3.970524931916426, -3.9393841901138194, -4.175557033960955, -4.665457571836425, -5.421387656623508, -6.188830626420157, -7.216316104939393, -8.590608910939103, -10.126346665682046, -11.929819842346202, -10.828409646151052, -9.285155178098625, -7.793847479302348, -6.495205104815245, -5.507098756865182, -4.765928380172464, -4.269341969673732, -3.911951622348203, -3.8125388535285714, -3.9650440448170814, -4.286297327055103, -4.979295193689667, -5.897425546676311, -6.869340829759497, -7.936232244827546, -9.083036813108258, -10.305155396577112, -11.366700247127318, -10.142374343941874, -8.780347269679234, -7.734651308792232, -6.553096669307098, -5.621762406347666, -4.777609225930604, -4.242991410180713, -3.8517590571822935, -3.6971924352430947, -3.733098823510763, -3.9436283283081863, -4.34594032046071, -4.964125849002004, -6.058824341299182, -7.041570574600606, -8.608760561541308, -9.84616237329623, -11.149504233306402, -10.709487451558902, -9.425111842424698, -8.272977420001121, -7.208606923685665, -6.422709097975568, -5.66180212025131, -5.037504204385684, -4.695670558367966, -4.495942872845302, -4.50904537968238, -4.7404568175164705, -5.077309457194627, -5.609903694168085, -6.221700859106388, -7.257850616510934, -8.130066143032723, -8.992805833901592, -10.164725821135574, -10.855483377286225, -9.86217856983583, -8.86168971522571, -7.798761410705263, -6.631154126209337, -5.686162285707863, -4.895135119417335, -4.401425285475605, -4.2091471965946, -4.2830646208607925, -4.462410113228659, -4.783649636990947, -5.45429905549655, -6.269567160579451, -7.431566598513287, -8.594566392070544, -10.19120447273655, -11.469762904962556, -10.445691487479628, -9.105395727698204, -7.808897085454437, -6.874570221552983, -6.060653346355166, -5.299294247513556], [-1.5401306255330034, -1.6454284233229697, -1.9414746591200536, -2.4564201881583125, -3.1954987168422395, -4.334188636575774, -5.931301311642117, -7.464050250516336, -9.480806784721608, -11.23667102122042, -13.023223659695374, -11.89496006692806, -10.132764353546891, -8.508247713958948, -6.70057685877278, -5.230314197029648, -4.0143848479657604, -3.159051841515661, -2.5274983811525416, -2.216429467366279, -2.137646722832264, -2.2310325581348405, -2.5649045210850594, -3.0771090625436104, -3.69195633485819, -4.7054762668202015, -5.9688666511603135, -7.605290677805559, -9.076063235539523, -11.002606643616947, -13.213761043854628, -11.289144683620135, -9.56978466506303, -8.02776285850399, -6.375756971361612, -5.15378455936066, -4.2031244820928, -3.365636093669793, -2.6914902342965914, -2.3574254095701765, -2.3150082660095457, -2.4762574655099416, -2.798751372687156, -3.449245179220735, -4.2900749166566605, -5.351456228771157, -6.640991938987229, -8.21702633628192, -9.799004340089962, -11.489586312554087, -12.171272183307657, -10.763444392566099, -8.833082978532236, -7.259072529390824, -6.046509061509654, -4.901550143784555, -3.778279957103344, -3.045268537796245, -2.672097778524417, -2.634442196348191, -2.9184128026986738, -3.5076238176226644, -4.133909872117625, -5.37831922674148, -6.450763484687634, -8.276508702151656, -9.843364973776417, -11.953548989430223, -12.381533022565023, -10.647453540953116, -8.779583661239188, -7.220519903188411, -5.771470746356994, -4.464609796734759, -3.6001999834517284, -2.843502737886491, -2.4249369437976034, -2.283037612955496, -2.4365571090286133, -2.9305237849375803, -3.7335607988470807, -4.752232037329008, -5.790549022411897, -7.526791556588114, -8.962605016619204, -10.820689706100383, -12.375005087111692, -11.302561367416109, -9.489535074182312, -8.176188644034921, -6.714612742658699, -5.491136005532628, -4.453031285501924, -3.793528307461308, -3.2570644124509323, -3.008966738552219, -2.9399688583782617, -3.058742488129198, -3.5147576294404934, -4.076994929119677, -4.919420531181002, -5.881971815640311, -7.159802015333927, -8.398886265078774, -10.078929002465985, -11.528817633084381, -11.223717826849015, -9.958430305041338, -8.541075437247146, -7.065348647725221, -5.629206209249858, -4.5777494666571314, -3.8410792695491702, -3.427255579673174, -3.2390104432455815, -3.2147659319087136, -3.4565378927274355, -3.968211518105402, -4.6716344810743795, -5.540481213314391, -6.834878067869378, -8.042529401690317, -9.288414104619555, -10.752695977316785, -11.62186627882336, -10.098897276266452, -8.77056093884018, -7.633250772008767, -6.533970247469068, -5.367636675604623, -4.482457325106879, -3.8213171365643746, -3.4394929082798518, -3.2938954457630443, -3.393725811063904, -3.714042232380817, -4.382935759425348, -5.275929384119992, -6.460982416529434, -8.058083400463243, -9.343118391622152, -10.825852338774133, -11.916568460594728, -10.330540423772248, -8.743133921399508, -7.459685796555713, -6.431297273688612, -5.480856925182617, -4.476322016778727, -3.805762572947091, -3.378868433792955, -3.2263815991350473, -3.3027575990380265, -3.723385470656536, -4.379209707757494, -5.130711838190629, -6.429941183141102, -7.701805455122942, -8.890074986368756, -10.362463034291832, -11.613380630662057, -10.651788436448829, -9.276018338954666, -8.069642628078274, -6.916166247018051, -5.663802801888726, -4.771667234238751, -4.047727410480242, -3.596735770026938, -3.368589666617206, -3.3737904196433557, -3.581811440195946, -4.065369748547311, -4.740954913242695, -5.736853185139927, -7.062021777777567, -8.562607689974554, -10.434885046896778, -12.123326029897319, -10.964002862899891, -9.570956155218608, -8.324579438060718, -6.929939003850015, -5.6783361196677475, -4.710481298855832, -3.905541859543143, -3.22271286032842, -2.891351279555862, -2.742585047411787, -2.8530472246213856, -3.2956554095113026, -3.905633454448287, -4.802231314919451, -6.149711937938126, -7.35335401642219, -8.66774001268124, -10.335144682786892, -11.894920335297495, -11.05166821453735, -9.469324778556537], [-1.6221187686946748, -1.6946626890137864, -1.8844230897152947, -2.1742512149675033, -2.593307896258994, -3.5068898453193387, -4.587838217574701, -6.083412360540348, -8.152848342528925, -9.84805588612205, -11.94838813395907, -13.354955515463194, -11.697534246192827, -9.93841760271166, -8.074260932542272, -6.549599954185805, -4.984734365015052, -3.6295681695046538, -2.671202662899438, -1.908771224103051, -1.5400892351510078, -1.231769149756201, -1.1378050508132755, -1.1648486975869943, -1.2942957513926623, -1.6831997809372565, -2.2504886644895943, -2.854545762578622, -3.62441594016839, -4.825111889098714, -6.679638619295723, -8.60277654294834, -10.805843021538161, -13.321844821019022, -13.406959780515626, -11.67876792380851, -9.666750664998682, -7.897295755231327, -5.963904706193983, -4.1974801112723075, -3.103141514614935, -2.2308660408342003, -1.6730271355228772, -1.1464130026458599, -0.8449353480622079, -0.6943469914875705, -0.5961665344146444, -0.5948690548485095, -0.7082190037448214, -0.8324436608565677, -1.2378714473838675, -1.7011878114476635, -2.366657338697816, -3.1651222868624105, -4.321656917283629, -5.554232330591438, -7.159107147721324, -9.549317120926494, -11.783322397726257, -14.109051607391267, -12.817829758512131, -10.604016652480249, -8.379024674998751, -6.679825931081631, -4.984971494506747, -3.7342113684296288, -2.9563925933145327, -2.3372717059859083, -1.9774610724333779, -1.8598900252376434, -1.9018690144486907, -2.0922646579339643, -2.5764869744659684, -3.1820136370037573, -4.216994547653468, -5.550769666938222, -7.298711007262536, -8.935109191122915, -10.951372213700102, -12.738681479142576, -12.202379661879824, -10.220114373256676, -8.278710738798143, -6.650277070039953, -5.440744442788973, -4.3406575866819175, -3.4721592626570903, -2.74023348004946, -2.247231300107038, -2.0524343380800305, -2.0814983195669754, -2.3140667851118457, -2.7104569793159854, -3.5601027012008672, -4.453990269707049, -5.755429872365568, -7.423617857466918, -8.955515148479101, -10.796172275564997, -12.360133924478784, -11.503309450265855, -10.063133944972577, -8.393992529561157, -7.009762584857624, -5.547449339317327, -4.452253713768783, -3.553018837306669, -2.8247956537022403, -2.41415981375142, -2.166562969195626, -2.1686560440449707, -2.330663227850364, -2.749584649007879, -3.469183178764096, -4.336612006708319, -5.540905837715082, -6.774605033687509, -8.355457259872036, -9.8065726477616, -11.301177433519078, -11.96379107329319, -10.458823576763772, -8.76872436060844, -7.535889620403415, -6.121695014065446, -4.864235000662488, -4.098414714682471, -3.4173312270353455, -3.0448208094057945, -2.972659221098414, -3.0354201067430413, -3.2417431921703197, -3.5909507203751034, -4.116116825120305, -4.932329297930439, -5.911171760233712, -7.012171342881891, -8.71441786211166, -10.099015152985713, -11.82573932267636, -10.967464144024225, -9.534474284846713, -8.09800188624174, -6.836556504891764, -5.797423993365353, -4.986816057334526, -4.394209761043892, -3.9525742037393523, -3.6908049141095596, -3.667062394884492, -3.836632082654533, -4.115760477080271, -4.613768054081093, -5.354133238485782, -6.3422128527021355, -7.693076409516869, -8.801202605017505, -9.914876070001137, -11.230564969886935, -10.540675382861243, -9.357842028615842, -8.04551132005561, -6.8819327976658276, -5.897135011524797, -5.192719822314771, -4.652324527819781, -4.317111017477895, -4.233878314634855, -4.410624059961613, -4.895938884268665, -5.410001310500132, -6.007600565416536, -6.6925789051176565, -7.485987728916998, -8.448849641033291, -9.56382780925608, -10.613535763919128, -10.411542671111219, -9.2886080290915, -8.166382543037024, -7.379191305436458, -6.629630326589578, -5.916868179843441, -5.231020544011079, -4.781114037686525, -4.509047617725183, -4.485114738627435, -4.757604651572184, -5.2040200080717804, -5.874137201751541, -6.675368355447317, -7.880001708116726, -8.944093730268758, -10.059268619975207, -11.232199438585164, -10.204697821113651, -9.016291340958766, -7.826254470736573, -6.629646953293881, -5.806138435152838], [-0.6005078973046557, -0.8421718365910453, -1.1583741686235627, -1.5293427333040461, -2.024067486834904, -2.6813659269527954, -3.656232213816096, -4.97371986901158, -6.986802669028235, -8.784665906097741, -10.814043801505116, -12.736429821481064, -13.320216800522378, -11.428873505274392, -9.742465673930926, -7.600526665083016, -6.1216398269616965, -4.820694948356829, -3.4730510588811443, -2.5659471022124904, -1.8650039826447202, -1.4382009173343004, -1.2151908571612615, -1.0917283679533656, -1.086314725512726, -1.1551808703072153, -1.3066301639562166, -1.5566505455840758, -1.8992046776627403, -2.6836793155945156, -3.722763839003596, -4.849750425529276, -6.356275083728393, -8.2630261011259, -10.7652978814706, -13.071908104167305, -13.350192427872809, -11.225802910427102, -9.06478198694838, -7.484957359688314, -5.826971635856952, -4.409409014612585, -3.3101478053780604, -2.694391790954875, -2.221665948015593, -2.0676399941791175, -2.0784852677029115, -2.233734446819313, -2.569485940700334, -3.0813708111401934, -3.9422436546980384, -4.9303400445294665, -6.302763816994222, -8.233093128434232, -10.412289588159894, -12.582064879082475, -12.59890313543694, -10.888598291782817, -8.955580610997647, -7.3250291188710035, -5.706603373468584, -4.407790766711749, -3.536403666691327, -2.7363697498806134, -2.2555426980022357, -1.912270397983459, -1.68467089264438, -1.7000694193455623, -1.8881533534550323, -2.2793982916021047, -2.8239540382318618, -3.8546055467191414, -5.272029444097065, -6.6991558984911705, -8.349380714211613, -10.204589888729782, -12.629288101489744, -13.115967024474665, -11.052828034991617, -8.90800904881373, -7.028855679528535, -5.689404817843342, -4.336457280079004, -3.337423114925658, -2.701733293623723, -2.2419724763410986, -2.0223374092191704, -2.0008377466168783, -2.2526213304203346, -2.8774906770540425, -3.7491045902924016, -4.81920470115798, -6.297403241675061, -8.120015149340823, -10.121362426854837, -12.077934139018408, -13.068048747600812, -11.3006837093055, -9.564050497186146, -7.5721235824235835, -5.85265071805578, -4.372856372348301, -3.2970777527469757, -2.6150771876352406, -2.310568742422108, -2.249300541337784, -2.3254200838752572, -2.6725519731572547, -3.091919247474358, -3.8719695294694043, -4.664381278902978, -6.099606490525654, -7.588967861431871, -9.071286667542061, -11.260464340289422, -13.155356531777782, -11.449758598818896, -9.913247979002675, -7.97630570497473, -6.255631896621673, -5.03948231174981, -3.871622110187369, -3.0354901213570384, -2.3730313490893447, -1.9125264923241152, -1.6202441113039623, -1.557901547283197, -1.7047327576317695, -1.965620960541226, -2.3292350752423023, -3.0464981332999206, -4.005089277610055, -5.030175766579662, -6.185710226680218, -8.052538867853277, -9.706979859665672, -11.349352185006454, -12.608825282472495, -11.132709158292434, -9.26767375055305, -7.887665098342534, -6.405708305324005, -5.050784056753401, -4.040000364401202, -3.382155736634634, -2.817398676244084, -2.5756764677022, -2.6257568699887845, -2.890244480157663, -3.4980247448693365, -4.475007069012729, -5.842076033088895, -7.122162074381977, -9.093100793364252, -11.388618471309016, -13.333040301769385, -11.443794886270028, -9.93192419999084, -7.979163467254006, -6.400499351721296, -5.162968095550482, -3.9649375848860426, -3.112270480056074, -2.6082524171674373, -2.2379983461674464, -2.1360136079944185, -2.291501791741835, -2.7392853321606605, -3.347166779236509, -4.215612889078297, -5.384374044057162, -6.685066946822447, -8.506607251299439, -10.34946285406102, -12.72245654615398, -12.355339120735442, -10.798560913198052, -8.700047090006043, -6.891399565704809, -5.564373085573759, -4.482903900760693, -3.464919822062354, -2.6606260828134474, -2.036209724682907, -1.6124687205726784, -1.4245392729836344, -1.4287411133957357, -1.6299262169575532, -2.1394268890962924, -2.9067745156274127, -3.7987105798488776, -5.215627625859814, -6.816056111353071, -8.36917668038201, -10.411787569137989, -12.384458114533757, -13.20344820052755, -11.339284441626619, -9.341399782161822, -7.438937124845035], [-8.80721544919939, -8.673047528523128, -8.61679113726314, -8.5668725188696, -8.565209742410227, -8.622292648177842, -8.71716762209011, -8.767108106479638, -8.786964226706974, -8.850531269812752, -9.009999453217443, -9.205398865384069, -9.509227836452428, -9.78732616918084, -9.823501584558223, -9.535965366381172, -9.246028568557275, -8.924083104278731, -8.586495956931282, -8.292314460452085, -8.102293023173958, -7.957465545937302, -7.8752779090613245, -7.867427375937358, -7.98138983024545, -8.080568624794562, -8.28758693466226, -8.665325408060452, -9.061733994355585, -9.473505104199933, -9.817491488360503, -9.826052344898459, -9.403705952504941, -8.973068954882974, -8.526790692767788, -8.207562409583577, -7.91644556983465, -7.7070552714463645, -7.555531509522803, -7.479795304958722, -7.423033043815059, -7.442416450839532, -7.632123998852765, -8.021378767572791, -8.307694578608707, -8.738434762195538, -9.083758642202035, -9.604095217079124, -10.115864895567988, -9.625694781513982, -9.141026055799559, -8.740603557061542, -8.350008281790156, -7.9457064016452135, -7.702989327244973, -7.546755835292396, -7.406249259367292, -7.297379312455277, -7.249275208311911, -7.303836932331898, -7.574422180309937, -7.809722139797679, -8.204904059336643, -8.80764688359289, -9.382621255044263, -10.1287697204675, -9.850049757147977, -9.202632316811563, -8.481653262940744, -7.850020525230993, -7.158294660443482, -6.68555119493526, -6.3018692273777885, -5.987941054364203, -5.8875821837442235, -6.030433612602131, -6.2654337863100436, -6.7791631742856, -7.228188863132572, -7.956547236533095, -8.775754237844417, -9.634063703270794, -10.677271501501739, -9.917444425860454, -8.964675957265023, -8.123626898800348, -7.170726874414308, -6.460723224469484, -6.024350937251047, -5.803577090845834, -5.761374640207975, -5.81273471772765, -5.991111325341252, -6.3319033947801024, -6.9338522264261195, -7.566003169750389, -8.52057940365668, -9.68326317511568, -10.90465187265389, -9.970956824322814, -8.995739023292787, -8.092623435228008, -7.417755161753755, -6.779036051017503, -6.260707335993623, -5.836302386991122, -5.622083235275387, -5.598497301728521, -5.853971578452306, -6.251286405274867, -6.777149179653961, -7.67220548422098, -8.492896000492772, -9.20820278502503, -10.182252287720228, -10.308880309909368, -9.488238890195936, -8.44777724596774, -7.655910274039703, -6.86015595317949, -6.307141350617983, -5.906837029002565, -5.657709684653273, -5.5672224428811585, -5.629448705344974, -5.853920647017395, -6.352175580282777, -6.931239425524033, -7.727783760621676, -8.444360670458341, -9.56193974375516, -10.633525211108525, -10.141688703334724, -9.214385741809625, -8.24937302746789, -7.332558693865624, -6.494541914010088, -5.747286682443623, -5.154704210126785, -4.728002076251966, -4.445604580249812, -4.405905325751596, -4.6522319899335365, -5.248299910479678, -5.816392938249527, -6.739216153109537, -8.056147995170543, -9.13622625783508, -10.268330371669768, -10.991287625329818, -9.798563785792343, -8.850956673110009, -7.883741593839458, -7.038339723721835, -6.1279095398311085, -5.5669572749325615, -5.10781639589257, -4.850385325113335, -4.68612040639684, -4.717579875312258, -5.047894812382563, -5.557572565552486, -6.1978301597317795, -6.834266710984761, -7.825248632809088, -8.9732623693023, -10.190673808176124, -10.910454462633373, -9.963790314161209, -8.962820956234044, -7.811501104948223, -6.914353775095193, -5.986881153687647, -5.2544398789537325, -4.533910350087653, -4.086990792234818, -3.8678018983001077, -3.8378522914013575, -4.086216600626496, -4.67187994307659, -5.592381498554077, -6.8270408176509845, -8.014101303907845, -9.772780921477318, -11.047387019231243, -11.418841782046771, -9.812766840394701, -8.457238178933128, -7.15437083665928, -6.170659786164238, -5.242523719077296, -4.638890692519235, -4.252249126406846, -4.155598506227515, -4.334650653469018, -4.796512473739056, -5.327268991525892, -6.0086646016402865, -6.823707533199397, -7.90705843305389]]\n",
      "Average Test Reward: -6.167370736760492\n",
      "Hyperparameters: {'EnvName': 'Pendulum-v0', 'IntermediateSize': 64, 'Epsilon': 1, 'ShowEvery': 10, 'InputShape': 3, 'NActions': 10}\n",
      "Test Rewards: [[-2.1230821880379698, -2.476667010723805, -3.171704939183213, -4.193603396333392, -5.380440492924093, -6.83189619856732, -8.401391326511757, -10.191571671237442, -11.783981740997397, -12.084011492384063, -10.369544235228728, -8.823488157595717, -7.485136587243547, -6.162706249810986, -5.010002438969513, -4.077718635782584, -3.175388397115664, -2.6349690872530136, -2.3619653604356663, -2.302911372907874, -2.4513340395925267, -2.7661307766704066, -3.390221073912573, -4.330201854465575, -5.539606807076132, -7.131803309963037, -8.865532872558981, -10.475826994869273, -12.614037616506424, -11.894096701473407, -10.021457329007156, -8.286371793349932, -6.928946432374311, -5.631064310305666, -4.498781133762407, -3.4065709530099006, -2.7865161594099477, -2.4089504549500482, -2.161759389378854, -2.078804545921758, -2.1831564182937577, -2.440823925295614, -3.10463519835225, -4.042337066943801, -5.394237028203186, -6.881874991551686, -8.727661222391012, -11.12665272212293, -13.076858413669882, -12.408503004078474, -10.62377644118249, -8.66404990967778, -6.831568941953536, -5.445328980820204, -4.277267098744572, -3.3667584686769354, -2.5418557583146253, -1.865677820788533, -1.4324792659448369, -1.256146563749757, -1.2034922200213527, -1.2355681367097702, -1.4557746300090373, -1.9663666012998444, -2.6046978976400057, -3.7208614624845695, -4.851343638164023, -6.571632272816006, -8.659960051539647, -10.451243692515217, -13.0606646104944, -13.635787919964992, -11.442383499023688, -9.301817452441774, -7.6579926239018645, -6.182261541363553, -4.5571815722728255, -3.2156577479989914, -2.5102055774048835, -1.9433873617193116, -1.4099572033582604, -1.1389670902734768, -0.9378051998057698, -0.8106762602755975, -0.7849566093794857, -0.8531771606366508, -1.0516364880489943, -1.457564356057102, -2.1480281826741354, -2.917471782042752, -3.9379724428361995, -5.565222167572961, -7.147095348378819, -8.817243520549532, -10.66813907357401, -12.578703861855313, -12.877398040358537, -10.782082421992161, -9.254926406925266, -7.606088616772453, -5.8948947016445405, -4.570647524993549, -3.6051899962721827, -2.7752607159873426, -2.1710033415355654, -1.7955594557106673, -1.6941534005879457, -1.7908827808666488, -2.1083946399227864, -2.571611963799055, -3.3987210352176738, -4.21750170928851, -5.606604369067877, -7.062622025668043, -8.894994202097049, -10.694770512035857, -12.794949016085692, -12.287742286033613, -10.636460611285932, -8.788258693034779, -7.099035237896042, -5.337780085281624, -4.137283346521478, -3.292590774627582, -2.5639801465847873, -1.9385933911608404, -1.5394203458991602, -1.4358023612883435, -1.4878377821037754, -1.715015019909909, -2.122880228191497, -2.630250509373803, -3.4325866583716573, -4.6169834861322165, -6.107664177224888, -7.689297533496057, -9.390766688670983, -11.659724128534709, -13.483223021869682, -11.777131187459004, -9.949022730149883, -7.920359297310701, -6.335685099497524, -4.88732201406693, -3.822922664168171, -3.084819216805994, -2.5234400619927673, -2.2314943162070096, -2.228743658376746, -2.5712482337132294, -3.064181997085714, -3.703527966787127, -4.565762256022122, -5.867355695700545, -7.252631111817909, -8.688009944727717, -10.44779197632212, -12.151356286112781, -11.377630413575298, -9.993867279187707, -8.415479296883449, -7.1119588913623515, -5.565793385696729, -4.534163739829538, -3.767373825123633, -3.13216678078144, -2.647712969040837, -2.2753633029981217, -2.173749672633864, -2.2966501409181728, -2.655108799346817, -3.298644933052356, -4.057913292287609, -5.203346254455815, -6.755685714128746, -8.247332556353081, -9.827921275449803, -11.302055260320802, -11.96513401774901, -10.51298902017169, -9.007992233459673, -7.46657827479844, -6.160169422298753, -5.105619195503296, -4.229607372243441, -3.7265881647004107, -3.4069996139110903, -3.2322698068775577, -3.2631332726961535, -3.619811777148554, -4.331884376563622, -5.10255824541138, -6.342254392424138, -7.480293993129507, -8.96415785113332, -10.886619332037117, -12.432852604782536, -11.019304220703637, -9.431988521682044, -7.812214249729305], [-5.948097659154959, -6.31594560836893, -7.045544566929719, -7.9751613661693765, -8.961628906403579, -10.06492723674161, -10.716307298581306, -9.66564925898648, -8.857670994285535, -7.897475007901848, -7.140128348568985, -6.455018102119034, -5.923786968199011, -5.571450013004202, -5.460410630892789, -5.5160992163568325, -5.7066906152224695, -6.203029529344735, -6.896889770785366, -7.763910993957431, -8.951174644463771, -9.836878417856981, -10.934271349347513, -9.97109521496865, -8.95347528367224, -8.026102071336492, -7.07564836965851, -6.238071193167317, -5.408669886113155, -4.837158232569916, -4.410885844526654, -4.299054101228219, -4.346372686165641, -4.521394226493163, -4.818023317369813, -5.303999537470983, -6.196111392793876, -7.155129127426032, -8.443791962893618, -9.802551868139712, -11.005056664971276, -10.77518625466326, -9.343314859888766, -8.237644961570716, -7.170060050834287, -6.254342008907798, -5.406632284650117, -4.49784693055954, -3.9376336525133016, -3.6935810883183913, -3.705983761133408, -3.8850476749551577, -4.38400019576072, -5.292076691262096, -6.4457679514697865, -7.623905433494627, -8.971975669805149, -10.629836319786863, -11.999036976078948, -10.54497286274089, -9.227377209779155, -7.603479424003664, -6.246125911675354, -5.174438027550261, -4.507845628997551, -3.9045876868755065, -3.5448983214409613, -3.4226879914090333, -3.5435399725965215, -3.8826895841363993, -4.453383284093586, -5.227761330138325, -6.331400612465712, -7.608527690536606, -8.858158712972228, -10.146243113968916, -11.860267611187576, -10.549661581532916, -9.202355553012316, -7.919685419821985, -6.849153325720086, -5.765687802694777, -4.952888987770395, -4.146186830862398, -3.738193904822603, -3.4622435094310524, -3.410597268821337, -3.6355294542178225, -4.1942809350699095, -5.060319276801367, -5.944506537704096, -7.3666207505954455, -8.517546015916736, -9.980429917520956, -11.854681534245746, -10.914709369854446, -9.395677506522034, -7.964658076968137, -6.858235584526167, -5.858109601627031, -5.12688044260327, -4.474949570689194, -3.944458937605186, -3.6613099556110136, -3.585709082254988, -3.7319050780570397, -4.178370088004249, -4.83161583725403, -5.6229554503364385, -6.815812450637374, -8.049010624143719, -9.316056066476206, -10.682029314921312, -11.224900836582508, -10.023517540647232, -8.664032566785975, -7.600855127151384, -6.630311095535257, -5.709455995181291, -4.947948875593197, -4.380661660185811, -4.075467320044337, -4.053813763444036, -4.316510456704933, -4.689476011330715, -5.151383378269612, -5.888110316166216, -7.040010778665974, -8.273665055093872, -9.565941781450809, -10.65518108674936, -10.994098810145363, -9.886662322831466, -8.418324773252417, -7.317081602107553, -6.251730696341701, -5.317364000876848, -4.615690391296915, -4.211594726595382, -3.9337309068822255, -3.7847349740859397, -3.8654116326336503, -4.259698837467116, -4.939481295832625, -5.946569298282505, -6.855122162869713, -7.899201864699158, -9.220274069677206, -10.911524019233866, -11.167907036888062, -9.84354864386131, -8.623897654167633, -7.610352048333355, -6.472529271931396, -5.654798951293528, -4.892186570375865, -4.332072812506739, -3.8896136468403424, -3.7259862415888043, -3.7871393948571748, -4.015660325864907, -4.54689508885155, -5.227755289359777, -5.941906029170555, -7.052485650580578, -8.373461821990198, -9.7539453027668, -11.308055429236301, -11.043152196594514, -9.523798300752064, -8.169126640513404, -7.060577319473797, -6.040188837796354, -5.027643373456889, -4.4089631133974505, -3.9655035485204144, -3.871903002532351, -3.9684568503786117, -4.33560881693643, -4.990208515371531, -5.907099018905285, -7.199352766247063, -8.72861223860552, -9.915553199588318, -11.360440701536515, -10.962748010138803, -9.645572554249634, -8.093599926754008, -6.932826711014662, -5.763271350158985, -4.892044243827061, -4.2829061826829475, -3.982145928052649, -3.8903420054849827, -3.9780531724059567, -4.4197413263182055, -4.916707655891974, -5.746688209274133, -6.861433825171696, -8.178173232239596], [-1.8511212108804722, -2.1152242583016023, -2.603484838473816, -3.278988403535417, -4.1847837926894735, -5.522880238692851, -7.056317629223888, -8.777555521324787, -11.074372357700431, -13.65569015788678, -12.660657668309893, -10.362164600371736, -8.353858377408867, -6.61752759836679, -5.101296048473608, -4.029291044475629, -3.1657067892081594, -2.485061040588279, -1.8643893981952835, -1.4709297875183622, -1.2817137050962624, -1.270683685440111, -1.5395750127637882, -2.005261876690456, -2.7835878832720664, -3.79805661867767, -4.987278073951105, -6.3456127804496285, -8.403310807627046, -10.822271631713093, -13.479878167764632, -13.558831957280727, -11.688629549209738, -9.84746636726891, -7.545001643713345, -5.982604556645239, -4.604129997421944, -3.3852305919622845, -2.3888054825711404, -1.5953552937490645, -1.1475899001664471, -0.8402025439162247, -0.6061068203740134, -0.4888622438606366, -0.39742956443012567, -0.4263622682205274, -0.5724257230916562, -0.7207147898097332, -0.9202457121823646, -1.456226153701714, -1.960191912124167, -2.918634677721767, -3.9408931580267774, -5.753285952247837, -7.312529647783219, -9.252151020481833, -11.537069172333748, -13.609883602827807, -13.585374458233096, -11.367659429908677, -9.349472813283734, -7.513797252832457, -5.703040567308115, -4.43549673849348, -3.1320408687996175, -2.134396406993545, -1.4733088255309323, -1.0213358455665407, -0.8483807614679245, -0.7156475636095506, -0.7178943488496189, -0.7765920847198888, -0.9236163593681181, -1.175606505158896, -1.7329254991029808, -2.482448800345725, -3.450123340751182, -4.677164831839231, -6.2864093433022346, -7.982291207273055, -9.877409184130578, -12.00869160286078, -13.931547013340813, -12.213881943640661, -10.537122302412751, -8.552685863620994, -6.513691006572106, -4.802045513730084, -3.746063049068853, -2.894377484259202, -2.126756754415253, -1.6774519839541129, -1.2917443916541544, -1.0687150733239708, -1.0896281076451226, -1.2526794094089815, -1.6838548276304917, -2.2522030106078073, -3.1966581567114236, -4.117473126722027, -5.558959480967969, -7.244813276978496, -9.202382386800368, -11.456595623238798, -13.506377526531367, -12.61504181815374, -10.745140122039782, -8.751190953605418, -6.860365512523048, -5.366768961602062, -4.134992860922886, -3.1739721763653104, -2.346737213953712, -1.7641182290232031, -1.4498477991336718, -1.2724664225628348, -1.1777138783096939, -1.149301186987395, -1.2225197896547315, -1.3790832723921298, -1.7265617543804586, -2.353869864429288, -3.1163423162096504, -4.323697043708762, -5.490399193084974, -7.033276920827372, -9.186130438927021, -11.22819671503526, -13.624702713309343, -12.70091193075312, -10.986254322735281, -8.73664444823983, -7.159954784008743, -5.74233557610285, -4.34076067433608, -3.278805779242316, -2.448507526693773, -1.8630796123756408, -1.1826874129317333, -0.8594973404415586, -0.5687570258055942, -0.4671551923392151, -0.40137000529110334, -0.39415962514006847, -0.5016479232693668, -0.7346731328088452, -0.9268490543645422, -1.2224647674157936, -1.643744351530337, -2.2566260844010912, -3.2691797493672627, -4.501876100497448, -6.073078066893324, -7.829513902402921, -9.67723498952677, -11.891087750643628, -13.761858369702294, -12.443545406022263, -10.669020192818701, -8.878465353217022, -7.168820514374424, -5.702769346645278, -4.405229881715895, -3.023069662937464, -2.2990784696357145, -1.5428312873106487, -1.1402424245695997, -0.7929945744113109, -0.5992532676360812, -0.5097837918851577, -0.505651748423526, -0.5247802296424413, -0.6896974787310229, -1.0465499356272403, -1.3617704322008284, -2.05793424687075, -2.9087401846860224, -4.356650954301758, -6.110562334126011, -8.275005530772953, -10.788286189615679, -13.73507630850058, -15.774515533624763, -13.482712271733918, -11.190934387069648, -8.617684777611265, -6.554928332029478, -4.799656847030406, -3.276504996553131, -2.470174151727217, -1.756028322709928, -1.3177984181825388, -0.8021977292965976, -0.6180472935785997, -0.3618653508033708, -0.3288924545771518, -0.32751016835892677, -0.38369389300781087, -0.36741074304237664, -0.3930391072684204], [-4.0518000701175, -4.355628508833538, -4.890413190166138, -5.848745143154957, -7.06967865673471, -8.47943347664248, -10.008257508242043, -11.386788271798997, -10.929556094907634, -9.74916776440985, -8.214465057260895, -6.916201936523462, -5.9450768717180695, -4.893535902983405, -4.299468464267352, -3.780869977238735, -3.5923457913890973, -3.742215923333901, -4.123227281219142, -4.835521378754802, -5.8159010716386375, -6.995691687329774, -8.6158731691763, -10.211284064320289, -11.67879767108244, -11.203352169933824, -9.650372050929711, -8.290810009482225, -7.029527143207202, -5.898591274421595, -4.714322875451945, -3.7563219981399354, -3.1034413738430238, -2.7996258899434547, -2.7584157787904164, -2.913348324869101, -3.23323788928074, -3.722251699441177, -4.38436967075201, -5.426440899152282, -6.661444463353689, -8.370247858316372, -10.234630354442935, -12.098241884853453, -11.769538850682043, -10.036613430525907, -8.562339703819152, -6.868346844141276, -5.685528706840766, -4.653842168704421, -3.814449914324757, -3.1091291530422374, -2.715196150776707, -2.55680316056664, -2.617998039531077, -3.026246009048534, -3.7168448561705723, -4.722275245036719, -5.953664204060657, -7.259431445741804, -8.638063565224776, -10.014062177174695, -11.360766952519102, -11.312498887937815, -9.80544336025616, -8.372079537211762, -7.048219108429753, -5.97994430440785, -5.063575901795212, -4.509716585120279, -4.133475595059582, -3.941689399792582, -3.923765552857326, -4.10540333538852, -4.55307594014736, -5.222732521663827, -6.214802064690352, -7.546529543386389, -8.636652799514637, -9.904477759243845, -11.375636228086135, -10.675920595731384, -9.414305720125078, -8.202578912046409, -6.9170756794771036, -5.737325325041594, -4.959825963036295, -4.35513307881335, -3.999969595419931, -3.9556225525268816, -4.072367185690755, -4.515708398709025, -5.065968923793451, -5.81977789052118, -6.977755839106693, -8.045354512280438, -9.624996007297991, -10.991164848609007, -11.009838807932024, -9.827736937920626, -8.443760471245403, -7.134337703619238, -6.159884588005144, -5.3807867213243465, -4.8116747321774245, -4.4311712443848466, -4.150331141911344, -4.014942006727504, -4.130823142007943, -4.525830883064336, -5.084049630925239, -5.7245463883272745, -6.681200934300388, -7.54255373820081, -8.770500333263335, -10.198724941735247, -11.533314831185349, -10.377553688553425, -8.961518062023442, -7.818505604622308, -6.5444525938898375, -5.642252818883966, -4.967143541093906, -4.397184588020847, -3.9988869909227485, -3.8295287002947407, -3.864675492315643, -4.014223520916364, -4.480889183042815, -5.327290475976039, -6.420624757713497, -7.424365964934336, -8.80609525163735, -10.271272326454305, -11.90253158427639, -10.596859428023366, -9.09336541792667, -7.714467025270352, -6.702535923136646, -5.796564617005123, -4.862420075142258, -4.198909555696911, -3.904183158048105, -3.897537687086072, -4.207602480865564, -4.844621973751257, -5.474955913718867, -6.566747399637587, -7.938324992204575, -9.31683972985657, -10.974466351821464, -11.650273736529766, -10.12458681593401, -8.745339304611376, -7.556693406677769, -6.255016338242946, -5.000916577772665, -4.181637457496971, -3.6038840565375048, -3.142246404487792, -2.8729284657318326, -2.7671967544602456, -2.9006335229774853, -3.2406203978788013, -3.942370172382124, -4.940767278235091, -6.048429586178961, -7.594760156335751, -8.94673666704315, -10.654197913027831, -12.244707793610656, -11.092994038740978, -9.545302187051814, -7.981502028091701, -6.641798488935259, -5.518265922919492, -4.391789403464173, -3.6745537703943176, -3.056698357350222, -2.722943162052687, -2.6354954486819677, -2.7621218830785654, -3.108649689169541, -3.875113165556528, -4.926481443319206, -5.914174302746095, -7.517443614042624, -8.97271036383957, -10.475800897358134, -12.452277464681263, -11.005233805409226, -9.361429000272981, -7.983628884412263, -6.538318747172031, -5.5512284750279095, -4.631167344558444, -4.053848871808976, -3.6687862731335357, -3.5480706246059204, -3.715492692064998], [-1.1212154776314913, -1.1055779703839117, -1.1899323730115228, -1.3844017010796068, -1.78199745532576, -2.244087216704118, -3.1300131876944697, -4.44924524671563, -5.963537693355094, -8.150330489520014, -10.654222900702054, -12.990444883447775, -14.203628222983024, -11.878600408038736, -9.630320718804068, -7.926677582939663, -6.232011404073389, -4.7388932277642075, -3.6606237717952297, -2.6288396411299404, -1.9259591572120993, -1.4837400622702093, -1.1992166493063483, -0.9987647564302047, -1.013469730497072, -1.1868221738397169, -1.5622220899897874, -2.231327110040678, -2.867439020852907, -4.136950985251968, -5.512593594273444, -7.166959274232447, -9.573908587125946, -11.951226367369658, -14.737311541812595, -13.456299152529558, -11.14757462573292, -8.99522594080616, -6.73987992502957, -5.121121707962145, -3.807714485913337, -2.7534018872858774, -1.8710330743562347, -1.3567231411745844, -0.9004646367288323, -0.7034621408051999, -0.5839054101694294, -0.5611719802139364, -0.6164231544579218, -0.779713985547625, -1.0530177756638657, -1.526433838569112, -2.0227433781132227, -2.999128615569855, -4.038949790315673, -5.765771497953423, -7.338975364809733, -9.289771722096665, -12.052739777937454, -14.246802334350475, -13.25797981391701, -10.795150906720384, -8.704638864277616, -7.102628109965177, -5.345901035371558, -4.1978903440583775, -3.2242744414219993, -2.168752092010519, -1.4659476118855925, -1.12598266304801, -0.9253015218563235, -0.8413557135900916, -0.9013884371727696, -1.1441806684358249, -1.519639053895469, -2.0599761062741613, -2.714250621185986, -3.481022501062936, -4.567141339129256, -5.765061180952813, -7.808428732980983, -10.194424233046496, -12.605060045050802, -14.062009321072948, -11.834566547208631, -10.070028116229496, -7.88039364978572, -6.186529083485632, -4.797621027376585, -3.458119545614709, -2.591084376332145, -1.9735837547896666, -1.699706280157326, -1.5728786289413883, -1.689577215393195, -2.1145434073190077, -2.8206014443564107, -3.6925269503190234, -4.687466954571755, -6.044002632981697, -7.671126851239798, -9.262485992191497, -10.85618463182443, -12.613426293179439, -11.331582566110459, -9.954083900136105, -8.32731068180469, -6.753269684874121, -5.349644830526497, -4.19770776406102, -3.524561201133813, -3.0079275025755137, -2.7009582911112733, -2.57073578022578, -2.7036707555718937, -3.0204267156617144, -3.444660484569861, -4.363453066712935, -5.542210903877455, -7.126963498136016, -8.47264212283722, -10.22705563601659, -11.996556265031135, -11.733218920089877, -9.989351209920349, -8.28013511167043, -7.088087367268459, -5.68638512481905, -4.735455924822879, -3.9546688908685916, -3.3175841368863015, -2.8754652774662195, -2.6622860712378786, -2.7396114692271976, -3.0428972525379185, -3.4717536027096894, -4.251674507657276, -5.11794016135245, -6.46870193654252, -8.103315490028322, -10.131872737790522, -12.083853277124364, -11.996692686496587, -10.517332048807697, -8.623033863172877, -7.330161411344134, -5.720185557209315, -4.509322969679798, -3.7318146450977405, -3.170948596670727, -2.731810093187051, -2.584109939702654, -2.7445709392177515, -3.1591331244207694, -3.685522405080356, -4.49232433081086, -5.76238178996892, -7.448774115775402, -9.377274597045822, -11.092230533322157, -12.798362016375744, -11.20177061399114, -9.556578869483817, -7.85602420531099, -6.308556645521729, -5.076011790415848, -4.162515824081601, -3.580084635973417, -3.2694971008235867, -3.200731831527147, -3.3724261820342276, -3.8205031807720204, -4.568183047652645, -5.457804671141039, -6.489092711835844, -7.916265901780029, -9.6138431443822, -11.53322743560812, -11.805607300447686, -10.456709206668902, -8.89108764856277, -7.5362677993850395, -5.884166726719624, -4.7686127526726665, -3.75612093598933, -3.1520996610260235, -2.698809888390529, -2.4777276303435656, -2.5867907816911586, -2.8393781269427856, -3.3519112967694356, -3.9590203804542368, -4.723905147660059, -5.718039549585943, -7.240131030899915, -9.067496806203279, -11.245141042915192, -13.011020339681387, -11.104689628062008, -9.634954867277145], [-2.0761762668371713, -2.091036273974147, -2.420149474095703, -2.9896448396088617, -3.848267569688448, -5.171903038782826, -6.448836642485723, -8.340418663390972, -10.30072281787287, -12.539242115288832, -12.822297412710334, -11.23447997595096, -9.224055368602706, -7.21317694873574, -5.641569308732652, -4.335322265370823, -3.4093121027025983, -2.5926528913818205, -1.9385354002006976, -1.6337376084858355, -1.547197987657786, -1.6118466563484195, -1.856356064790979, -2.2859416146445795, -3.076821010538546, -4.001974726845407, -5.52720786315633, -7.343341725246757, -9.356326531176656, -11.214482457571977, -13.19796576417839, -12.068958170740489, -10.492160987209008, -8.590260649180687, -6.71854062898567, -5.124825222349215, -3.9213008291797395, -3.1296359278902064, -2.6709115880233973, -2.4623574922033895, -2.4496984163556554, -2.750129344076288, -3.440665985165661, -4.402592367766153, -5.3585004691531735, -6.444912048887831, -7.638734086198155, -9.56056625393551, -11.700508751995248, -12.204882736067644, -10.52353354062822, -8.83463795241721, -7.497819796896648, -6.2756060878316555, -5.23206667491124, -4.071309961956474, -3.397723350045719, -2.799127332829153, -2.5504689526324005, -2.511945433723642, -2.7645309236361872, -3.3973377913938494, -4.461267716525512, -5.438562003464849, -6.628060434738419, -8.299362964077826, -9.710359195041905, -11.082268979673119, -11.745759073575416, -10.446200106184751, -9.018658372481944, -7.647220994427401, -6.343186561041553, -5.292933906666064, -4.223205919539063, -3.46901123327279, -3.0899154841332677, -2.9747039699676, -3.135018536463365, -3.4401773456080478, -3.867615321347691, -4.605763523626748, -5.4456350780699, -6.820906506495313, -8.29000853278698, -9.665834528881701, -10.916141246480521, -11.495985471901855, -9.917053755194942, -8.496498119787095, -7.414430941424483, -6.342851218571007, -5.519797880445397, -4.712914186854314, -4.2816740962642195, -4.039092447940153, -4.04761345211838, -4.180778025108275, -4.532100149778626, -5.282377630398154, -6.347857856346831, -7.692511383200834, -9.011061247079882, -10.789252535336367, -11.679612150377697, -10.499013158097329, -9.029144648755235, -7.5501335019217, -6.241880645643778, -5.2278993088845525, -4.578658954416115, -4.165603812988629, -3.970524931916426, -3.9393841901138194, -4.175557033960955, -4.665457571836425, -5.421387656623508, -6.188830626420157, -7.216316104939393, -8.590608910939103, -10.126346665682046, -11.929819842346202, -10.828409646151052, -9.285155178098625, -7.793847479302348, -6.495205104815245, -5.507098756865182, -4.765928380172464, -4.269341969673732, -3.911951622348203, -3.8125388535285714, -3.9650440448170814, -4.286297327055103, -4.979295193689667, -5.897425546676311, -6.869340829759497, -7.936232244827546, -9.083036813108258, -10.305155396577112, -11.366700247127318, -10.142374343941874, -8.780347269679234, -7.734651308792232, -6.553096669307098, -5.621762406347666, -4.777609225930604, -4.242991410180713, -3.8517590571822935, -3.6971924352430947, -3.733098823510763, -3.9436283283081863, -4.34594032046071, -4.964125849002004, -6.058824341299182, -7.041570574600606, -8.608760561541308, -9.84616237329623, -11.149504233306402, -10.709487451558902, -9.425111842424698, -8.272977420001121, -7.208606923685665, -6.422709097975568, -5.66180212025131, -5.037504204385684, -4.695670558367966, -4.495942872845302, -4.50904537968238, -4.7404568175164705, -5.077309457194627, -5.609903694168085, -6.221700859106388, -7.257850616510934, -8.130066143032723, -8.992805833901592, -10.164725821135574, -10.855483377286225, -9.86217856983583, -8.86168971522571, -7.798761410705263, -6.631154126209337, -5.686162285707863, -4.895135119417335, -4.401425285475605, -4.2091471965946, -4.2830646208607925, -4.462410113228659, -4.783649636990947, -5.45429905549655, -6.269567160579451, -7.431566598513287, -8.594566392070544, -10.19120447273655, -11.469762904962556, -10.445691487479628, -9.105395727698204, -7.808897085454437, -6.874570221552983, -6.060653346355166, -5.299294247513556], [-1.5401306255330034, -1.6454284233229697, -1.9414746591200536, -2.4564201881583125, -3.1954987168422395, -4.334188636575774, -5.931301311642117, -7.464050250516336, -9.480806784721608, -11.23667102122042, -13.023223659695374, -11.89496006692806, -10.132764353546891, -8.508247713958948, -6.70057685877278, -5.230314197029648, -4.0143848479657604, -3.159051841515661, -2.5274983811525416, -2.216429467366279, -2.137646722832264, -2.2310325581348405, -2.5649045210850594, -3.0771090625436104, -3.69195633485819, -4.7054762668202015, -5.9688666511603135, -7.605290677805559, -9.076063235539523, -11.002606643616947, -13.213761043854628, -11.289144683620135, -9.56978466506303, -8.02776285850399, -6.375756971361612, -5.15378455936066, -4.2031244820928, -3.365636093669793, -2.6914902342965914, -2.3574254095701765, -2.3150082660095457, -2.4762574655099416, -2.798751372687156, -3.449245179220735, -4.2900749166566605, -5.351456228771157, -6.640991938987229, -8.21702633628192, -9.799004340089962, -11.489586312554087, -12.171272183307657, -10.763444392566099, -8.833082978532236, -7.259072529390824, -6.046509061509654, -4.901550143784555, -3.778279957103344, -3.045268537796245, -2.672097778524417, -2.634442196348191, -2.9184128026986738, -3.5076238176226644, -4.133909872117625, -5.37831922674148, -6.450763484687634, -8.276508702151656, -9.843364973776417, -11.953548989430223, -12.381533022565023, -10.647453540953116, -8.779583661239188, -7.220519903188411, -5.771470746356994, -4.464609796734759, -3.6001999834517284, -2.843502737886491, -2.4249369437976034, -2.283037612955496, -2.4365571090286133, -2.9305237849375803, -3.7335607988470807, -4.752232037329008, -5.790549022411897, -7.526791556588114, -8.962605016619204, -10.820689706100383, -12.375005087111692, -11.302561367416109, -9.489535074182312, -8.176188644034921, -6.714612742658699, -5.491136005532628, -4.453031285501924, -3.793528307461308, -3.2570644124509323, -3.008966738552219, -2.9399688583782617, -3.058742488129198, -3.5147576294404934, -4.076994929119677, -4.919420531181002, -5.881971815640311, -7.159802015333927, -8.398886265078774, -10.078929002465985, -11.528817633084381, -11.223717826849015, -9.958430305041338, -8.541075437247146, -7.065348647725221, -5.629206209249858, -4.5777494666571314, -3.8410792695491702, -3.427255579673174, -3.2390104432455815, -3.2147659319087136, -3.4565378927274355, -3.968211518105402, -4.6716344810743795, -5.540481213314391, -6.834878067869378, -8.042529401690317, -9.288414104619555, -10.752695977316785, -11.62186627882336, -10.098897276266452, -8.77056093884018, -7.633250772008767, -6.533970247469068, -5.367636675604623, -4.482457325106879, -3.8213171365643746, -3.4394929082798518, -3.2938954457630443, -3.393725811063904, -3.714042232380817, -4.382935759425348, -5.275929384119992, -6.460982416529434, -8.058083400463243, -9.343118391622152, -10.825852338774133, -11.916568460594728, -10.330540423772248, -8.743133921399508, -7.459685796555713, -6.431297273688612, -5.480856925182617, -4.476322016778727, -3.805762572947091, -3.378868433792955, -3.2263815991350473, -3.3027575990380265, -3.723385470656536, -4.379209707757494, -5.130711838190629, -6.429941183141102, -7.701805455122942, -8.890074986368756, -10.362463034291832, -11.613380630662057, -10.651788436448829, -9.276018338954666, -8.069642628078274, -6.916166247018051, -5.663802801888726, -4.771667234238751, -4.047727410480242, -3.596735770026938, -3.368589666617206, -3.3737904196433557, -3.581811440195946, -4.065369748547311, -4.740954913242695, -5.736853185139927, -7.062021777777567, -8.562607689974554, -10.434885046896778, -12.123326029897319, -10.964002862899891, -9.570956155218608, -8.324579438060718, -6.929939003850015, -5.6783361196677475, -4.710481298855832, -3.905541859543143, -3.22271286032842, -2.891351279555862, -2.742585047411787, -2.8530472246213856, -3.2956554095113026, -3.905633454448287, -4.802231314919451, -6.149711937938126, -7.35335401642219, -8.66774001268124, -10.335144682786892, -11.894920335297495, -11.05166821453735, -9.469324778556537], [-1.6221187686946748, -1.6946626890137864, -1.8844230897152947, -2.1742512149675033, -2.593307896258994, -3.5068898453193387, -4.587838217574701, -6.083412360540348, -8.152848342528925, -9.84805588612205, -11.94838813395907, -13.354955515463194, -11.697534246192827, -9.93841760271166, -8.074260932542272, -6.549599954185805, -4.984734365015052, -3.6295681695046538, -2.671202662899438, -1.908771224103051, -1.5400892351510078, -1.231769149756201, -1.1378050508132755, -1.1648486975869943, -1.2942957513926623, -1.6831997809372565, -2.2504886644895943, -2.854545762578622, -3.62441594016839, -4.825111889098714, -6.679638619295723, -8.60277654294834, -10.805843021538161, -13.321844821019022, -13.406959780515626, -11.67876792380851, -9.666750664998682, -7.897295755231327, -5.963904706193983, -4.1974801112723075, -3.103141514614935, -2.2308660408342003, -1.6730271355228772, -1.1464130026458599, -0.8449353480622079, -0.6943469914875705, -0.5961665344146444, -0.5948690548485095, -0.7082190037448214, -0.8324436608565677, -1.2378714473838675, -1.7011878114476635, -2.366657338697816, -3.1651222868624105, -4.321656917283629, -5.554232330591438, -7.159107147721324, -9.549317120926494, -11.783322397726257, -14.109051607391267, -12.817829758512131, -10.604016652480249, -8.379024674998751, -6.679825931081631, -4.984971494506747, -3.7342113684296288, -2.9563925933145327, -2.3372717059859083, -1.9774610724333779, -1.8598900252376434, -1.9018690144486907, -2.0922646579339643, -2.5764869744659684, -3.1820136370037573, -4.216994547653468, -5.550769666938222, -7.298711007262536, -8.935109191122915, -10.951372213700102, -12.738681479142576, -12.202379661879824, -10.220114373256676, -8.278710738798143, -6.650277070039953, -5.440744442788973, -4.3406575866819175, -3.4721592626570903, -2.74023348004946, -2.247231300107038, -2.0524343380800305, -2.0814983195669754, -2.3140667851118457, -2.7104569793159854, -3.5601027012008672, -4.453990269707049, -5.755429872365568, -7.423617857466918, -8.955515148479101, -10.796172275564997, -12.360133924478784, -11.503309450265855, -10.063133944972577, -8.393992529561157, -7.009762584857624, -5.547449339317327, -4.452253713768783, -3.553018837306669, -2.8247956537022403, -2.41415981375142, -2.166562969195626, -2.1686560440449707, -2.330663227850364, -2.749584649007879, -3.469183178764096, -4.336612006708319, -5.540905837715082, -6.774605033687509, -8.355457259872036, -9.8065726477616, -11.301177433519078, -11.96379107329319, -10.458823576763772, -8.76872436060844, -7.535889620403415, -6.121695014065446, -4.864235000662488, -4.098414714682471, -3.4173312270353455, -3.0448208094057945, -2.972659221098414, -3.0354201067430413, -3.2417431921703197, -3.5909507203751034, -4.116116825120305, -4.932329297930439, -5.911171760233712, -7.012171342881891, -8.71441786211166, -10.099015152985713, -11.82573932267636, -10.967464144024225, -9.534474284846713, -8.09800188624174, -6.836556504891764, -5.797423993365353, -4.986816057334526, -4.394209761043892, -3.9525742037393523, -3.6908049141095596, -3.667062394884492, -3.836632082654533, -4.115760477080271, -4.613768054081093, -5.354133238485782, -6.3422128527021355, -7.693076409516869, -8.801202605017505, -9.914876070001137, -11.230564969886935, -10.540675382861243, -9.357842028615842, -8.04551132005561, -6.8819327976658276, -5.897135011524797, -5.192719822314771, -4.652324527819781, -4.317111017477895, -4.233878314634855, -4.410624059961613, -4.895938884268665, -5.410001310500132, -6.007600565416536, -6.6925789051176565, -7.485987728916998, -8.448849641033291, -9.56382780925608, -10.613535763919128, -10.411542671111219, -9.2886080290915, -8.166382543037024, -7.379191305436458, -6.629630326589578, -5.916868179843441, -5.231020544011079, -4.781114037686525, -4.509047617725183, -4.485114738627435, -4.757604651572184, -5.2040200080717804, -5.874137201751541, -6.675368355447317, -7.880001708116726, -8.944093730268758, -10.059268619975207, -11.232199438585164, -10.204697821113651, -9.016291340958766, -7.826254470736573, -6.629646953293881, -5.806138435152838], [-0.6005078973046557, -0.8421718365910453, -1.1583741686235627, -1.5293427333040461, -2.024067486834904, -2.6813659269527954, -3.656232213816096, -4.97371986901158, -6.986802669028235, -8.784665906097741, -10.814043801505116, -12.736429821481064, -13.320216800522378, -11.428873505274392, -9.742465673930926, -7.600526665083016, -6.1216398269616965, -4.820694948356829, -3.4730510588811443, -2.5659471022124904, -1.8650039826447202, -1.4382009173343004, -1.2151908571612615, -1.0917283679533656, -1.086314725512726, -1.1551808703072153, -1.3066301639562166, -1.5566505455840758, -1.8992046776627403, -2.6836793155945156, -3.722763839003596, -4.849750425529276, -6.356275083728393, -8.2630261011259, -10.7652978814706, -13.071908104167305, -13.350192427872809, -11.225802910427102, -9.06478198694838, -7.484957359688314, -5.826971635856952, -4.409409014612585, -3.3101478053780604, -2.694391790954875, -2.221665948015593, -2.0676399941791175, -2.0784852677029115, -2.233734446819313, -2.569485940700334, -3.0813708111401934, -3.9422436546980384, -4.9303400445294665, -6.302763816994222, -8.233093128434232, -10.412289588159894, -12.582064879082475, -12.59890313543694, -10.888598291782817, -8.955580610997647, -7.3250291188710035, -5.706603373468584, -4.407790766711749, -3.536403666691327, -2.7363697498806134, -2.2555426980022357, -1.912270397983459, -1.68467089264438, -1.7000694193455623, -1.8881533534550323, -2.2793982916021047, -2.8239540382318618, -3.8546055467191414, -5.272029444097065, -6.6991558984911705, -8.349380714211613, -10.204589888729782, -12.629288101489744, -13.115967024474665, -11.052828034991617, -8.90800904881373, -7.028855679528535, -5.689404817843342, -4.336457280079004, -3.337423114925658, -2.701733293623723, -2.2419724763410986, -2.0223374092191704, -2.0008377466168783, -2.2526213304203346, -2.8774906770540425, -3.7491045902924016, -4.81920470115798, -6.297403241675061, -8.120015149340823, -10.121362426854837, -12.077934139018408, -13.068048747600812, -11.3006837093055, -9.564050497186146, -7.5721235824235835, -5.85265071805578, -4.372856372348301, -3.2970777527469757, -2.6150771876352406, -2.310568742422108, -2.249300541337784, -2.3254200838752572, -2.6725519731572547, -3.091919247474358, -3.8719695294694043, -4.664381278902978, -6.099606490525654, -7.588967861431871, -9.071286667542061, -11.260464340289422, -13.155356531777782, -11.449758598818896, -9.913247979002675, -7.97630570497473, -6.255631896621673, -5.03948231174981, -3.871622110187369, -3.0354901213570384, -2.3730313490893447, -1.9125264923241152, -1.6202441113039623, -1.557901547283197, -1.7047327576317695, -1.965620960541226, -2.3292350752423023, -3.0464981332999206, -4.005089277610055, -5.030175766579662, -6.185710226680218, -8.052538867853277, -9.706979859665672, -11.349352185006454, -12.608825282472495, -11.132709158292434, -9.26767375055305, -7.887665098342534, -6.405708305324005, -5.050784056753401, -4.040000364401202, -3.382155736634634, -2.817398676244084, -2.5756764677022, -2.6257568699887845, -2.890244480157663, -3.4980247448693365, -4.475007069012729, -5.842076033088895, -7.122162074381977, -9.093100793364252, -11.388618471309016, -13.333040301769385, -11.443794886270028, -9.93192419999084, -7.979163467254006, -6.400499351721296, -5.162968095550482, -3.9649375848860426, -3.112270480056074, -2.6082524171674373, -2.2379983461674464, -2.1360136079944185, -2.291501791741835, -2.7392853321606605, -3.347166779236509, -4.215612889078297, -5.384374044057162, -6.685066946822447, -8.506607251299439, -10.34946285406102, -12.72245654615398, -12.355339120735442, -10.798560913198052, -8.700047090006043, -6.891399565704809, -5.564373085573759, -4.482903900760693, -3.464919822062354, -2.6606260828134474, -2.036209724682907, -1.6124687205726784, -1.4245392729836344, -1.4287411133957357, -1.6299262169575532, -2.1394268890962924, -2.9067745156274127, -3.7987105798488776, -5.215627625859814, -6.816056111353071, -8.36917668038201, -10.411787569137989, -12.384458114533757, -13.20344820052755, -11.339284441626619, -9.341399782161822, -7.438937124845035], [-8.80721544919939, -8.673047528523128, -8.61679113726314, -8.5668725188696, -8.565209742410227, -8.622292648177842, -8.71716762209011, -8.767108106479638, -8.786964226706974, -8.850531269812752, -9.009999453217443, -9.205398865384069, -9.509227836452428, -9.78732616918084, -9.823501584558223, -9.535965366381172, -9.246028568557275, -8.924083104278731, -8.586495956931282, -8.292314460452085, -8.102293023173958, -7.957465545937302, -7.8752779090613245, -7.867427375937358, -7.98138983024545, -8.080568624794562, -8.28758693466226, -8.665325408060452, -9.061733994355585, -9.473505104199933, -9.817491488360503, -9.826052344898459, -9.403705952504941, -8.973068954882974, -8.526790692767788, -8.207562409583577, -7.91644556983465, -7.7070552714463645, -7.555531509522803, -7.479795304958722, -7.423033043815059, -7.442416450839532, -7.632123998852765, -8.021378767572791, -8.307694578608707, -8.738434762195538, -9.083758642202035, -9.604095217079124, -10.115864895567988, -9.625694781513982, -9.141026055799559, -8.740603557061542, -8.350008281790156, -7.9457064016452135, -7.702989327244973, -7.546755835292396, -7.406249259367292, -7.297379312455277, -7.249275208311911, -7.303836932331898, -7.574422180309937, -7.809722139797679, -8.204904059336643, -8.80764688359289, -9.382621255044263, -10.1287697204675, -9.850049757147977, -9.202632316811563, -8.481653262940744, -7.850020525230993, -7.158294660443482, -6.68555119493526, -6.3018692273777885, -5.987941054364203, -5.8875821837442235, -6.030433612602131, -6.2654337863100436, -6.7791631742856, -7.228188863132572, -7.956547236533095, -8.775754237844417, -9.634063703270794, -10.677271501501739, -9.917444425860454, -8.964675957265023, -8.123626898800348, -7.170726874414308, -6.460723224469484, -6.024350937251047, -5.803577090845834, -5.761374640207975, -5.81273471772765, -5.991111325341252, -6.3319033947801024, -6.9338522264261195, -7.566003169750389, -8.52057940365668, -9.68326317511568, -10.90465187265389, -9.970956824322814, -8.995739023292787, -8.092623435228008, -7.417755161753755, -6.779036051017503, -6.260707335993623, -5.836302386991122, -5.622083235275387, -5.598497301728521, -5.853971578452306, -6.251286405274867, -6.777149179653961, -7.67220548422098, -8.492896000492772, -9.20820278502503, -10.182252287720228, -10.308880309909368, -9.488238890195936, -8.44777724596774, -7.655910274039703, -6.86015595317949, -6.307141350617983, -5.906837029002565, -5.657709684653273, -5.5672224428811585, -5.629448705344974, -5.853920647017395, -6.352175580282777, -6.931239425524033, -7.727783760621676, -8.444360670458341, -9.56193974375516, -10.633525211108525, -10.141688703334724, -9.214385741809625, -8.24937302746789, -7.332558693865624, -6.494541914010088, -5.747286682443623, -5.154704210126785, -4.728002076251966, -4.445604580249812, -4.405905325751596, -4.6522319899335365, -5.248299910479678, -5.816392938249527, -6.739216153109537, -8.056147995170543, -9.13622625783508, -10.268330371669768, -10.991287625329818, -9.798563785792343, -8.850956673110009, -7.883741593839458, -7.038339723721835, -6.1279095398311085, -5.5669572749325615, -5.10781639589257, -4.850385325113335, -4.68612040639684, -4.717579875312258, -5.047894812382563, -5.557572565552486, -6.1978301597317795, -6.834266710984761, -7.825248632809088, -8.9732623693023, -10.190673808176124, -10.910454462633373, -9.963790314161209, -8.962820956234044, -7.811501104948223, -6.914353775095193, -5.986881153687647, -5.2544398789537325, -4.533910350087653, -4.086990792234818, -3.8678018983001077, -3.8378522914013575, -4.086216600626496, -4.67187994307659, -5.592381498554077, -6.8270408176509845, -8.014101303907845, -9.772780921477318, -11.047387019231243, -11.418841782046771, -9.812766840394701, -8.457238178933128, -7.15437083665928, -6.170659786164238, -5.242523719077296, -4.638890692519235, -4.252249126406846, -4.155598506227515, -4.334650653469018, -4.796512473739056, -5.327268991525892, -6.0086646016402865, -6.823707533199397, -7.90705843305389]]\n",
      "Average Test Reward: -6.167370736760492\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'EnvName': EnvName,\n",
    "    'IntermediateSize': IntermediateSize,\n",
    "    'Epsilon': Epsilon,\n",
    "    'ShowEvery': ShowEvery,\n",
    "    'InputShape': InputShape,\n",
    "    'NActions': NActions\n",
    "}\n",
    "\n",
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "\n",
    "# Test the best agent by loading the best weights\n",
    "dir_path = 'best_dqn_weights'\n",
    "\n",
    "dqn.load_weights(path=dir_path)\n",
    "test_episodes = 10\n",
    "test_rewards = []\n",
    "for _ in range(test_episodes):\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    test_rewards.append(reward)\n",
    "\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env = gym.make(f'{EnvName}')\n",
    "state = env.reset()\n",
    "ListOfRewards = []\n",
    "Done = False\n",
    "while not Done:\n",
    "    Q = dqn.Main(state.reshape(-1, state.shape[0]))\n",
    "    action = np.argmax(Q)\n",
    "    action = PendulumActionConverter(action)\n",
    "    AStep = np.array([action])\n",
    "    action = PendulumInverseActionConverter(action)\n",
    "    env.render()\n",
    "    SNext, reward, Done, Info = env.step(AStep)\n",
    "\n",
    "    state = SNext\n",
    "\n",
    "print(f'Hyperparameters: {hyperparameters}')\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
