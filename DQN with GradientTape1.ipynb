{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58cdb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bbefb",
   "metadata": {},
   "source": [
    "1) More actions, less actions: What are appropriate number of actions to discretise the range -2.0 to 2.0?\n",
    "2) Stability of training, i.e. should you train longer or cut it off within some number of episodes?\n",
    "3) Track the reward, save weights, plot performance. Reproduce your best possible agent by loading your best weights and test it for say, 10 times. Does it consistently balance the pendulum for all 10 times when tested?\n",
    "4) Exploration vs exploitation (the epsilon hyperparameter). Should you decay it?\n",
    "5) Explain the differences between this code and the lab code for cartpole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ce568",
   "metadata": {},
   "source": [
    "# NO NEED GPU! CPU will do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e5572aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84a3c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self,\n",
    "                 InputShape = 4,\n",
    "                 NActions = 2,\n",
    "                 Gamma = 0.95,  # Discount rate\n",
    "                 epsilon = 1.0,  # Exploration rate\n",
    "                 epsilon_min = 0.1,\n",
    "                 epsilon_decay = 0.995,\n",
    "                 learning_rate = 0.01,\n",
    "                 ReplayMemorySize = 10000,\n",
    "                 MinReplayMemory = 1000,\n",
    "                 UpdateTargetEveryThisEpisodes = 1,\n",
    "                 IntermediateSize = 64,\n",
    "                 BatchSize = 32):\n",
    "        \n",
    "        # Hyperparameters. #\n",
    "        \n",
    "        self.InputShape = InputShape\n",
    "        self.NActions = NActions\n",
    "        self.Gamma = Gamma\n",
    "        self.ReplayMemorySize = ReplayMemorySize\n",
    "        self.MinReplayMemory = MinReplayMemory\n",
    "        self.UpdateTargetEveryThisEpisodes = UpdateTargetEveryThisEpisodes\n",
    "        self.IntermediateSize = IntermediateSize\n",
    "        self.BatchSize = BatchSize\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.total_reward = 0  # Initialize total reward accumulator\n",
    "        self.episode_rewards = []  # List to store rewards for each episode\n",
    "        self.average_rewards = []\n",
    "    \n",
    "\n",
    "\n",
    "        # Main model. #\n",
    "        \n",
    "        self.Main = self.CreateModel('Main')\n",
    "        self.Optimiser = Adam()\n",
    "        \n",
    "        # Target model. #\n",
    "        \n",
    "        self.Target = self.CreateModel('Target')\n",
    "        self.Target.set_weights(self.Main.get_weights())\n",
    "        \n",
    "        # Replay memory. #\n",
    "        \n",
    "        self.ReplayMemory = deque(maxlen = ReplayMemorySize)\n",
    "        \n",
    "        # Target network update counter. #\n",
    "        \n",
    "        self.TargetUpdateCounter = 0\n",
    "\n",
    "    def save_weights(self, dir_path):\n",
    "        print(f'Saving weights to {dir_path}')\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        Main_path = os.path.join(dir_path, 'Main')\n",
    "        Target_path = os.path.join(dir_path, 'Target')\n",
    "        self.Main.save_weights(Main_path + '_main.weights.h5')\n",
    "        self.Target.save_weights(Target_path + '_target.weights.h5')\n",
    "    \n",
    "    \n",
    "    def load_weights(self, path):\n",
    "        print(f'Loading weights from {path}')\n",
    "        Main_path = os.path.join(path, 'Main')\n",
    "        Target_path = os.path.join(path, 'Target')\n",
    "        self.Main.load_weights(Main_path + '_main.weights.h5')\n",
    "        self.Target.load_weights(Target_path + '_target.weights.h5')\n",
    "\n",
    "    def moving_average (self, values, window):\n",
    "        weights = np.repeat(1.0, window)/window\n",
    "        return np.convolve(values, weights, 'valid')\n",
    "    \n",
    "    def plot_rewards(self):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(self.episode_rewards, marker='o')\n",
    "        plt.plot(self.moving_average(self.episode_rewards, 10), marker='o')\n",
    "        plt.title('Episode Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_avg_rewards(self):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(self.average_rewards, marker='o')\n",
    "        plt.plot(self.moving_average(self.average_rewards, 10), marker='o')\n",
    "        plt.title('Episode Rewards')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Average Reward')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def CreateModel(self, Type):\n",
    "        inputs = Input(shape = (self.InputShape,), name = 'Input')\n",
    "        x = Dense(self.IntermediateSize, activation = 'relu', name = '1stHiddenLayer')(inputs)\n",
    "        x = Dense(self.IntermediateSize, activation = 'relu', name = '2ndHiddenLayer')(x)\n",
    "        outputs = Dense(self.NActions, activation = 'linear', name = 'Output')(x)\n",
    "        \n",
    "        NN = Model(inputs, outputs, name = f'{Type}')\n",
    "        NN.summary()\n",
    "        \n",
    "        return NN\n",
    "    \n",
    "    def UpdateReplayMemory(self, Information): # Information = (state, action, reward, SNext, Done)\n",
    "        self.ReplayMemory.append(Information)\n",
    "\n",
    "        # Epsilon-Greedy Policy to choose action\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # pull random action (exploration)\n",
    "            return random.randrange(self.action_size)\n",
    "        # else pull current-best action (greedy; exploitation)\n",
    "        act_values = self.model.predict(state, verbose = 0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "    def Train(self, EndOfEpisode, reward):\n",
    "        self.total_reward += reward  # Accumulate reward for the current episode\n",
    "\n",
    "        # Only train if replay memory has enough data. #\n",
    "        \n",
    "        if len(self.ReplayMemory) < self.MinReplayMemory:\n",
    "            print(f'DID NOT TRAIN..., replay memory = {len(self.ReplayMemory)}')\n",
    "            return\n",
    "        \n",
    "        # Get batch of data for training. #\n",
    "        \n",
    "        TrainingData = random.sample(self.ReplayMemory, self.BatchSize)\n",
    "        \n",
    "        # Get states from training data, then get corresponding Q values. #\n",
    "        \n",
    "        ListOfS = np.array([element[0] for element in TrainingData])\n",
    "        ListOfQ = np.array(self.Main(ListOfS))\n",
    "        \n",
    "        # Get future states from training data, then get corresponding Q values. #\n",
    "        \n",
    "        ListOfSNext = np.array([element[3] for element in TrainingData])\n",
    "        ListOfQNext = self.Target(ListOfSNext)\n",
    "        \n",
    "        # Build actual training data for neural network. #\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, (state, action, reward, SNext, Done) in enumerate(TrainingData):\n",
    "            if not Done:\n",
    "                MaxQNext = np.max(ListOfQNext[index])\n",
    "                QNext = reward + self.Gamma * MaxQNext\n",
    "            else:\n",
    "                QNext = reward\n",
    "            Q = ListOfQ[index]\n",
    "            Q[action] = QNext\n",
    "        \n",
    "            X.append(state)\n",
    "            Y.append(Q)\n",
    "        \n",
    "        # Train model using tf.GradientTape(), defined below.\n",
    "    \n",
    "        self.GTfit(X, Y)\n",
    "                \n",
    "        # Update target network every episode. #\n",
    "        \n",
    "        if EndOfEpisode:\n",
    "            self.episode_rewards.append(self.total_reward)  # Store total reward for the episode\n",
    "            self.total_reward = 0  # Reset total reward for the next episode\n",
    "            self.TargetUpdateCounter += 1\n",
    "\n",
    "        \n",
    "        # Update target if counter is full. #\n",
    "        \n",
    "        if self.TargetUpdateCounter >= self.UpdateTargetEveryThisEpisodes:\n",
    "            self.Target.set_weights(self.Main.get_weights())\n",
    "            self.TargetUpdateCounter = 0\n",
    "\n",
    "        # Decay epsilon gradually\n",
    "        # if self.epsilon > self.epsilon_min:\n",
    "        #     self.epsilon *= self.epsilon_decay\n",
    "        #     print('epsilon:', self.epsilon)\n",
    "\n",
    "\n",
    "    # This is the tf.GradientTape() which significantly speeds up training of neural networks\n",
    "    @tf.function\n",
    "    def GTfit(self, X, Y):\n",
    "        \n",
    "        # Train the neural network with this batch of data. #\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            Predictions = self.Main(tf.convert_to_tensor(X), training = True)\n",
    "            Loss = tf.math.reduce_mean(tf.math.square(tf.convert_to_tensor(Y) - Predictions))\n",
    "        Grad = tape.gradient(Loss, self.Main.trainable_variables)\n",
    "        self.Optimiser.apply_gradients(zip(Grad, self.Main.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7fc86272",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnvName = 'Pendulum-v0'\n",
    "IntermediateSize = 64\n",
    "Epsilon_min = 0.1\n",
    "Epsilon_decay = 0.99\n",
    "Epsilon = 1.0\n",
    "ShowEvery = 10\n",
    "InputShape = 3\n",
    "NActions = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "543ebad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PendulumActionConverter(action, NActions=NActions):\n",
    "    ActualTorque = (action / NActions - 0.5) * 4\n",
    "    return ActualTorque\n",
    "\n",
    "def PendulumInverseActionConverter(action, NActions=NActions):\n",
    "    ActualA = round((action + 2) * (NActions - 1) / 4)\n",
    "    return(ActualA)\n",
    "\n",
    "def OneEpisode(DQN):\n",
    "    env = gym.make(f'{EnvName}')\n",
    "    state = env.reset()\n",
    "    ListOfRewards = []\n",
    "    Done = False\n",
    "    global Epsilon\n",
    "    while not Done:\n",
    "        Q = DQN.Main(state.reshape(-1, state.shape[0]))\n",
    "        if np.random.rand() < Epsilon:\n",
    "            AStep = env.action_space.sample()\n",
    "            action = PendulumInverseActionConverter(AStep[0])\n",
    "        else:\n",
    "            action = np.argmax(Q)\n",
    "            action = PendulumActionConverter(action)\n",
    "            AStep = np.array([action])\n",
    "            action = PendulumInverseActionConverter(action)\n",
    "        #Epsilon *= Epsilon_decay \n",
    "        if not _ % ShowEvery and len(DQN.ReplayMemory) >= DQN.MinReplayMemory:\n",
    "            env.render()\n",
    "        SNext, reward, Done, Info = env.step(AStep)\n",
    "        DQN.UpdateReplayMemory((state, action, reward, SNext, Done))\n",
    "        DQN.Train(Done, reward)\n",
    "        ListOfRewards.append(reward)\n",
    "\n",
    "        if Done:\n",
    "            print(f'Finished! | Return: {np.sum(ListOfRewards)} | average reward: {np.mean(ListOfRewards)}')\n",
    "            env.close()\n",
    "            return ListOfRewards\n",
    "        state = SNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48c1d451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_dqn_weights\n",
      "Episode 0\n",
      "DID NOT TRAIN..., replay memory = 1\n",
      "DID NOT TRAIN..., replay memory = 2\n",
      "DID NOT TRAIN..., replay memory = 3\n",
      "DID NOT TRAIN..., replay memory = 4\n",
      "DID NOT TRAIN..., replay memory = 5\n",
      "DID NOT TRAIN..., replay memory = 6\n",
      "DID NOT TRAIN..., replay memory = 7\n",
      "DID NOT TRAIN..., replay memory = 8\n",
      "DID NOT TRAIN..., replay memory = 9\n",
      "DID NOT TRAIN..., replay memory = 10\n",
      "DID NOT TRAIN..., replay memory = 11\n",
      "DID NOT TRAIN..., replay memory = 12\n",
      "DID NOT TRAIN..., replay memory = 13\n",
      "DID NOT TRAIN..., replay memory = 14\n",
      "DID NOT TRAIN..., replay memory = 15\n",
      "DID NOT TRAIN..., replay memory = 16\n",
      "DID NOT TRAIN..., replay memory = 17\n",
      "DID NOT TRAIN..., replay memory = 18\n",
      "DID NOT TRAIN..., replay memory = 19\n",
      "DID NOT TRAIN..., replay memory = 20\n",
      "DID NOT TRAIN..., replay memory = 21\n",
      "DID NOT TRAIN..., replay memory = 22\n",
      "DID NOT TRAIN..., replay memory = 23\n",
      "DID NOT TRAIN..., replay memory = 24\n",
      "DID NOT TRAIN..., replay memory = 25\n",
      "DID NOT TRAIN..., replay memory = 26\n",
      "DID NOT TRAIN..., replay memory = 27\n",
      "DID NOT TRAIN..., replay memory = 28\n",
      "DID NOT TRAIN..., replay memory = 29\n",
      "DID NOT TRAIN..., replay memory = 30\n",
      "DID NOT TRAIN..., replay memory = 31\n",
      "DID NOT TRAIN..., replay memory = 32\n",
      "DID NOT TRAIN..., replay memory = 33\n",
      "DID NOT TRAIN..., replay memory = 34\n",
      "DID NOT TRAIN..., replay memory = 35\n",
      "DID NOT TRAIN..., replay memory = 36\n",
      "DID NOT TRAIN..., replay memory = 37\n",
      "DID NOT TRAIN..., replay memory = 38\n",
      "DID NOT TRAIN..., replay memory = 39\n",
      "DID NOT TRAIN..., replay memory = 40\n",
      "DID NOT TRAIN..., replay memory = 41\n",
      "DID NOT TRAIN..., replay memory = 42\n",
      "DID NOT TRAIN..., replay memory = 43\n",
      "DID NOT TRAIN..., replay memory = 44\n",
      "DID NOT TRAIN..., replay memory = 45\n",
      "DID NOT TRAIN..., replay memory = 46\n",
      "DID NOT TRAIN..., replay memory = 47\n",
      "DID NOT TRAIN..., replay memory = 48\n",
      "DID NOT TRAIN..., replay memory = 49\n",
      "DID NOT TRAIN..., replay memory = 50\n",
      "DID NOT TRAIN..., replay memory = 51\n",
      "DID NOT TRAIN..., replay memory = 52\n",
      "DID NOT TRAIN..., replay memory = 53\n",
      "DID NOT TRAIN..., replay memory = 54\n",
      "DID NOT TRAIN..., replay memory = 55\n",
      "DID NOT TRAIN..., replay memory = 56\n",
      "DID NOT TRAIN..., replay memory = 57\n",
      "DID NOT TRAIN..., replay memory = 58\n",
      "DID NOT TRAIN..., replay memory = 59\n",
      "DID NOT TRAIN..., replay memory = 60\n",
      "DID NOT TRAIN..., replay memory = 61\n",
      "DID NOT TRAIN..., replay memory = 62\n",
      "DID NOT TRAIN..., replay memory = 63\n",
      "DID NOT TRAIN..., replay memory = 64\n",
      "DID NOT TRAIN..., replay memory = 65\n",
      "DID NOT TRAIN..., replay memory = 66\n",
      "DID NOT TRAIN..., replay memory = 67\n",
      "DID NOT TRAIN..., replay memory = 68\n",
      "DID NOT TRAIN..., replay memory = 69\n",
      "DID NOT TRAIN..., replay memory = 70\n",
      "DID NOT TRAIN..., replay memory = 71\n",
      "DID NOT TRAIN..., replay memory = 72\n",
      "DID NOT TRAIN..., replay memory = 73\n",
      "DID NOT TRAIN..., replay memory = 74\n",
      "DID NOT TRAIN..., replay memory = 75\n",
      "DID NOT TRAIN..., replay memory = 76\n",
      "DID NOT TRAIN..., replay memory = 77\n",
      "DID NOT TRAIN..., replay memory = 78\n",
      "DID NOT TRAIN..., replay memory = 79\n",
      "DID NOT TRAIN..., replay memory = 80\n",
      "DID NOT TRAIN..., replay memory = 81\n",
      "DID NOT TRAIN..., replay memory = 82\n",
      "DID NOT TRAIN..., replay memory = 83\n",
      "DID NOT TRAIN..., replay memory = 84\n",
      "DID NOT TRAIN..., replay memory = 85\n",
      "DID NOT TRAIN..., replay memory = 86\n",
      "DID NOT TRAIN..., replay memory = 87\n",
      "DID NOT TRAIN..., replay memory = 88\n",
      "DID NOT TRAIN..., replay memory = 89\n",
      "DID NOT TRAIN..., replay memory = 90\n",
      "DID NOT TRAIN..., replay memory = 91\n",
      "DID NOT TRAIN..., replay memory = 92\n",
      "DID NOT TRAIN..., replay memory = 93\n",
      "DID NOT TRAIN..., replay memory = 94\n",
      "DID NOT TRAIN..., replay memory = 95\n",
      "DID NOT TRAIN..., replay memory = 96\n",
      "DID NOT TRAIN..., replay memory = 97\n",
      "DID NOT TRAIN..., replay memory = 98\n",
      "DID NOT TRAIN..., replay memory = 99\n",
      "DID NOT TRAIN..., replay memory = 100\n",
      "DID NOT TRAIN..., replay memory = 101\n",
      "DID NOT TRAIN..., replay memory = 102\n",
      "DID NOT TRAIN..., replay memory = 103\n",
      "DID NOT TRAIN..., replay memory = 104\n",
      "DID NOT TRAIN..., replay memory = 105\n",
      "DID NOT TRAIN..., replay memory = 106\n",
      "DID NOT TRAIN..., replay memory = 107\n",
      "DID NOT TRAIN..., replay memory = 108\n",
      "DID NOT TRAIN..., replay memory = 109\n",
      "DID NOT TRAIN..., replay memory = 110\n",
      "DID NOT TRAIN..., replay memory = 111\n",
      "DID NOT TRAIN..., replay memory = 112\n",
      "DID NOT TRAIN..., replay memory = 113\n",
      "DID NOT TRAIN..., replay memory = 114\n",
      "DID NOT TRAIN..., replay memory = 115\n",
      "DID NOT TRAIN..., replay memory = 116\n",
      "DID NOT TRAIN..., replay memory = 117\n",
      "DID NOT TRAIN..., replay memory = 118\n",
      "DID NOT TRAIN..., replay memory = 119\n",
      "DID NOT TRAIN..., replay memory = 120\n",
      "DID NOT TRAIN..., replay memory = 121\n",
      "DID NOT TRAIN..., replay memory = 122\n",
      "DID NOT TRAIN..., replay memory = 123\n",
      "DID NOT TRAIN..., replay memory = 124\n",
      "DID NOT TRAIN..., replay memory = 125\n",
      "DID NOT TRAIN..., replay memory = 126\n",
      "DID NOT TRAIN..., replay memory = 127\n",
      "DID NOT TRAIN..., replay memory = 128\n",
      "DID NOT TRAIN..., replay memory = 129\n",
      "DID NOT TRAIN..., replay memory = 130\n",
      "DID NOT TRAIN..., replay memory = 131\n",
      "DID NOT TRAIN..., replay memory = 132\n",
      "DID NOT TRAIN..., replay memory = 133\n",
      "DID NOT TRAIN..., replay memory = 134\n",
      "DID NOT TRAIN..., replay memory = 135\n",
      "DID NOT TRAIN..., replay memory = 136\n",
      "DID NOT TRAIN..., replay memory = 137\n",
      "DID NOT TRAIN..., replay memory = 138\n",
      "DID NOT TRAIN..., replay memory = 139\n",
      "DID NOT TRAIN..., replay memory = 140\n",
      "DID NOT TRAIN..., replay memory = 141\n",
      "DID NOT TRAIN..., replay memory = 142\n",
      "DID NOT TRAIN..., replay memory = 143\n",
      "DID NOT TRAIN..., replay memory = 144\n",
      "DID NOT TRAIN..., replay memory = 145\n",
      "DID NOT TRAIN..., replay memory = 146\n",
      "DID NOT TRAIN..., replay memory = 147\n",
      "DID NOT TRAIN..., replay memory = 148\n",
      "DID NOT TRAIN..., replay memory = 149\n",
      "DID NOT TRAIN..., replay memory = 150\n",
      "DID NOT TRAIN..., replay memory = 151\n",
      "DID NOT TRAIN..., replay memory = 152\n",
      "DID NOT TRAIN..., replay memory = 153\n",
      "DID NOT TRAIN..., replay memory = 154\n",
      "DID NOT TRAIN..., replay memory = 155\n",
      "DID NOT TRAIN..., replay memory = 156\n",
      "DID NOT TRAIN..., replay memory = 157\n",
      "DID NOT TRAIN..., replay memory = 158\n",
      "DID NOT TRAIN..., replay memory = 159\n",
      "DID NOT TRAIN..., replay memory = 160\n",
      "DID NOT TRAIN..., replay memory = 161\n",
      "DID NOT TRAIN..., replay memory = 162\n",
      "DID NOT TRAIN..., replay memory = 163\n",
      "DID NOT TRAIN..., replay memory = 164\n",
      "DID NOT TRAIN..., replay memory = 165\n",
      "DID NOT TRAIN..., replay memory = 166\n",
      "DID NOT TRAIN..., replay memory = 167\n",
      "DID NOT TRAIN..., replay memory = 168\n",
      "DID NOT TRAIN..., replay memory = 169\n",
      "DID NOT TRAIN..., replay memory = 170\n",
      "DID NOT TRAIN..., replay memory = 171\n",
      "DID NOT TRAIN..., replay memory = 172\n",
      "DID NOT TRAIN..., replay memory = 173\n",
      "DID NOT TRAIN..., replay memory = 174\n",
      "DID NOT TRAIN..., replay memory = 175\n",
      "DID NOT TRAIN..., replay memory = 176\n",
      "DID NOT TRAIN..., replay memory = 177\n",
      "DID NOT TRAIN..., replay memory = 178\n",
      "DID NOT TRAIN..., replay memory = 179\n",
      "DID NOT TRAIN..., replay memory = 180\n",
      "DID NOT TRAIN..., replay memory = 181\n",
      "DID NOT TRAIN..., replay memory = 182\n",
      "DID NOT TRAIN..., replay memory = 183\n",
      "DID NOT TRAIN..., replay memory = 184\n",
      "DID NOT TRAIN..., replay memory = 185\n",
      "DID NOT TRAIN..., replay memory = 186\n",
      "DID NOT TRAIN..., replay memory = 187\n",
      "DID NOT TRAIN..., replay memory = 188\n",
      "DID NOT TRAIN..., replay memory = 189\n",
      "DID NOT TRAIN..., replay memory = 190\n",
      "DID NOT TRAIN..., replay memory = 191\n",
      "DID NOT TRAIN..., replay memory = 192\n",
      "DID NOT TRAIN..., replay memory = 193\n",
      "DID NOT TRAIN..., replay memory = 194\n",
      "DID NOT TRAIN..., replay memory = 195\n",
      "DID NOT TRAIN..., replay memory = 196\n",
      "DID NOT TRAIN..., replay memory = 197\n",
      "DID NOT TRAIN..., replay memory = 198\n",
      "DID NOT TRAIN..., replay memory = 199\n",
      "DID NOT TRAIN..., replay memory = 200\n",
      "Finished! | Return: -966.4401845413491 | average reward: -4.832200922706746\n",
      "Epsilon: 0.99\n",
      "Best reward: -1000\n",
      "Saving best model weights for episode 0 with reward -4.832200922706746\n",
      "Saving weights to best_dqn_weights\n",
      "Episode 1\n",
      "DID NOT TRAIN..., replay memory = 201\n",
      "DID NOT TRAIN..., replay memory = 202\n",
      "DID NOT TRAIN..., replay memory = 203\n",
      "DID NOT TRAIN..., replay memory = 204\n",
      "DID NOT TRAIN..., replay memory = 205\n",
      "DID NOT TRAIN..., replay memory = 206\n",
      "DID NOT TRAIN..., replay memory = 207\n",
      "DID NOT TRAIN..., replay memory = 208\n",
      "DID NOT TRAIN..., replay memory = 209\n",
      "DID NOT TRAIN..., replay memory = 210\n",
      "DID NOT TRAIN..., replay memory = 211\n",
      "DID NOT TRAIN..., replay memory = 212\n",
      "DID NOT TRAIN..., replay memory = 213\n",
      "DID NOT TRAIN..., replay memory = 214\n",
      "DID NOT TRAIN..., replay memory = 215\n",
      "DID NOT TRAIN..., replay memory = 216\n",
      "DID NOT TRAIN..., replay memory = 217\n",
      "DID NOT TRAIN..., replay memory = 218\n",
      "DID NOT TRAIN..., replay memory = 219\n",
      "DID NOT TRAIN..., replay memory = 220\n",
      "DID NOT TRAIN..., replay memory = 221\n",
      "DID NOT TRAIN..., replay memory = 222\n",
      "DID NOT TRAIN..., replay memory = 223\n",
      "DID NOT TRAIN..., replay memory = 224\n",
      "DID NOT TRAIN..., replay memory = 225\n",
      "DID NOT TRAIN..., replay memory = 226\n",
      "DID NOT TRAIN..., replay memory = 227\n",
      "DID NOT TRAIN..., replay memory = 228\n",
      "DID NOT TRAIN..., replay memory = 229\n",
      "DID NOT TRAIN..., replay memory = 230\n",
      "DID NOT TRAIN..., replay memory = 231\n",
      "DID NOT TRAIN..., replay memory = 232\n",
      "DID NOT TRAIN..., replay memory = 233\n",
      "DID NOT TRAIN..., replay memory = 234\n",
      "DID NOT TRAIN..., replay memory = 235\n",
      "DID NOT TRAIN..., replay memory = 236\n",
      "DID NOT TRAIN..., replay memory = 237\n",
      "DID NOT TRAIN..., replay memory = 238\n",
      "DID NOT TRAIN..., replay memory = 239\n",
      "DID NOT TRAIN..., replay memory = 240\n",
      "DID NOT TRAIN..., replay memory = 241\n",
      "DID NOT TRAIN..., replay memory = 242\n",
      "DID NOT TRAIN..., replay memory = 243\n",
      "DID NOT TRAIN..., replay memory = 244\n",
      "DID NOT TRAIN..., replay memory = 245\n",
      "DID NOT TRAIN..., replay memory = 246\n",
      "DID NOT TRAIN..., replay memory = 247\n",
      "DID NOT TRAIN..., replay memory = 248\n",
      "DID NOT TRAIN..., replay memory = 249\n",
      "DID NOT TRAIN..., replay memory = 250\n",
      "DID NOT TRAIN..., replay memory = 251\n",
      "DID NOT TRAIN..., replay memory = 252\n",
      "DID NOT TRAIN..., replay memory = 253\n",
      "DID NOT TRAIN..., replay memory = 254\n",
      "DID NOT TRAIN..., replay memory = 255\n",
      "DID NOT TRAIN..., replay memory = 256\n",
      "DID NOT TRAIN..., replay memory = 257\n",
      "DID NOT TRAIN..., replay memory = 258\n",
      "DID NOT TRAIN..., replay memory = 259\n",
      "DID NOT TRAIN..., replay memory = 260\n",
      "DID NOT TRAIN..., replay memory = 261\n",
      "DID NOT TRAIN..., replay memory = 262\n",
      "DID NOT TRAIN..., replay memory = 263\n",
      "DID NOT TRAIN..., replay memory = 264\n",
      "DID NOT TRAIN..., replay memory = 265\n",
      "DID NOT TRAIN..., replay memory = 266\n",
      "DID NOT TRAIN..., replay memory = 267\n",
      "DID NOT TRAIN..., replay memory = 268\n",
      "DID NOT TRAIN..., replay memory = 269\n",
      "DID NOT TRAIN..., replay memory = 270\n",
      "DID NOT TRAIN..., replay memory = 271\n",
      "DID NOT TRAIN..., replay memory = 272\n",
      "DID NOT TRAIN..., replay memory = 273\n",
      "DID NOT TRAIN..., replay memory = 274\n",
      "DID NOT TRAIN..., replay memory = 275\n",
      "DID NOT TRAIN..., replay memory = 276\n",
      "DID NOT TRAIN..., replay memory = 277\n",
      "DID NOT TRAIN..., replay memory = 278\n",
      "DID NOT TRAIN..., replay memory = 279\n",
      "DID NOT TRAIN..., replay memory = 280\n",
      "DID NOT TRAIN..., replay memory = 281\n",
      "DID NOT TRAIN..., replay memory = 282\n",
      "DID NOT TRAIN..., replay memory = 283\n",
      "DID NOT TRAIN..., replay memory = 284\n",
      "DID NOT TRAIN..., replay memory = 285\n",
      "DID NOT TRAIN..., replay memory = 286\n",
      "DID NOT TRAIN..., replay memory = 287\n",
      "DID NOT TRAIN..., replay memory = 288\n",
      "DID NOT TRAIN..., replay memory = 289\n",
      "DID NOT TRAIN..., replay memory = 290\n",
      "DID NOT TRAIN..., replay memory = 291\n",
      "DID NOT TRAIN..., replay memory = 292\n",
      "DID NOT TRAIN..., replay memory = 293\n",
      "DID NOT TRAIN..., replay memory = 294\n",
      "DID NOT TRAIN..., replay memory = 295\n",
      "DID NOT TRAIN..., replay memory = 296\n",
      "DID NOT TRAIN..., replay memory = 297\n",
      "DID NOT TRAIN..., replay memory = 298\n",
      "DID NOT TRAIN..., replay memory = 299\n",
      "DID NOT TRAIN..., replay memory = 300\n",
      "DID NOT TRAIN..., replay memory = 301\n",
      "DID NOT TRAIN..., replay memory = 302\n",
      "DID NOT TRAIN..., replay memory = 303\n",
      "DID NOT TRAIN..., replay memory = 304\n",
      "DID NOT TRAIN..., replay memory = 305\n",
      "DID NOT TRAIN..., replay memory = 306\n",
      "DID NOT TRAIN..., replay memory = 307\n",
      "DID NOT TRAIN..., replay memory = 308\n",
      "DID NOT TRAIN..., replay memory = 309\n",
      "DID NOT TRAIN..., replay memory = 310\n",
      "DID NOT TRAIN..., replay memory = 311\n",
      "DID NOT TRAIN..., replay memory = 312\n",
      "DID NOT TRAIN..., replay memory = 313\n",
      "DID NOT TRAIN..., replay memory = 314\n",
      "DID NOT TRAIN..., replay memory = 315\n",
      "DID NOT TRAIN..., replay memory = 316\n",
      "DID NOT TRAIN..., replay memory = 317\n",
      "DID NOT TRAIN..., replay memory = 318\n",
      "DID NOT TRAIN..., replay memory = 319\n",
      "DID NOT TRAIN..., replay memory = 320\n",
      "DID NOT TRAIN..., replay memory = 321\n",
      "DID NOT TRAIN..., replay memory = 322\n",
      "DID NOT TRAIN..., replay memory = 323\n",
      "DID NOT TRAIN..., replay memory = 324\n",
      "DID NOT TRAIN..., replay memory = 325\n",
      "DID NOT TRAIN..., replay memory = 326\n",
      "DID NOT TRAIN..., replay memory = 327\n",
      "DID NOT TRAIN..., replay memory = 328\n",
      "DID NOT TRAIN..., replay memory = 329\n",
      "DID NOT TRAIN..., replay memory = 330\n",
      "DID NOT TRAIN..., replay memory = 331\n",
      "DID NOT TRAIN..., replay memory = 332\n",
      "DID NOT TRAIN..., replay memory = 333\n",
      "DID NOT TRAIN..., replay memory = 334\n",
      "DID NOT TRAIN..., replay memory = 335\n",
      "DID NOT TRAIN..., replay memory = 336\n",
      "DID NOT TRAIN..., replay memory = 337\n",
      "DID NOT TRAIN..., replay memory = 338\n",
      "DID NOT TRAIN..., replay memory = 339\n",
      "DID NOT TRAIN..., replay memory = 340\n",
      "DID NOT TRAIN..., replay memory = 341\n",
      "DID NOT TRAIN..., replay memory = 342\n",
      "DID NOT TRAIN..., replay memory = 343\n",
      "DID NOT TRAIN..., replay memory = 344\n",
      "DID NOT TRAIN..., replay memory = 345\n",
      "DID NOT TRAIN..., replay memory = 346\n",
      "DID NOT TRAIN..., replay memory = 347\n",
      "DID NOT TRAIN..., replay memory = 348\n",
      "DID NOT TRAIN..., replay memory = 349\n",
      "DID NOT TRAIN..., replay memory = 350\n",
      "DID NOT TRAIN..., replay memory = 351\n",
      "DID NOT TRAIN..., replay memory = 352\n",
      "DID NOT TRAIN..., replay memory = 353\n",
      "DID NOT TRAIN..., replay memory = 354\n",
      "DID NOT TRAIN..., replay memory = 355\n",
      "DID NOT TRAIN..., replay memory = 356\n",
      "DID NOT TRAIN..., replay memory = 357\n",
      "DID NOT TRAIN..., replay memory = 358\n",
      "DID NOT TRAIN..., replay memory = 359\n",
      "DID NOT TRAIN..., replay memory = 360\n",
      "DID NOT TRAIN..., replay memory = 361\n",
      "DID NOT TRAIN..., replay memory = 362\n",
      "DID NOT TRAIN..., replay memory = 363\n",
      "DID NOT TRAIN..., replay memory = 364\n",
      "DID NOT TRAIN..., replay memory = 365\n",
      "DID NOT TRAIN..., replay memory = 366\n",
      "DID NOT TRAIN..., replay memory = 367\n",
      "DID NOT TRAIN..., replay memory = 368\n",
      "DID NOT TRAIN..., replay memory = 369\n",
      "DID NOT TRAIN..., replay memory = 370\n",
      "DID NOT TRAIN..., replay memory = 371\n",
      "DID NOT TRAIN..., replay memory = 372\n",
      "DID NOT TRAIN..., replay memory = 373\n",
      "DID NOT TRAIN..., replay memory = 374\n",
      "DID NOT TRAIN..., replay memory = 375\n",
      "DID NOT TRAIN..., replay memory = 376\n",
      "DID NOT TRAIN..., replay memory = 377\n",
      "DID NOT TRAIN..., replay memory = 378\n",
      "DID NOT TRAIN..., replay memory = 379\n",
      "DID NOT TRAIN..., replay memory = 380\n",
      "DID NOT TRAIN..., replay memory = 381\n",
      "DID NOT TRAIN..., replay memory = 382\n",
      "DID NOT TRAIN..., replay memory = 383\n",
      "DID NOT TRAIN..., replay memory = 384\n",
      "DID NOT TRAIN..., replay memory = 385\n",
      "DID NOT TRAIN..., replay memory = 386\n",
      "DID NOT TRAIN..., replay memory = 387\n",
      "DID NOT TRAIN..., replay memory = 388\n",
      "DID NOT TRAIN..., replay memory = 389\n",
      "DID NOT TRAIN..., replay memory = 390\n",
      "DID NOT TRAIN..., replay memory = 391\n",
      "DID NOT TRAIN..., replay memory = 392\n",
      "DID NOT TRAIN..., replay memory = 393\n",
      "DID NOT TRAIN..., replay memory = 394\n",
      "DID NOT TRAIN..., replay memory = 395\n",
      "DID NOT TRAIN..., replay memory = 396\n",
      "DID NOT TRAIN..., replay memory = 397\n",
      "DID NOT TRAIN..., replay memory = 398\n",
      "DID NOT TRAIN..., replay memory = 399\n",
      "DID NOT TRAIN..., replay memory = 400\n",
      "Finished! | Return: -753.8691700521549 | average reward: -3.7693458502607746\n",
      "Epsilon: 0.9801\n",
      "Best reward: -4.832200922706746\n",
      "Saving best model weights for episode 1 with reward -3.7693458502607746\n",
      "Saving weights to best_dqn_weights\n",
      "Episode 2\n",
      "DID NOT TRAIN..., replay memory = 401\n",
      "DID NOT TRAIN..., replay memory = 402\n",
      "DID NOT TRAIN..., replay memory = 403\n",
      "DID NOT TRAIN..., replay memory = 404\n",
      "DID NOT TRAIN..., replay memory = 405\n",
      "DID NOT TRAIN..., replay memory = 406\n",
      "DID NOT TRAIN..., replay memory = 407\n",
      "DID NOT TRAIN..., replay memory = 408\n",
      "DID NOT TRAIN..., replay memory = 409\n",
      "DID NOT TRAIN..., replay memory = 410\n",
      "DID NOT TRAIN..., replay memory = 411\n",
      "DID NOT TRAIN..., replay memory = 412\n",
      "DID NOT TRAIN..., replay memory = 413\n",
      "DID NOT TRAIN..., replay memory = 414\n",
      "DID NOT TRAIN..., replay memory = 415\n",
      "DID NOT TRAIN..., replay memory = 416\n",
      "DID NOT TRAIN..., replay memory = 417\n",
      "DID NOT TRAIN..., replay memory = 418\n",
      "DID NOT TRAIN..., replay memory = 419\n",
      "DID NOT TRAIN..., replay memory = 420\n",
      "DID NOT TRAIN..., replay memory = 421\n",
      "DID NOT TRAIN..., replay memory = 422\n",
      "DID NOT TRAIN..., replay memory = 423\n",
      "DID NOT TRAIN..., replay memory = 424\n",
      "DID NOT TRAIN..., replay memory = 425\n",
      "DID NOT TRAIN..., replay memory = 426\n",
      "DID NOT TRAIN..., replay memory = 427\n",
      "DID NOT TRAIN..., replay memory = 428\n",
      "DID NOT TRAIN..., replay memory = 429\n",
      "DID NOT TRAIN..., replay memory = 430\n",
      "DID NOT TRAIN..., replay memory = 431\n",
      "DID NOT TRAIN..., replay memory = 432\n",
      "DID NOT TRAIN..., replay memory = 433\n",
      "DID NOT TRAIN..., replay memory = 434\n",
      "DID NOT TRAIN..., replay memory = 435\n",
      "DID NOT TRAIN..., replay memory = 436\n",
      "DID NOT TRAIN..., replay memory = 437\n",
      "DID NOT TRAIN..., replay memory = 438\n",
      "DID NOT TRAIN..., replay memory = 439\n",
      "DID NOT TRAIN..., replay memory = 440\n",
      "DID NOT TRAIN..., replay memory = 441\n",
      "DID NOT TRAIN..., replay memory = 442\n",
      "DID NOT TRAIN..., replay memory = 443\n",
      "DID NOT TRAIN..., replay memory = 444\n",
      "DID NOT TRAIN..., replay memory = 445\n",
      "DID NOT TRAIN..., replay memory = 446\n",
      "DID NOT TRAIN..., replay memory = 447\n",
      "DID NOT TRAIN..., replay memory = 448\n",
      "DID NOT TRAIN..., replay memory = 449\n",
      "DID NOT TRAIN..., replay memory = 450\n",
      "DID NOT TRAIN..., replay memory = 451\n",
      "DID NOT TRAIN..., replay memory = 452\n",
      "DID NOT TRAIN..., replay memory = 453\n",
      "DID NOT TRAIN..., replay memory = 454\n",
      "DID NOT TRAIN..., replay memory = 455\n",
      "DID NOT TRAIN..., replay memory = 456\n",
      "DID NOT TRAIN..., replay memory = 457\n",
      "DID NOT TRAIN..., replay memory = 458\n",
      "DID NOT TRAIN..., replay memory = 459\n",
      "DID NOT TRAIN..., replay memory = 460\n",
      "DID NOT TRAIN..., replay memory = 461\n",
      "DID NOT TRAIN..., replay memory = 462\n",
      "DID NOT TRAIN..., replay memory = 463\n",
      "DID NOT TRAIN..., replay memory = 464\n",
      "DID NOT TRAIN..., replay memory = 465\n",
      "DID NOT TRAIN..., replay memory = 466\n",
      "DID NOT TRAIN..., replay memory = 467\n",
      "DID NOT TRAIN..., replay memory = 468\n",
      "DID NOT TRAIN..., replay memory = 469\n",
      "DID NOT TRAIN..., replay memory = 470\n",
      "DID NOT TRAIN..., replay memory = 471\n",
      "DID NOT TRAIN..., replay memory = 472\n",
      "DID NOT TRAIN..., replay memory = 473\n",
      "DID NOT TRAIN..., replay memory = 474\n",
      "DID NOT TRAIN..., replay memory = 475\n",
      "DID NOT TRAIN..., replay memory = 476\n",
      "DID NOT TRAIN..., replay memory = 477\n",
      "DID NOT TRAIN..., replay memory = 478\n",
      "DID NOT TRAIN..., replay memory = 479\n",
      "DID NOT TRAIN..., replay memory = 480\n",
      "DID NOT TRAIN..., replay memory = 481\n",
      "DID NOT TRAIN..., replay memory = 482\n",
      "DID NOT TRAIN..., replay memory = 483\n",
      "DID NOT TRAIN..., replay memory = 484\n",
      "DID NOT TRAIN..., replay memory = 485\n",
      "DID NOT TRAIN..., replay memory = 486\n",
      "DID NOT TRAIN..., replay memory = 487\n",
      "DID NOT TRAIN..., replay memory = 488\n",
      "DID NOT TRAIN..., replay memory = 489\n",
      "DID NOT TRAIN..., replay memory = 490\n",
      "DID NOT TRAIN..., replay memory = 491\n",
      "DID NOT TRAIN..., replay memory = 492\n",
      "DID NOT TRAIN..., replay memory = 493\n",
      "DID NOT TRAIN..., replay memory = 494\n",
      "DID NOT TRAIN..., replay memory = 495\n",
      "DID NOT TRAIN..., replay memory = 496\n",
      "DID NOT TRAIN..., replay memory = 497\n",
      "DID NOT TRAIN..., replay memory = 498\n",
      "DID NOT TRAIN..., replay memory = 499\n",
      "DID NOT TRAIN..., replay memory = 500\n",
      "DID NOT TRAIN..., replay memory = 501\n",
      "DID NOT TRAIN..., replay memory = 502\n",
      "DID NOT TRAIN..., replay memory = 503\n",
      "DID NOT TRAIN..., replay memory = 504\n",
      "DID NOT TRAIN..., replay memory = 505\n",
      "DID NOT TRAIN..., replay memory = 506\n",
      "DID NOT TRAIN..., replay memory = 507\n",
      "DID NOT TRAIN..., replay memory = 508\n",
      "DID NOT TRAIN..., replay memory = 509\n",
      "DID NOT TRAIN..., replay memory = 510\n",
      "DID NOT TRAIN..., replay memory = 511\n",
      "DID NOT TRAIN..., replay memory = 512\n",
      "DID NOT TRAIN..., replay memory = 513\n",
      "DID NOT TRAIN..., replay memory = 514\n",
      "DID NOT TRAIN..., replay memory = 515\n",
      "DID NOT TRAIN..., replay memory = 516\n",
      "DID NOT TRAIN..., replay memory = 517\n",
      "DID NOT TRAIN..., replay memory = 518\n",
      "DID NOT TRAIN..., replay memory = 519\n",
      "DID NOT TRAIN..., replay memory = 520\n",
      "DID NOT TRAIN..., replay memory = 521\n",
      "DID NOT TRAIN..., replay memory = 522\n",
      "DID NOT TRAIN..., replay memory = 523\n",
      "DID NOT TRAIN..., replay memory = 524\n",
      "DID NOT TRAIN..., replay memory = 525\n",
      "DID NOT TRAIN..., replay memory = 526\n",
      "DID NOT TRAIN..., replay memory = 527\n",
      "DID NOT TRAIN..., replay memory = 528\n",
      "DID NOT TRAIN..., replay memory = 529\n",
      "DID NOT TRAIN..., replay memory = 530\n",
      "DID NOT TRAIN..., replay memory = 531\n",
      "DID NOT TRAIN..., replay memory = 532\n",
      "DID NOT TRAIN..., replay memory = 533\n",
      "DID NOT TRAIN..., replay memory = 534\n",
      "DID NOT TRAIN..., replay memory = 535\n",
      "DID NOT TRAIN..., replay memory = 536\n",
      "DID NOT TRAIN..., replay memory = 537\n",
      "DID NOT TRAIN..., replay memory = 538\n",
      "DID NOT TRAIN..., replay memory = 539\n",
      "DID NOT TRAIN..., replay memory = 540\n",
      "DID NOT TRAIN..., replay memory = 541\n",
      "DID NOT TRAIN..., replay memory = 542\n",
      "DID NOT TRAIN..., replay memory = 543\n",
      "DID NOT TRAIN..., replay memory = 544\n",
      "DID NOT TRAIN..., replay memory = 545\n",
      "DID NOT TRAIN..., replay memory = 546\n",
      "DID NOT TRAIN..., replay memory = 547\n",
      "DID NOT TRAIN..., replay memory = 548\n",
      "DID NOT TRAIN..., replay memory = 549\n",
      "DID NOT TRAIN..., replay memory = 550\n",
      "DID NOT TRAIN..., replay memory = 551\n",
      "DID NOT TRAIN..., replay memory = 552\n",
      "DID NOT TRAIN..., replay memory = 553\n",
      "DID NOT TRAIN..., replay memory = 554\n",
      "DID NOT TRAIN..., replay memory = 555\n",
      "DID NOT TRAIN..., replay memory = 556\n",
      "DID NOT TRAIN..., replay memory = 557\n",
      "DID NOT TRAIN..., replay memory = 558\n",
      "DID NOT TRAIN..., replay memory = 559\n",
      "DID NOT TRAIN..., replay memory = 560\n",
      "DID NOT TRAIN..., replay memory = 561\n",
      "DID NOT TRAIN..., replay memory = 562\n",
      "DID NOT TRAIN..., replay memory = 563\n",
      "DID NOT TRAIN..., replay memory = 564\n",
      "DID NOT TRAIN..., replay memory = 565\n",
      "DID NOT TRAIN..., replay memory = 566\n",
      "DID NOT TRAIN..., replay memory = 567\n",
      "DID NOT TRAIN..., replay memory = 568\n",
      "DID NOT TRAIN..., replay memory = 569\n",
      "DID NOT TRAIN..., replay memory = 570\n",
      "DID NOT TRAIN..., replay memory = 571\n",
      "DID NOT TRAIN..., replay memory = 572\n",
      "DID NOT TRAIN..., replay memory = 573\n",
      "DID NOT TRAIN..., replay memory = 574\n",
      "DID NOT TRAIN..., replay memory = 575\n",
      "DID NOT TRAIN..., replay memory = 576\n",
      "DID NOT TRAIN..., replay memory = 577\n",
      "DID NOT TRAIN..., replay memory = 578\n",
      "DID NOT TRAIN..., replay memory = 579\n",
      "DID NOT TRAIN..., replay memory = 580\n",
      "DID NOT TRAIN..., replay memory = 581\n",
      "DID NOT TRAIN..., replay memory = 582\n",
      "DID NOT TRAIN..., replay memory = 583\n",
      "DID NOT TRAIN..., replay memory = 584\n",
      "DID NOT TRAIN..., replay memory = 585\n",
      "DID NOT TRAIN..., replay memory = 586\n",
      "DID NOT TRAIN..., replay memory = 587\n",
      "DID NOT TRAIN..., replay memory = 588\n",
      "DID NOT TRAIN..., replay memory = 589\n",
      "DID NOT TRAIN..., replay memory = 590\n",
      "DID NOT TRAIN..., replay memory = 591\n",
      "DID NOT TRAIN..., replay memory = 592\n",
      "DID NOT TRAIN..., replay memory = 593\n",
      "DID NOT TRAIN..., replay memory = 594\n",
      "DID NOT TRAIN..., replay memory = 595\n",
      "DID NOT TRAIN..., replay memory = 596\n",
      "DID NOT TRAIN..., replay memory = 597\n",
      "DID NOT TRAIN..., replay memory = 598\n",
      "DID NOT TRAIN..., replay memory = 599\n",
      "DID NOT TRAIN..., replay memory = 600\n",
      "Finished! | Return: -1074.414556732462 | average reward: -5.3720727836623094\n",
      "Epsilon: 0.9702989999999999\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 3\n",
      "DID NOT TRAIN..., replay memory = 601\n",
      "DID NOT TRAIN..., replay memory = 602\n",
      "DID NOT TRAIN..., replay memory = 603\n",
      "DID NOT TRAIN..., replay memory = 604\n",
      "DID NOT TRAIN..., replay memory = 605\n",
      "DID NOT TRAIN..., replay memory = 606\n",
      "DID NOT TRAIN..., replay memory = 607\n",
      "DID NOT TRAIN..., replay memory = 608\n",
      "DID NOT TRAIN..., replay memory = 609\n",
      "DID NOT TRAIN..., replay memory = 610\n",
      "DID NOT TRAIN..., replay memory = 611\n",
      "DID NOT TRAIN..., replay memory = 612\n",
      "DID NOT TRAIN..., replay memory = 613\n",
      "DID NOT TRAIN..., replay memory = 614\n",
      "DID NOT TRAIN..., replay memory = 615\n",
      "DID NOT TRAIN..., replay memory = 616\n",
      "DID NOT TRAIN..., replay memory = 617\n",
      "DID NOT TRAIN..., replay memory = 618\n",
      "DID NOT TRAIN..., replay memory = 619\n",
      "DID NOT TRAIN..., replay memory = 620\n",
      "DID NOT TRAIN..., replay memory = 621\n",
      "DID NOT TRAIN..., replay memory = 622\n",
      "DID NOT TRAIN..., replay memory = 623\n",
      "DID NOT TRAIN..., replay memory = 624\n",
      "DID NOT TRAIN..., replay memory = 625\n",
      "DID NOT TRAIN..., replay memory = 626\n",
      "DID NOT TRAIN..., replay memory = 627\n",
      "DID NOT TRAIN..., replay memory = 628\n",
      "DID NOT TRAIN..., replay memory = 629\n",
      "DID NOT TRAIN..., replay memory = 630\n",
      "DID NOT TRAIN..., replay memory = 631\n",
      "DID NOT TRAIN..., replay memory = 632\n",
      "DID NOT TRAIN..., replay memory = 633\n",
      "DID NOT TRAIN..., replay memory = 634\n",
      "DID NOT TRAIN..., replay memory = 635\n",
      "DID NOT TRAIN..., replay memory = 636\n",
      "DID NOT TRAIN..., replay memory = 637\n",
      "DID NOT TRAIN..., replay memory = 638\n",
      "DID NOT TRAIN..., replay memory = 639\n",
      "DID NOT TRAIN..., replay memory = 640\n",
      "DID NOT TRAIN..., replay memory = 641\n",
      "DID NOT TRAIN..., replay memory = 642\n",
      "DID NOT TRAIN..., replay memory = 643\n",
      "DID NOT TRAIN..., replay memory = 644\n",
      "DID NOT TRAIN..., replay memory = 645\n",
      "DID NOT TRAIN..., replay memory = 646\n",
      "DID NOT TRAIN..., replay memory = 647\n",
      "DID NOT TRAIN..., replay memory = 648\n",
      "DID NOT TRAIN..., replay memory = 649\n",
      "DID NOT TRAIN..., replay memory = 650\n",
      "DID NOT TRAIN..., replay memory = 651\n",
      "DID NOT TRAIN..., replay memory = 652\n",
      "DID NOT TRAIN..., replay memory = 653\n",
      "DID NOT TRAIN..., replay memory = 654\n",
      "DID NOT TRAIN..., replay memory = 655\n",
      "DID NOT TRAIN..., replay memory = 656\n",
      "DID NOT TRAIN..., replay memory = 657\n",
      "DID NOT TRAIN..., replay memory = 658\n",
      "DID NOT TRAIN..., replay memory = 659\n",
      "DID NOT TRAIN..., replay memory = 660\n",
      "DID NOT TRAIN..., replay memory = 661\n",
      "DID NOT TRAIN..., replay memory = 662\n",
      "DID NOT TRAIN..., replay memory = 663\n",
      "DID NOT TRAIN..., replay memory = 664\n",
      "DID NOT TRAIN..., replay memory = 665\n",
      "DID NOT TRAIN..., replay memory = 666\n",
      "DID NOT TRAIN..., replay memory = 667\n",
      "DID NOT TRAIN..., replay memory = 668\n",
      "DID NOT TRAIN..., replay memory = 669\n",
      "DID NOT TRAIN..., replay memory = 670\n",
      "DID NOT TRAIN..., replay memory = 671\n",
      "DID NOT TRAIN..., replay memory = 672\n",
      "DID NOT TRAIN..., replay memory = 673\n",
      "DID NOT TRAIN..., replay memory = 674\n",
      "DID NOT TRAIN..., replay memory = 675\n",
      "DID NOT TRAIN..., replay memory = 676\n",
      "DID NOT TRAIN..., replay memory = 677\n",
      "DID NOT TRAIN..., replay memory = 678\n",
      "DID NOT TRAIN..., replay memory = 679\n",
      "DID NOT TRAIN..., replay memory = 680\n",
      "DID NOT TRAIN..., replay memory = 681\n",
      "DID NOT TRAIN..., replay memory = 682\n",
      "DID NOT TRAIN..., replay memory = 683\n",
      "DID NOT TRAIN..., replay memory = 684\n",
      "DID NOT TRAIN..., replay memory = 685\n",
      "DID NOT TRAIN..., replay memory = 686\n",
      "DID NOT TRAIN..., replay memory = 687\n",
      "DID NOT TRAIN..., replay memory = 688\n",
      "DID NOT TRAIN..., replay memory = 689\n",
      "DID NOT TRAIN..., replay memory = 690\n",
      "DID NOT TRAIN..., replay memory = 691\n",
      "DID NOT TRAIN..., replay memory = 692\n",
      "DID NOT TRAIN..., replay memory = 693\n",
      "DID NOT TRAIN..., replay memory = 694\n",
      "DID NOT TRAIN..., replay memory = 695\n",
      "DID NOT TRAIN..., replay memory = 696\n",
      "DID NOT TRAIN..., replay memory = 697\n",
      "DID NOT TRAIN..., replay memory = 698\n",
      "DID NOT TRAIN..., replay memory = 699\n",
      "DID NOT TRAIN..., replay memory = 700\n",
      "DID NOT TRAIN..., replay memory = 701\n",
      "DID NOT TRAIN..., replay memory = 702\n",
      "DID NOT TRAIN..., replay memory = 703\n",
      "DID NOT TRAIN..., replay memory = 704\n",
      "DID NOT TRAIN..., replay memory = 705\n",
      "DID NOT TRAIN..., replay memory = 706\n",
      "DID NOT TRAIN..., replay memory = 707\n",
      "DID NOT TRAIN..., replay memory = 708\n",
      "DID NOT TRAIN..., replay memory = 709\n",
      "DID NOT TRAIN..., replay memory = 710\n",
      "DID NOT TRAIN..., replay memory = 711\n",
      "DID NOT TRAIN..., replay memory = 712\n",
      "DID NOT TRAIN..., replay memory = 713\n",
      "DID NOT TRAIN..., replay memory = 714\n",
      "DID NOT TRAIN..., replay memory = 715\n",
      "DID NOT TRAIN..., replay memory = 716\n",
      "DID NOT TRAIN..., replay memory = 717\n",
      "DID NOT TRAIN..., replay memory = 718\n",
      "DID NOT TRAIN..., replay memory = 719\n",
      "DID NOT TRAIN..., replay memory = 720\n",
      "DID NOT TRAIN..., replay memory = 721\n",
      "DID NOT TRAIN..., replay memory = 722\n",
      "DID NOT TRAIN..., replay memory = 723\n",
      "DID NOT TRAIN..., replay memory = 724\n",
      "DID NOT TRAIN..., replay memory = 725\n",
      "DID NOT TRAIN..., replay memory = 726\n",
      "DID NOT TRAIN..., replay memory = 727\n",
      "DID NOT TRAIN..., replay memory = 728\n",
      "DID NOT TRAIN..., replay memory = 729\n",
      "DID NOT TRAIN..., replay memory = 730\n",
      "DID NOT TRAIN..., replay memory = 731\n",
      "DID NOT TRAIN..., replay memory = 732\n",
      "DID NOT TRAIN..., replay memory = 733\n",
      "DID NOT TRAIN..., replay memory = 734\n",
      "DID NOT TRAIN..., replay memory = 735\n",
      "DID NOT TRAIN..., replay memory = 736\n",
      "DID NOT TRAIN..., replay memory = 737\n",
      "DID NOT TRAIN..., replay memory = 738\n",
      "DID NOT TRAIN..., replay memory = 739\n",
      "DID NOT TRAIN..., replay memory = 740\n",
      "DID NOT TRAIN..., replay memory = 741\n",
      "DID NOT TRAIN..., replay memory = 742\n",
      "DID NOT TRAIN..., replay memory = 743\n",
      "DID NOT TRAIN..., replay memory = 744\n",
      "DID NOT TRAIN..., replay memory = 745\n",
      "DID NOT TRAIN..., replay memory = 746\n",
      "DID NOT TRAIN..., replay memory = 747\n",
      "DID NOT TRAIN..., replay memory = 748\n",
      "DID NOT TRAIN..., replay memory = 749\n",
      "DID NOT TRAIN..., replay memory = 750\n",
      "DID NOT TRAIN..., replay memory = 751\n",
      "DID NOT TRAIN..., replay memory = 752\n",
      "DID NOT TRAIN..., replay memory = 753\n",
      "DID NOT TRAIN..., replay memory = 754\n",
      "DID NOT TRAIN..., replay memory = 755\n",
      "DID NOT TRAIN..., replay memory = 756\n",
      "DID NOT TRAIN..., replay memory = 757\n",
      "DID NOT TRAIN..., replay memory = 758\n",
      "DID NOT TRAIN..., replay memory = 759\n",
      "DID NOT TRAIN..., replay memory = 760\n",
      "DID NOT TRAIN..., replay memory = 761\n",
      "DID NOT TRAIN..., replay memory = 762\n",
      "DID NOT TRAIN..., replay memory = 763\n",
      "DID NOT TRAIN..., replay memory = 764\n",
      "DID NOT TRAIN..., replay memory = 765\n",
      "DID NOT TRAIN..., replay memory = 766\n",
      "DID NOT TRAIN..., replay memory = 767\n",
      "DID NOT TRAIN..., replay memory = 768\n",
      "DID NOT TRAIN..., replay memory = 769\n",
      "DID NOT TRAIN..., replay memory = 770\n",
      "DID NOT TRAIN..., replay memory = 771\n",
      "DID NOT TRAIN..., replay memory = 772\n",
      "DID NOT TRAIN..., replay memory = 773\n",
      "DID NOT TRAIN..., replay memory = 774\n",
      "DID NOT TRAIN..., replay memory = 775\n",
      "DID NOT TRAIN..., replay memory = 776\n",
      "DID NOT TRAIN..., replay memory = 777\n",
      "DID NOT TRAIN..., replay memory = 778\n",
      "DID NOT TRAIN..., replay memory = 779\n",
      "DID NOT TRAIN..., replay memory = 780\n",
      "DID NOT TRAIN..., replay memory = 781\n",
      "DID NOT TRAIN..., replay memory = 782\n",
      "DID NOT TRAIN..., replay memory = 783\n",
      "DID NOT TRAIN..., replay memory = 784\n",
      "DID NOT TRAIN..., replay memory = 785\n",
      "DID NOT TRAIN..., replay memory = 786\n",
      "DID NOT TRAIN..., replay memory = 787\n",
      "DID NOT TRAIN..., replay memory = 788\n",
      "DID NOT TRAIN..., replay memory = 789\n",
      "DID NOT TRAIN..., replay memory = 790\n",
      "DID NOT TRAIN..., replay memory = 791\n",
      "DID NOT TRAIN..., replay memory = 792\n",
      "DID NOT TRAIN..., replay memory = 793\n",
      "DID NOT TRAIN..., replay memory = 794\n",
      "DID NOT TRAIN..., replay memory = 795\n",
      "DID NOT TRAIN..., replay memory = 796\n",
      "DID NOT TRAIN..., replay memory = 797\n",
      "DID NOT TRAIN..., replay memory = 798\n",
      "DID NOT TRAIN..., replay memory = 799\n",
      "DID NOT TRAIN..., replay memory = 800\n",
      "Finished! | Return: -1284.1508189864126 | average reward: -6.420754094932063\n",
      "Epsilon: 0.96059601\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 4\n",
      "DID NOT TRAIN..., replay memory = 801\n",
      "DID NOT TRAIN..., replay memory = 802\n",
      "DID NOT TRAIN..., replay memory = 803\n",
      "DID NOT TRAIN..., replay memory = 804\n",
      "DID NOT TRAIN..., replay memory = 805\n",
      "DID NOT TRAIN..., replay memory = 806\n",
      "DID NOT TRAIN..., replay memory = 807\n",
      "DID NOT TRAIN..., replay memory = 808\n",
      "DID NOT TRAIN..., replay memory = 809\n",
      "DID NOT TRAIN..., replay memory = 810\n",
      "DID NOT TRAIN..., replay memory = 811\n",
      "DID NOT TRAIN..., replay memory = 812\n",
      "DID NOT TRAIN..., replay memory = 813\n",
      "DID NOT TRAIN..., replay memory = 814\n",
      "DID NOT TRAIN..., replay memory = 815\n",
      "DID NOT TRAIN..., replay memory = 816\n",
      "DID NOT TRAIN..., replay memory = 817\n",
      "DID NOT TRAIN..., replay memory = 818\n",
      "DID NOT TRAIN..., replay memory = 819\n",
      "DID NOT TRAIN..., replay memory = 820\n",
      "DID NOT TRAIN..., replay memory = 821\n",
      "DID NOT TRAIN..., replay memory = 822\n",
      "DID NOT TRAIN..., replay memory = 823\n",
      "DID NOT TRAIN..., replay memory = 824\n",
      "DID NOT TRAIN..., replay memory = 825\n",
      "DID NOT TRAIN..., replay memory = 826\n",
      "DID NOT TRAIN..., replay memory = 827\n",
      "DID NOT TRAIN..., replay memory = 828\n",
      "DID NOT TRAIN..., replay memory = 829\n",
      "DID NOT TRAIN..., replay memory = 830\n",
      "DID NOT TRAIN..., replay memory = 831\n",
      "DID NOT TRAIN..., replay memory = 832\n",
      "DID NOT TRAIN..., replay memory = 833\n",
      "DID NOT TRAIN..., replay memory = 834\n",
      "DID NOT TRAIN..., replay memory = 835\n",
      "DID NOT TRAIN..., replay memory = 836\n",
      "DID NOT TRAIN..., replay memory = 837\n",
      "DID NOT TRAIN..., replay memory = 838\n",
      "DID NOT TRAIN..., replay memory = 839\n",
      "DID NOT TRAIN..., replay memory = 840\n",
      "DID NOT TRAIN..., replay memory = 841\n",
      "DID NOT TRAIN..., replay memory = 842\n",
      "DID NOT TRAIN..., replay memory = 843\n",
      "DID NOT TRAIN..., replay memory = 844\n",
      "DID NOT TRAIN..., replay memory = 845\n",
      "DID NOT TRAIN..., replay memory = 846\n",
      "DID NOT TRAIN..., replay memory = 847\n",
      "DID NOT TRAIN..., replay memory = 848\n",
      "DID NOT TRAIN..., replay memory = 849\n",
      "DID NOT TRAIN..., replay memory = 850\n",
      "DID NOT TRAIN..., replay memory = 851\n",
      "DID NOT TRAIN..., replay memory = 852\n",
      "DID NOT TRAIN..., replay memory = 853\n",
      "DID NOT TRAIN..., replay memory = 854\n",
      "DID NOT TRAIN..., replay memory = 855\n",
      "DID NOT TRAIN..., replay memory = 856\n",
      "DID NOT TRAIN..., replay memory = 857\n",
      "DID NOT TRAIN..., replay memory = 858\n",
      "DID NOT TRAIN..., replay memory = 859\n",
      "DID NOT TRAIN..., replay memory = 860\n",
      "DID NOT TRAIN..., replay memory = 861\n",
      "DID NOT TRAIN..., replay memory = 862\n",
      "DID NOT TRAIN..., replay memory = 863\n",
      "DID NOT TRAIN..., replay memory = 864\n",
      "DID NOT TRAIN..., replay memory = 865\n",
      "DID NOT TRAIN..., replay memory = 866\n",
      "DID NOT TRAIN..., replay memory = 867\n",
      "DID NOT TRAIN..., replay memory = 868\n",
      "DID NOT TRAIN..., replay memory = 869\n",
      "DID NOT TRAIN..., replay memory = 870\n",
      "DID NOT TRAIN..., replay memory = 871\n",
      "DID NOT TRAIN..., replay memory = 872\n",
      "DID NOT TRAIN..., replay memory = 873\n",
      "DID NOT TRAIN..., replay memory = 874\n",
      "DID NOT TRAIN..., replay memory = 875\n",
      "DID NOT TRAIN..., replay memory = 876\n",
      "DID NOT TRAIN..., replay memory = 877\n",
      "DID NOT TRAIN..., replay memory = 878\n",
      "DID NOT TRAIN..., replay memory = 879\n",
      "DID NOT TRAIN..., replay memory = 880\n",
      "DID NOT TRAIN..., replay memory = 881\n",
      "DID NOT TRAIN..., replay memory = 882\n",
      "DID NOT TRAIN..., replay memory = 883\n",
      "DID NOT TRAIN..., replay memory = 884\n",
      "DID NOT TRAIN..., replay memory = 885\n",
      "DID NOT TRAIN..., replay memory = 886\n",
      "DID NOT TRAIN..., replay memory = 887\n",
      "DID NOT TRAIN..., replay memory = 888\n",
      "DID NOT TRAIN..., replay memory = 889\n",
      "DID NOT TRAIN..., replay memory = 890\n",
      "DID NOT TRAIN..., replay memory = 891\n",
      "DID NOT TRAIN..., replay memory = 892\n",
      "DID NOT TRAIN..., replay memory = 893\n",
      "DID NOT TRAIN..., replay memory = 894\n",
      "DID NOT TRAIN..., replay memory = 895\n",
      "DID NOT TRAIN..., replay memory = 896\n",
      "DID NOT TRAIN..., replay memory = 897\n",
      "DID NOT TRAIN..., replay memory = 898\n",
      "DID NOT TRAIN..., replay memory = 899\n",
      "DID NOT TRAIN..., replay memory = 900\n",
      "DID NOT TRAIN..., replay memory = 901\n",
      "DID NOT TRAIN..., replay memory = 902\n",
      "DID NOT TRAIN..., replay memory = 903\n",
      "DID NOT TRAIN..., replay memory = 904\n",
      "DID NOT TRAIN..., replay memory = 905\n",
      "DID NOT TRAIN..., replay memory = 906\n",
      "DID NOT TRAIN..., replay memory = 907\n",
      "DID NOT TRAIN..., replay memory = 908\n",
      "DID NOT TRAIN..., replay memory = 909\n",
      "DID NOT TRAIN..., replay memory = 910\n",
      "DID NOT TRAIN..., replay memory = 911\n",
      "DID NOT TRAIN..., replay memory = 912\n",
      "DID NOT TRAIN..., replay memory = 913\n",
      "DID NOT TRAIN..., replay memory = 914\n",
      "DID NOT TRAIN..., replay memory = 915\n",
      "DID NOT TRAIN..., replay memory = 916\n",
      "DID NOT TRAIN..., replay memory = 917\n",
      "DID NOT TRAIN..., replay memory = 918\n",
      "DID NOT TRAIN..., replay memory = 919\n",
      "DID NOT TRAIN..., replay memory = 920\n",
      "DID NOT TRAIN..., replay memory = 921\n",
      "DID NOT TRAIN..., replay memory = 922\n",
      "DID NOT TRAIN..., replay memory = 923\n",
      "DID NOT TRAIN..., replay memory = 924\n",
      "DID NOT TRAIN..., replay memory = 925\n",
      "DID NOT TRAIN..., replay memory = 926\n",
      "DID NOT TRAIN..., replay memory = 927\n",
      "DID NOT TRAIN..., replay memory = 928\n",
      "DID NOT TRAIN..., replay memory = 929\n",
      "DID NOT TRAIN..., replay memory = 930\n",
      "DID NOT TRAIN..., replay memory = 931\n",
      "DID NOT TRAIN..., replay memory = 932\n",
      "DID NOT TRAIN..., replay memory = 933\n",
      "DID NOT TRAIN..., replay memory = 934\n",
      "DID NOT TRAIN..., replay memory = 935\n",
      "DID NOT TRAIN..., replay memory = 936\n",
      "DID NOT TRAIN..., replay memory = 937\n",
      "DID NOT TRAIN..., replay memory = 938\n",
      "DID NOT TRAIN..., replay memory = 939\n",
      "DID NOT TRAIN..., replay memory = 940\n",
      "DID NOT TRAIN..., replay memory = 941\n",
      "DID NOT TRAIN..., replay memory = 942\n",
      "DID NOT TRAIN..., replay memory = 943\n",
      "DID NOT TRAIN..., replay memory = 944\n",
      "DID NOT TRAIN..., replay memory = 945\n",
      "DID NOT TRAIN..., replay memory = 946\n",
      "DID NOT TRAIN..., replay memory = 947\n",
      "DID NOT TRAIN..., replay memory = 948\n",
      "DID NOT TRAIN..., replay memory = 949\n",
      "DID NOT TRAIN..., replay memory = 950\n",
      "DID NOT TRAIN..., replay memory = 951\n",
      "DID NOT TRAIN..., replay memory = 952\n",
      "DID NOT TRAIN..., replay memory = 953\n",
      "DID NOT TRAIN..., replay memory = 954\n",
      "DID NOT TRAIN..., replay memory = 955\n",
      "DID NOT TRAIN..., replay memory = 956\n",
      "DID NOT TRAIN..., replay memory = 957\n",
      "DID NOT TRAIN..., replay memory = 958\n",
      "DID NOT TRAIN..., replay memory = 959\n",
      "DID NOT TRAIN..., replay memory = 960\n",
      "DID NOT TRAIN..., replay memory = 961\n",
      "DID NOT TRAIN..., replay memory = 962\n",
      "DID NOT TRAIN..., replay memory = 963\n",
      "DID NOT TRAIN..., replay memory = 964\n",
      "DID NOT TRAIN..., replay memory = 965\n",
      "DID NOT TRAIN..., replay memory = 966\n",
      "DID NOT TRAIN..., replay memory = 967\n",
      "DID NOT TRAIN..., replay memory = 968\n",
      "DID NOT TRAIN..., replay memory = 969\n",
      "DID NOT TRAIN..., replay memory = 970\n",
      "DID NOT TRAIN..., replay memory = 971\n",
      "DID NOT TRAIN..., replay memory = 972\n",
      "DID NOT TRAIN..., replay memory = 973\n",
      "DID NOT TRAIN..., replay memory = 974\n",
      "DID NOT TRAIN..., replay memory = 975\n",
      "DID NOT TRAIN..., replay memory = 976\n",
      "DID NOT TRAIN..., replay memory = 977\n",
      "DID NOT TRAIN..., replay memory = 978\n",
      "DID NOT TRAIN..., replay memory = 979\n",
      "DID NOT TRAIN..., replay memory = 980\n",
      "DID NOT TRAIN..., replay memory = 981\n",
      "DID NOT TRAIN..., replay memory = 982\n",
      "DID NOT TRAIN..., replay memory = 983\n",
      "DID NOT TRAIN..., replay memory = 984\n",
      "DID NOT TRAIN..., replay memory = 985\n",
      "DID NOT TRAIN..., replay memory = 986\n",
      "DID NOT TRAIN..., replay memory = 987\n",
      "DID NOT TRAIN..., replay memory = 988\n",
      "DID NOT TRAIN..., replay memory = 989\n",
      "DID NOT TRAIN..., replay memory = 990\n",
      "DID NOT TRAIN..., replay memory = 991\n",
      "DID NOT TRAIN..., replay memory = 992\n",
      "DID NOT TRAIN..., replay memory = 993\n",
      "DID NOT TRAIN..., replay memory = 994\n",
      "DID NOT TRAIN..., replay memory = 995\n",
      "DID NOT TRAIN..., replay memory = 996\n",
      "DID NOT TRAIN..., replay memory = 997\n",
      "DID NOT TRAIN..., replay memory = 998\n",
      "DID NOT TRAIN..., replay memory = 999\n",
      "Finished! | Return: -926.487624761284 | average reward: -4.63243812380642\n",
      "Epsilon: 0.9509900498999999\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 5\n",
      "Finished! | Return: -1497.3636633554252 | average reward: -7.486818316777126\n",
      "Epsilon: 0.9414801494009999\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 6\n",
      "Finished! | Return: -1222.2403163437175 | average reward: -6.111201581718587\n",
      "Epsilon: 0.9320653479069899\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 7\n",
      "Finished! | Return: -1674.0094175188806 | average reward: -8.370047087594402\n",
      "Epsilon: 0.92274469442792\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 8\n",
      "Finished! | Return: -1224.7201249408042 | average reward: -6.1236006247040216\n",
      "Epsilon: 0.9135172474836407\n",
      "Best reward: -3.7693458502607746\n",
      "Episode 9\n",
      "Finished! | Return: -750.9716139645014 | average reward: -3.7548580698225074\n",
      "Epsilon: 0.9043820750088043\n",
      "Best reward: -3.7693458502607746\n",
      "Saving best model weights for episode 9 with reward -3.7548580698225074\n",
      "Saving weights to best_dqn_weights\n",
      "Episode 10\n",
      "Finished! | Return: -1240.963203901107 | average reward: -6.204816019505534\n",
      "Epsilon: 0.8953382542587163\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 11\n",
      "Finished! | Return: -988.7291065978152 | average reward: -4.943645532989076\n",
      "Epsilon: 0.8863848717161291\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 12\n",
      "Finished! | Return: -1396.0303554577104 | average reward: -6.980151777288552\n",
      "Epsilon: 0.8775210229989678\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 13\n",
      "Finished! | Return: -1017.0984361519442 | average reward: -5.08549218075972\n",
      "Epsilon: 0.8687458127689781\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 14\n",
      "Finished! | Return: -1270.389313672138 | average reward: -6.351946568360691\n",
      "Epsilon: 0.8600583546412883\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 15\n",
      "Finished! | Return: -1238.3653216425018 | average reward: -6.1918266082125095\n",
      "Epsilon: 0.8514577710948754\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 16\n",
      "Finished! | Return: -1201.7947515700935 | average reward: -6.008973757850467\n",
      "Epsilon: 0.8429431933839266\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 17\n",
      "Finished! | Return: -1197.051087349049 | average reward: -5.985255436745246\n",
      "Epsilon: 0.8345137614500874\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 18\n",
      "Finished! | Return: -811.980991412486 | average reward: -4.05990495706243\n",
      "Epsilon: 0.8261686238355865\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 19\n",
      "Finished! | Return: -1359.1109679638369 | average reward: -6.795554839819184\n",
      "Epsilon: 0.8179069375972307\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 20\n",
      "Finished! | Return: -862.034759775817 | average reward: -4.3101737988790845\n",
      "Epsilon: 0.8097278682212583\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 21\n",
      "Finished! | Return: -1535.8867512397703 | average reward: -7.6794337561988515\n",
      "Epsilon: 0.8016305895390458\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 22\n",
      "Finished! | Return: -940.7445378198646 | average reward: -4.703722689099323\n",
      "Epsilon: 0.7936142836436553\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 23\n",
      "Finished! | Return: -755.038269785362 | average reward: -3.77519134892681\n",
      "Epsilon: 0.7856781408072188\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 24\n",
      "Finished! | Return: -906.2699423720762 | average reward: -4.531349711860381\n",
      "Epsilon: 0.7778213593991465\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 25\n",
      "Finished! | Return: -1082.2164664583227 | average reward: -5.411082332291613\n",
      "Epsilon: 0.7700431458051551\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 26\n",
      "Finished! | Return: -910.138795715413 | average reward: -4.5506939785770655\n",
      "Epsilon: 0.7623427143471035\n",
      "Best reward: -3.7548580698225074\n",
      "Episode 27\n",
      "Finished! | Return: -742.278411783277 | average reward: -3.7113920589163847\n",
      "Epsilon: 0.7547192872036325\n",
      "Best reward: -3.7548580698225074\n",
      "Saving best model weights for episode 27 with reward -3.7113920589163847\n",
      "Saving weights to best_dqn_weights\n",
      "Episode 28\n",
      "Finished! | Return: -822.1932712385837 | average reward: -4.110966356192919\n",
      "Epsilon: 0.7471720943315961\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 29\n",
      "Finished! | Return: -1296.0999424224722 | average reward: -6.480499712112361\n",
      "Epsilon: 0.7397003733882802\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 30\n",
      "Finished! | Return: -1055.510387919834 | average reward: -5.277551939599171\n",
      "Epsilon: 0.7323033696543974\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 31\n",
      "Finished! | Return: -905.3032251224042 | average reward: -4.526516125612021\n",
      "Epsilon: 0.7249803359578534\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 32\n",
      "Finished! | Return: -1619.0174073603941 | average reward: -8.09508703680197\n",
      "Epsilon: 0.7177305325982748\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 33\n",
      "Finished! | Return: -759.1463045742214 | average reward: -3.795731522871107\n",
      "Epsilon: 0.7105532272722921\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 34\n",
      "Finished! | Return: -856.2787543869193 | average reward: -4.281393771934597\n",
      "Epsilon: 0.7034476949995692\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 35\n",
      "Finished! | Return: -1109.1676272641396 | average reward: -5.545838136320698\n",
      "Epsilon: 0.6964132180495735\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 36\n",
      "Finished! | Return: -749.6208858404851 | average reward: -3.7481044292024257\n",
      "Epsilon: 0.6894490858690777\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 37\n",
      "Finished! | Return: -743.6324861181208 | average reward: -3.718162430590604\n",
      "Epsilon: 0.682554595010387\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 38\n",
      "Finished! | Return: -1285.1391852645313 | average reward: -6.425695926322657\n",
      "Epsilon: 0.6757290490602831\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 39\n",
      "Finished! | Return: -745.9121603204867 | average reward: -3.7295608016024335\n",
      "Epsilon: 0.6689717585696803\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 40\n",
      "Finished! | Return: -862.2924960905518 | average reward: -4.311462480452759\n",
      "Epsilon: 0.6622820409839835\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 41\n",
      "Finished! | Return: -1124.616529203715 | average reward: -5.623082646018575\n",
      "Epsilon: 0.6556592205741436\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 42\n",
      "Finished! | Return: -861.0330716451435 | average reward: -4.305165358225718\n",
      "Epsilon: 0.6491026283684022\n",
      "Best reward: -3.7113920589163847\n",
      "Episode 43\n",
      "Finished! | Return: -525.5632656334359 | average reward: -2.6278163281671794\n",
      "Epsilon: 0.6426116020847181\n",
      "Best reward: -3.7113920589163847\n",
      "Saving best model weights for episode 43 with reward -2.6278163281671794\n",
      "Saving weights to best_dqn_weights\n",
      "Episode 44\n",
      "Finished! | Return: -736.3602105929635 | average reward: -3.6818010529648175\n",
      "Epsilon: 0.6361854860638709\n",
      "Best reward: -2.6278163281671794\n",
      "Episode 45\n",
      "Finished! | Return: -630.8663485136118 | average reward: -3.154331742568059\n",
      "Epsilon: 0.6298236312032323\n",
      "Best reward: -2.6278163281671794\n",
      "Episode 46\n",
      "Finished! | Return: -866.3794266416461 | average reward: -4.331897133208231\n",
      "Epsilon: 0.6235253948912\n",
      "Best reward: -2.6278163281671794\n",
      "Episode 47\n",
      "Finished! | Return: -837.3807248159148 | average reward: -4.186903624079574\n",
      "Epsilon: 0.617290140942288\n",
      "Best reward: -2.6278163281671794\n",
      "Episode 48\n",
      "Finished! | Return: -625.0134103651463 | average reward: -3.1250670518257317\n",
      "Epsilon: 0.6111172395328651\n",
      "Best reward: -2.6278163281671794\n",
      "Episode 49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPISODES):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mOneEpisode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Epsilon \u001b[38;5;241m>\u001b[39m Epsilon_min:\n\u001b[0;32m     17\u001b[0m         Epsilon \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m Epsilon_decay \n",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36mOneEpisode\u001b[1;34m(DQN)\u001b[0m\n\u001b[0;32m     28\u001b[0m SNext, reward, Done, Info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(AStep)\n\u001b[0;32m     29\u001b[0m DQN\u001b[38;5;241m.\u001b[39mUpdateReplayMemory((state, action, reward, SNext, Done))\n\u001b[1;32m---> 30\u001b[0m \u001b[43mDQN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m ListOfRewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Done:\n",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36mDQN.Train\u001b[1;34m(self, EndOfEpisode, reward)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (state, action, reward, SNext, Done) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(TrainingData):\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Done:\n\u001b[1;32m--> 150\u001b[0m         MaxQNext \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43mListOfQNext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    151\u001b[0m         QNext \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGamma \u001b[38;5;241m*\u001b[39m MaxQNext\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\tensor_getitem_override.py:256\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    254\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant_op\u001b[38;5;241m.\u001b[39mconstant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    255\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1096\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[1;32m-> 1096\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:13782\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  13780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m  13781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 13782\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  13783\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  13784\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  13785\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  13787\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "STARTTIME = time.time()\n",
    "\n",
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "dir_path='best_dqn_weights'\n",
    "dqn.load_weights(path=dir_path)\n",
    "\n",
    "Epsilon = 1.0\n",
    "EPISODES = 450\n",
    "best_reward = -1000\n",
    "avg_reward = []\n",
    "for _ in range(EPISODES):\n",
    "\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    if Epsilon > Epsilon_min:\n",
    "        Epsilon *= Epsilon_decay \n",
    "        print('Epsilon:',Epsilon)\n",
    "\n",
    "    dqn.episode_rewards.append(np.sum(reward))\n",
    "    dqn.average_rewards.append(np.mean(reward))\n",
    "    print(f'Best reward: {best_reward}')\n",
    "    if np.mean(reward) > best_reward:\n",
    "        best_reward = np.mean(reward)\n",
    "        dir_path = 'best_dqn_weights'\n",
    "        print(f'Saving best model weights for episode {_} with reward {np.mean(reward)}')\n",
    "        dqn.save_weights(dir_path=dir_path)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "\n",
    "print(f'Total time taken: {time.time() - STARTTIME} seconds ...')\n",
    "\n",
    "\n",
    "# Plot rewards\n",
    "dqn.plot_rewards()\n",
    "\n",
    "dqn.plot_avg_rewards()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85010d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_dqn_weights\n",
      "Episode 0\n",
      "DID NOT TRAIN..., replay memory = 1\n",
      "DID NOT TRAIN..., replay memory = 2\n",
      "DID NOT TRAIN..., replay memory = 3\n",
      "DID NOT TRAIN..., replay memory = 4\n",
      "DID NOT TRAIN..., replay memory = 5\n",
      "DID NOT TRAIN..., replay memory = 6\n",
      "DID NOT TRAIN..., replay memory = 7\n",
      "DID NOT TRAIN..., replay memory = 8\n",
      "DID NOT TRAIN..., replay memory = 9\n",
      "DID NOT TRAIN..., replay memory = 10\n",
      "DID NOT TRAIN..., replay memory = 11\n",
      "DID NOT TRAIN..., replay memory = 12\n",
      "DID NOT TRAIN..., replay memory = 13\n",
      "DID NOT TRAIN..., replay memory = 14\n",
      "DID NOT TRAIN..., replay memory = 15\n",
      "DID NOT TRAIN..., replay memory = 16\n",
      "DID NOT TRAIN..., replay memory = 17\n",
      "DID NOT TRAIN..., replay memory = 18\n",
      "DID NOT TRAIN..., replay memory = 19\n",
      "DID NOT TRAIN..., replay memory = 20\n",
      "DID NOT TRAIN..., replay memory = 21\n",
      "DID NOT TRAIN..., replay memory = 22\n",
      "DID NOT TRAIN..., replay memory = 23\n",
      "DID NOT TRAIN..., replay memory = 24\n",
      "DID NOT TRAIN..., replay memory = 25\n",
      "DID NOT TRAIN..., replay memory = 26\n",
      "DID NOT TRAIN..., replay memory = 27\n",
      "DID NOT TRAIN..., replay memory = 28\n",
      "DID NOT TRAIN..., replay memory = 29\n",
      "DID NOT TRAIN..., replay memory = 30\n",
      "DID NOT TRAIN..., replay memory = 31\n",
      "DID NOT TRAIN..., replay memory = 32\n",
      "DID NOT TRAIN..., replay memory = 33\n",
      "DID NOT TRAIN..., replay memory = 34\n",
      "DID NOT TRAIN..., replay memory = 35\n",
      "DID NOT TRAIN..., replay memory = 36\n",
      "DID NOT TRAIN..., replay memory = 37\n",
      "DID NOT TRAIN..., replay memory = 38\n",
      "DID NOT TRAIN..., replay memory = 39\n",
      "DID NOT TRAIN..., replay memory = 40\n",
      "DID NOT TRAIN..., replay memory = 41\n",
      "DID NOT TRAIN..., replay memory = 42\n",
      "DID NOT TRAIN..., replay memory = 43\n",
      "DID NOT TRAIN..., replay memory = 44\n",
      "DID NOT TRAIN..., replay memory = 45\n",
      "DID NOT TRAIN..., replay memory = 46\n",
      "DID NOT TRAIN..., replay memory = 47\n",
      "DID NOT TRAIN..., replay memory = 48\n",
      "DID NOT TRAIN..., replay memory = 49\n",
      "DID NOT TRAIN..., replay memory = 50\n",
      "DID NOT TRAIN..., replay memory = 51\n",
      "DID NOT TRAIN..., replay memory = 52\n",
      "DID NOT TRAIN..., replay memory = 53\n",
      "DID NOT TRAIN..., replay memory = 54\n",
      "DID NOT TRAIN..., replay memory = 55\n",
      "DID NOT TRAIN..., replay memory = 56\n",
      "DID NOT TRAIN..., replay memory = 57\n",
      "DID NOT TRAIN..., replay memory = 58\n",
      "DID NOT TRAIN..., replay memory = 59\n",
      "DID NOT TRAIN..., replay memory = 60\n",
      "DID NOT TRAIN..., replay memory = 61\n",
      "DID NOT TRAIN..., replay memory = 62\n",
      "DID NOT TRAIN..., replay memory = 63\n",
      "DID NOT TRAIN..., replay memory = 64\n",
      "DID NOT TRAIN..., replay memory = 65\n",
      "DID NOT TRAIN..., replay memory = 66\n",
      "DID NOT TRAIN..., replay memory = 67\n",
      "DID NOT TRAIN..., replay memory = 68\n",
      "DID NOT TRAIN..., replay memory = 69\n",
      "DID NOT TRAIN..., replay memory = 70\n",
      "DID NOT TRAIN..., replay memory = 71\n",
      "DID NOT TRAIN..., replay memory = 72\n",
      "DID NOT TRAIN..., replay memory = 73\n",
      "DID NOT TRAIN..., replay memory = 74\n",
      "DID NOT TRAIN..., replay memory = 75\n",
      "DID NOT TRAIN..., replay memory = 76\n",
      "DID NOT TRAIN..., replay memory = 77\n",
      "DID NOT TRAIN..., replay memory = 78\n",
      "DID NOT TRAIN..., replay memory = 79\n",
      "DID NOT TRAIN..., replay memory = 80\n",
      "DID NOT TRAIN..., replay memory = 81\n",
      "DID NOT TRAIN..., replay memory = 82\n",
      "DID NOT TRAIN..., replay memory = 83\n",
      "DID NOT TRAIN..., replay memory = 84\n",
      "DID NOT TRAIN..., replay memory = 85\n",
      "DID NOT TRAIN..., replay memory = 86\n",
      "DID NOT TRAIN..., replay memory = 87\n",
      "DID NOT TRAIN..., replay memory = 88\n",
      "DID NOT TRAIN..., replay memory = 89\n",
      "DID NOT TRAIN..., replay memory = 90\n",
      "DID NOT TRAIN..., replay memory = 91\n",
      "DID NOT TRAIN..., replay memory = 92\n",
      "DID NOT TRAIN..., replay memory = 93\n",
      "DID NOT TRAIN..., replay memory = 94\n",
      "DID NOT TRAIN..., replay memory = 95\n",
      "DID NOT TRAIN..., replay memory = 96\n",
      "DID NOT TRAIN..., replay memory = 97\n",
      "DID NOT TRAIN..., replay memory = 98\n",
      "DID NOT TRAIN..., replay memory = 99\n",
      "DID NOT TRAIN..., replay memory = 100\n",
      "DID NOT TRAIN..., replay memory = 101\n",
      "DID NOT TRAIN..., replay memory = 102\n",
      "DID NOT TRAIN..., replay memory = 103\n",
      "DID NOT TRAIN..., replay memory = 104\n",
      "DID NOT TRAIN..., replay memory = 105\n",
      "DID NOT TRAIN..., replay memory = 106\n",
      "DID NOT TRAIN..., replay memory = 107\n",
      "DID NOT TRAIN..., replay memory = 108\n",
      "DID NOT TRAIN..., replay memory = 109\n",
      "DID NOT TRAIN..., replay memory = 110\n",
      "DID NOT TRAIN..., replay memory = 111\n",
      "DID NOT TRAIN..., replay memory = 112\n",
      "DID NOT TRAIN..., replay memory = 113\n",
      "DID NOT TRAIN..., replay memory = 114\n",
      "DID NOT TRAIN..., replay memory = 115\n",
      "DID NOT TRAIN..., replay memory = 116\n",
      "DID NOT TRAIN..., replay memory = 117\n",
      "DID NOT TRAIN..., replay memory = 118\n",
      "DID NOT TRAIN..., replay memory = 119\n",
      "DID NOT TRAIN..., replay memory = 120\n",
      "DID NOT TRAIN..., replay memory = 121\n",
      "DID NOT TRAIN..., replay memory = 122\n",
      "DID NOT TRAIN..., replay memory = 123\n",
      "DID NOT TRAIN..., replay memory = 124\n",
      "DID NOT TRAIN..., replay memory = 125\n",
      "DID NOT TRAIN..., replay memory = 126\n",
      "DID NOT TRAIN..., replay memory = 127\n",
      "DID NOT TRAIN..., replay memory = 128\n",
      "DID NOT TRAIN..., replay memory = 129\n",
      "DID NOT TRAIN..., replay memory = 130\n",
      "DID NOT TRAIN..., replay memory = 131\n",
      "DID NOT TRAIN..., replay memory = 132\n",
      "DID NOT TRAIN..., replay memory = 133\n",
      "DID NOT TRAIN..., replay memory = 134\n",
      "DID NOT TRAIN..., replay memory = 135\n",
      "DID NOT TRAIN..., replay memory = 136\n",
      "DID NOT TRAIN..., replay memory = 137\n",
      "DID NOT TRAIN..., replay memory = 138\n",
      "DID NOT TRAIN..., replay memory = 139\n",
      "DID NOT TRAIN..., replay memory = 140\n",
      "DID NOT TRAIN..., replay memory = 141\n",
      "DID NOT TRAIN..., replay memory = 142\n",
      "DID NOT TRAIN..., replay memory = 143\n",
      "DID NOT TRAIN..., replay memory = 144\n",
      "DID NOT TRAIN..., replay memory = 145\n",
      "DID NOT TRAIN..., replay memory = 146\n",
      "DID NOT TRAIN..., replay memory = 147\n",
      "DID NOT TRAIN..., replay memory = 148\n",
      "DID NOT TRAIN..., replay memory = 149\n",
      "DID NOT TRAIN..., replay memory = 150\n",
      "DID NOT TRAIN..., replay memory = 151\n",
      "DID NOT TRAIN..., replay memory = 152\n",
      "DID NOT TRAIN..., replay memory = 153\n",
      "DID NOT TRAIN..., replay memory = 154\n",
      "DID NOT TRAIN..., replay memory = 155\n",
      "DID NOT TRAIN..., replay memory = 156\n",
      "DID NOT TRAIN..., replay memory = 157\n",
      "DID NOT TRAIN..., replay memory = 158\n",
      "DID NOT TRAIN..., replay memory = 159\n",
      "DID NOT TRAIN..., replay memory = 160\n",
      "DID NOT TRAIN..., replay memory = 161\n",
      "DID NOT TRAIN..., replay memory = 162\n",
      "DID NOT TRAIN..., replay memory = 163\n",
      "DID NOT TRAIN..., replay memory = 164\n",
      "DID NOT TRAIN..., replay memory = 165\n",
      "DID NOT TRAIN..., replay memory = 166\n",
      "DID NOT TRAIN..., replay memory = 167\n",
      "DID NOT TRAIN..., replay memory = 168\n",
      "DID NOT TRAIN..., replay memory = 169\n",
      "DID NOT TRAIN..., replay memory = 170\n",
      "DID NOT TRAIN..., replay memory = 171\n",
      "DID NOT TRAIN..., replay memory = 172\n",
      "DID NOT TRAIN..., replay memory = 173\n",
      "DID NOT TRAIN..., replay memory = 174\n",
      "DID NOT TRAIN..., replay memory = 175\n",
      "DID NOT TRAIN..., replay memory = 176\n",
      "DID NOT TRAIN..., replay memory = 177\n",
      "DID NOT TRAIN..., replay memory = 178\n",
      "DID NOT TRAIN..., replay memory = 179\n",
      "DID NOT TRAIN..., replay memory = 180\n",
      "DID NOT TRAIN..., replay memory = 181\n",
      "DID NOT TRAIN..., replay memory = 182\n",
      "DID NOT TRAIN..., replay memory = 183\n",
      "DID NOT TRAIN..., replay memory = 184\n",
      "DID NOT TRAIN..., replay memory = 185\n",
      "DID NOT TRAIN..., replay memory = 186\n",
      "DID NOT TRAIN..., replay memory = 187\n",
      "DID NOT TRAIN..., replay memory = 188\n",
      "DID NOT TRAIN..., replay memory = 189\n",
      "DID NOT TRAIN..., replay memory = 190\n",
      "DID NOT TRAIN..., replay memory = 191\n",
      "DID NOT TRAIN..., replay memory = 192\n",
      "DID NOT TRAIN..., replay memory = 193\n",
      "DID NOT TRAIN..., replay memory = 194\n",
      "DID NOT TRAIN..., replay memory = 195\n",
      "DID NOT TRAIN..., replay memory = 196\n",
      "DID NOT TRAIN..., replay memory = 197\n",
      "DID NOT TRAIN..., replay memory = 198\n",
      "DID NOT TRAIN..., replay memory = 199\n",
      "DID NOT TRAIN..., replay memory = 200\n",
      "Finished! | Return: -252.74452823352195 | average reward: -1.2637226411676097\n",
      "Episode 1\n",
      "DID NOT TRAIN..., replay memory = 201\n",
      "DID NOT TRAIN..., replay memory = 202\n",
      "DID NOT TRAIN..., replay memory = 203\n",
      "DID NOT TRAIN..., replay memory = 204\n",
      "DID NOT TRAIN..., replay memory = 205\n",
      "DID NOT TRAIN..., replay memory = 206\n",
      "DID NOT TRAIN..., replay memory = 207\n",
      "DID NOT TRAIN..., replay memory = 208\n",
      "DID NOT TRAIN..., replay memory = 209\n",
      "DID NOT TRAIN..., replay memory = 210\n",
      "DID NOT TRAIN..., replay memory = 211\n",
      "DID NOT TRAIN..., replay memory = 212\n",
      "DID NOT TRAIN..., replay memory = 213\n",
      "DID NOT TRAIN..., replay memory = 214\n",
      "DID NOT TRAIN..., replay memory = 215\n",
      "DID NOT TRAIN..., replay memory = 216\n",
      "DID NOT TRAIN..., replay memory = 217\n",
      "DID NOT TRAIN..., replay memory = 218\n",
      "DID NOT TRAIN..., replay memory = 219\n",
      "DID NOT TRAIN..., replay memory = 220\n",
      "DID NOT TRAIN..., replay memory = 221\n",
      "DID NOT TRAIN..., replay memory = 222\n",
      "DID NOT TRAIN..., replay memory = 223\n",
      "DID NOT TRAIN..., replay memory = 224\n",
      "DID NOT TRAIN..., replay memory = 225\n",
      "DID NOT TRAIN..., replay memory = 226\n",
      "DID NOT TRAIN..., replay memory = 227\n",
      "DID NOT TRAIN..., replay memory = 228\n",
      "DID NOT TRAIN..., replay memory = 229\n",
      "DID NOT TRAIN..., replay memory = 230\n",
      "DID NOT TRAIN..., replay memory = 231\n",
      "DID NOT TRAIN..., replay memory = 232\n",
      "DID NOT TRAIN..., replay memory = 233\n",
      "DID NOT TRAIN..., replay memory = 234\n",
      "DID NOT TRAIN..., replay memory = 235\n",
      "DID NOT TRAIN..., replay memory = 236\n",
      "DID NOT TRAIN..., replay memory = 237\n",
      "DID NOT TRAIN..., replay memory = 238\n",
      "DID NOT TRAIN..., replay memory = 239\n",
      "DID NOT TRAIN..., replay memory = 240\n",
      "DID NOT TRAIN..., replay memory = 241\n",
      "DID NOT TRAIN..., replay memory = 242\n",
      "DID NOT TRAIN..., replay memory = 243\n",
      "DID NOT TRAIN..., replay memory = 244\n",
      "DID NOT TRAIN..., replay memory = 245\n",
      "DID NOT TRAIN..., replay memory = 246\n",
      "DID NOT TRAIN..., replay memory = 247\n",
      "DID NOT TRAIN..., replay memory = 248\n",
      "DID NOT TRAIN..., replay memory = 249\n",
      "DID NOT TRAIN..., replay memory = 250\n",
      "DID NOT TRAIN..., replay memory = 251\n",
      "DID NOT TRAIN..., replay memory = 252\n",
      "DID NOT TRAIN..., replay memory = 253\n",
      "DID NOT TRAIN..., replay memory = 254\n",
      "DID NOT TRAIN..., replay memory = 255\n",
      "DID NOT TRAIN..., replay memory = 256\n",
      "DID NOT TRAIN..., replay memory = 257\n",
      "DID NOT TRAIN..., replay memory = 258\n",
      "DID NOT TRAIN..., replay memory = 259\n",
      "DID NOT TRAIN..., replay memory = 260\n",
      "DID NOT TRAIN..., replay memory = 261\n",
      "DID NOT TRAIN..., replay memory = 262\n",
      "DID NOT TRAIN..., replay memory = 263\n",
      "DID NOT TRAIN..., replay memory = 264\n",
      "DID NOT TRAIN..., replay memory = 265\n",
      "DID NOT TRAIN..., replay memory = 266\n",
      "DID NOT TRAIN..., replay memory = 267\n",
      "DID NOT TRAIN..., replay memory = 268\n",
      "DID NOT TRAIN..., replay memory = 269\n",
      "DID NOT TRAIN..., replay memory = 270\n",
      "DID NOT TRAIN..., replay memory = 271\n",
      "DID NOT TRAIN..., replay memory = 272\n",
      "DID NOT TRAIN..., replay memory = 273\n",
      "DID NOT TRAIN..., replay memory = 274\n",
      "DID NOT TRAIN..., replay memory = 275\n",
      "DID NOT TRAIN..., replay memory = 276\n",
      "DID NOT TRAIN..., replay memory = 277\n",
      "DID NOT TRAIN..., replay memory = 278\n",
      "DID NOT TRAIN..., replay memory = 279\n",
      "DID NOT TRAIN..., replay memory = 280\n",
      "DID NOT TRAIN..., replay memory = 281\n",
      "DID NOT TRAIN..., replay memory = 282\n",
      "DID NOT TRAIN..., replay memory = 283\n",
      "DID NOT TRAIN..., replay memory = 284\n",
      "DID NOT TRAIN..., replay memory = 285\n",
      "DID NOT TRAIN..., replay memory = 286\n",
      "DID NOT TRAIN..., replay memory = 287\n",
      "DID NOT TRAIN..., replay memory = 288\n",
      "DID NOT TRAIN..., replay memory = 289\n",
      "DID NOT TRAIN..., replay memory = 290\n",
      "DID NOT TRAIN..., replay memory = 291\n",
      "DID NOT TRAIN..., replay memory = 292\n",
      "DID NOT TRAIN..., replay memory = 293\n",
      "DID NOT TRAIN..., replay memory = 294\n",
      "DID NOT TRAIN..., replay memory = 295\n",
      "DID NOT TRAIN..., replay memory = 296\n",
      "DID NOT TRAIN..., replay memory = 297\n",
      "DID NOT TRAIN..., replay memory = 298\n",
      "DID NOT TRAIN..., replay memory = 299\n",
      "DID NOT TRAIN..., replay memory = 300\n",
      "DID NOT TRAIN..., replay memory = 301\n",
      "DID NOT TRAIN..., replay memory = 302\n",
      "DID NOT TRAIN..., replay memory = 303\n",
      "DID NOT TRAIN..., replay memory = 304\n",
      "DID NOT TRAIN..., replay memory = 305\n",
      "DID NOT TRAIN..., replay memory = 306\n",
      "DID NOT TRAIN..., replay memory = 307\n",
      "DID NOT TRAIN..., replay memory = 308\n",
      "DID NOT TRAIN..., replay memory = 309\n",
      "DID NOT TRAIN..., replay memory = 310\n",
      "DID NOT TRAIN..., replay memory = 311\n",
      "DID NOT TRAIN..., replay memory = 312\n",
      "DID NOT TRAIN..., replay memory = 313\n",
      "DID NOT TRAIN..., replay memory = 314\n",
      "DID NOT TRAIN..., replay memory = 315\n",
      "DID NOT TRAIN..., replay memory = 316\n",
      "DID NOT TRAIN..., replay memory = 317\n",
      "DID NOT TRAIN..., replay memory = 318\n",
      "DID NOT TRAIN..., replay memory = 319\n",
      "DID NOT TRAIN..., replay memory = 320\n",
      "DID NOT TRAIN..., replay memory = 321\n",
      "DID NOT TRAIN..., replay memory = 322\n",
      "DID NOT TRAIN..., replay memory = 323\n",
      "DID NOT TRAIN..., replay memory = 324\n",
      "DID NOT TRAIN..., replay memory = 325\n",
      "DID NOT TRAIN..., replay memory = 326\n",
      "DID NOT TRAIN..., replay memory = 327\n",
      "DID NOT TRAIN..., replay memory = 328\n",
      "DID NOT TRAIN..., replay memory = 329\n",
      "DID NOT TRAIN..., replay memory = 330\n",
      "DID NOT TRAIN..., replay memory = 331\n",
      "DID NOT TRAIN..., replay memory = 332\n",
      "DID NOT TRAIN..., replay memory = 333\n",
      "DID NOT TRAIN..., replay memory = 334\n",
      "DID NOT TRAIN..., replay memory = 335\n",
      "DID NOT TRAIN..., replay memory = 336\n",
      "DID NOT TRAIN..., replay memory = 337\n",
      "DID NOT TRAIN..., replay memory = 338\n",
      "DID NOT TRAIN..., replay memory = 339\n",
      "DID NOT TRAIN..., replay memory = 340\n",
      "DID NOT TRAIN..., replay memory = 341\n",
      "DID NOT TRAIN..., replay memory = 342\n",
      "DID NOT TRAIN..., replay memory = 343\n",
      "DID NOT TRAIN..., replay memory = 344\n",
      "DID NOT TRAIN..., replay memory = 345\n",
      "DID NOT TRAIN..., replay memory = 346\n",
      "DID NOT TRAIN..., replay memory = 347\n",
      "DID NOT TRAIN..., replay memory = 348\n",
      "DID NOT TRAIN..., replay memory = 349\n",
      "DID NOT TRAIN..., replay memory = 350\n",
      "DID NOT TRAIN..., replay memory = 351\n",
      "DID NOT TRAIN..., replay memory = 352\n",
      "DID NOT TRAIN..., replay memory = 353\n",
      "DID NOT TRAIN..., replay memory = 354\n",
      "DID NOT TRAIN..., replay memory = 355\n",
      "DID NOT TRAIN..., replay memory = 356\n",
      "DID NOT TRAIN..., replay memory = 357\n",
      "DID NOT TRAIN..., replay memory = 358\n",
      "DID NOT TRAIN..., replay memory = 359\n",
      "DID NOT TRAIN..., replay memory = 360\n",
      "DID NOT TRAIN..., replay memory = 361\n",
      "DID NOT TRAIN..., replay memory = 362\n",
      "DID NOT TRAIN..., replay memory = 363\n",
      "DID NOT TRAIN..., replay memory = 364\n",
      "DID NOT TRAIN..., replay memory = 365\n",
      "DID NOT TRAIN..., replay memory = 366\n",
      "DID NOT TRAIN..., replay memory = 367\n",
      "DID NOT TRAIN..., replay memory = 368\n",
      "DID NOT TRAIN..., replay memory = 369\n",
      "DID NOT TRAIN..., replay memory = 370\n",
      "DID NOT TRAIN..., replay memory = 371\n",
      "DID NOT TRAIN..., replay memory = 372\n",
      "DID NOT TRAIN..., replay memory = 373\n",
      "DID NOT TRAIN..., replay memory = 374\n",
      "DID NOT TRAIN..., replay memory = 375\n",
      "DID NOT TRAIN..., replay memory = 376\n",
      "DID NOT TRAIN..., replay memory = 377\n",
      "DID NOT TRAIN..., replay memory = 378\n",
      "DID NOT TRAIN..., replay memory = 379\n",
      "DID NOT TRAIN..., replay memory = 380\n",
      "DID NOT TRAIN..., replay memory = 381\n",
      "DID NOT TRAIN..., replay memory = 382\n",
      "DID NOT TRAIN..., replay memory = 383\n",
      "DID NOT TRAIN..., replay memory = 384\n",
      "DID NOT TRAIN..., replay memory = 385\n",
      "DID NOT TRAIN..., replay memory = 386\n",
      "DID NOT TRAIN..., replay memory = 387\n",
      "DID NOT TRAIN..., replay memory = 388\n",
      "DID NOT TRAIN..., replay memory = 389\n",
      "DID NOT TRAIN..., replay memory = 390\n",
      "DID NOT TRAIN..., replay memory = 391\n",
      "DID NOT TRAIN..., replay memory = 392\n",
      "DID NOT TRAIN..., replay memory = 393\n",
      "DID NOT TRAIN..., replay memory = 394\n",
      "DID NOT TRAIN..., replay memory = 395\n",
      "DID NOT TRAIN..., replay memory = 396\n",
      "DID NOT TRAIN..., replay memory = 397\n",
      "DID NOT TRAIN..., replay memory = 398\n",
      "DID NOT TRAIN..., replay memory = 399\n",
      "DID NOT TRAIN..., replay memory = 400\n",
      "Finished! | Return: -122.1563149463418 | average reward: -0.610781574731709\n",
      "Episode 2\n",
      "DID NOT TRAIN..., replay memory = 401\n",
      "DID NOT TRAIN..., replay memory = 402\n",
      "DID NOT TRAIN..., replay memory = 403\n",
      "DID NOT TRAIN..., replay memory = 404\n",
      "DID NOT TRAIN..., replay memory = 405\n",
      "DID NOT TRAIN..., replay memory = 406\n",
      "DID NOT TRAIN..., replay memory = 407\n",
      "DID NOT TRAIN..., replay memory = 408\n",
      "DID NOT TRAIN..., replay memory = 409\n",
      "DID NOT TRAIN..., replay memory = 410\n",
      "DID NOT TRAIN..., replay memory = 411\n",
      "DID NOT TRAIN..., replay memory = 412\n",
      "DID NOT TRAIN..., replay memory = 413\n",
      "DID NOT TRAIN..., replay memory = 414\n",
      "DID NOT TRAIN..., replay memory = 415\n",
      "DID NOT TRAIN..., replay memory = 416\n",
      "DID NOT TRAIN..., replay memory = 417\n",
      "DID NOT TRAIN..., replay memory = 418\n",
      "DID NOT TRAIN..., replay memory = 419\n",
      "DID NOT TRAIN..., replay memory = 420\n",
      "DID NOT TRAIN..., replay memory = 421\n",
      "DID NOT TRAIN..., replay memory = 422\n",
      "DID NOT TRAIN..., replay memory = 423\n",
      "DID NOT TRAIN..., replay memory = 424\n",
      "DID NOT TRAIN..., replay memory = 425\n",
      "DID NOT TRAIN..., replay memory = 426\n",
      "DID NOT TRAIN..., replay memory = 427\n",
      "DID NOT TRAIN..., replay memory = 428\n",
      "DID NOT TRAIN..., replay memory = 429\n",
      "DID NOT TRAIN..., replay memory = 430\n",
      "DID NOT TRAIN..., replay memory = 431\n",
      "DID NOT TRAIN..., replay memory = 432\n",
      "DID NOT TRAIN..., replay memory = 433\n",
      "DID NOT TRAIN..., replay memory = 434\n",
      "DID NOT TRAIN..., replay memory = 435\n",
      "DID NOT TRAIN..., replay memory = 436\n",
      "DID NOT TRAIN..., replay memory = 437\n",
      "DID NOT TRAIN..., replay memory = 438\n",
      "DID NOT TRAIN..., replay memory = 439\n",
      "DID NOT TRAIN..., replay memory = 440\n",
      "DID NOT TRAIN..., replay memory = 441\n",
      "DID NOT TRAIN..., replay memory = 442\n",
      "DID NOT TRAIN..., replay memory = 443\n",
      "DID NOT TRAIN..., replay memory = 444\n",
      "DID NOT TRAIN..., replay memory = 445\n",
      "DID NOT TRAIN..., replay memory = 446\n",
      "DID NOT TRAIN..., replay memory = 447\n",
      "DID NOT TRAIN..., replay memory = 448\n",
      "DID NOT TRAIN..., replay memory = 449\n",
      "DID NOT TRAIN..., replay memory = 450\n",
      "DID NOT TRAIN..., replay memory = 451\n",
      "DID NOT TRAIN..., replay memory = 452\n",
      "DID NOT TRAIN..., replay memory = 453\n",
      "DID NOT TRAIN..., replay memory = 454\n",
      "DID NOT TRAIN..., replay memory = 455\n",
      "DID NOT TRAIN..., replay memory = 456\n",
      "DID NOT TRAIN..., replay memory = 457\n",
      "DID NOT TRAIN..., replay memory = 458\n",
      "DID NOT TRAIN..., replay memory = 459\n",
      "DID NOT TRAIN..., replay memory = 460\n",
      "DID NOT TRAIN..., replay memory = 461\n",
      "DID NOT TRAIN..., replay memory = 462\n",
      "DID NOT TRAIN..., replay memory = 463\n",
      "DID NOT TRAIN..., replay memory = 464\n",
      "DID NOT TRAIN..., replay memory = 465\n",
      "DID NOT TRAIN..., replay memory = 466\n",
      "DID NOT TRAIN..., replay memory = 467\n",
      "DID NOT TRAIN..., replay memory = 468\n",
      "DID NOT TRAIN..., replay memory = 469\n",
      "DID NOT TRAIN..., replay memory = 470\n",
      "DID NOT TRAIN..., replay memory = 471\n",
      "DID NOT TRAIN..., replay memory = 472\n",
      "DID NOT TRAIN..., replay memory = 473\n",
      "DID NOT TRAIN..., replay memory = 474\n",
      "DID NOT TRAIN..., replay memory = 475\n",
      "DID NOT TRAIN..., replay memory = 476\n",
      "DID NOT TRAIN..., replay memory = 477\n",
      "DID NOT TRAIN..., replay memory = 478\n",
      "DID NOT TRAIN..., replay memory = 479\n",
      "DID NOT TRAIN..., replay memory = 480\n",
      "DID NOT TRAIN..., replay memory = 481\n",
      "DID NOT TRAIN..., replay memory = 482\n",
      "DID NOT TRAIN..., replay memory = 483\n",
      "DID NOT TRAIN..., replay memory = 484\n",
      "DID NOT TRAIN..., replay memory = 485\n",
      "DID NOT TRAIN..., replay memory = 486\n",
      "DID NOT TRAIN..., replay memory = 487\n",
      "DID NOT TRAIN..., replay memory = 488\n",
      "DID NOT TRAIN..., replay memory = 489\n",
      "DID NOT TRAIN..., replay memory = 490\n",
      "DID NOT TRAIN..., replay memory = 491\n",
      "DID NOT TRAIN..., replay memory = 492\n",
      "DID NOT TRAIN..., replay memory = 493\n",
      "DID NOT TRAIN..., replay memory = 494\n",
      "DID NOT TRAIN..., replay memory = 495\n",
      "DID NOT TRAIN..., replay memory = 496\n",
      "DID NOT TRAIN..., replay memory = 497\n",
      "DID NOT TRAIN..., replay memory = 498\n",
      "DID NOT TRAIN..., replay memory = 499\n",
      "DID NOT TRAIN..., replay memory = 500\n",
      "DID NOT TRAIN..., replay memory = 501\n",
      "DID NOT TRAIN..., replay memory = 502\n",
      "DID NOT TRAIN..., replay memory = 503\n",
      "DID NOT TRAIN..., replay memory = 504\n",
      "DID NOT TRAIN..., replay memory = 505\n",
      "DID NOT TRAIN..., replay memory = 506\n",
      "DID NOT TRAIN..., replay memory = 507\n",
      "DID NOT TRAIN..., replay memory = 508\n",
      "DID NOT TRAIN..., replay memory = 509\n",
      "DID NOT TRAIN..., replay memory = 510\n",
      "DID NOT TRAIN..., replay memory = 511\n",
      "DID NOT TRAIN..., replay memory = 512\n",
      "DID NOT TRAIN..., replay memory = 513\n",
      "DID NOT TRAIN..., replay memory = 514\n",
      "DID NOT TRAIN..., replay memory = 515\n",
      "DID NOT TRAIN..., replay memory = 516\n",
      "DID NOT TRAIN..., replay memory = 517\n",
      "DID NOT TRAIN..., replay memory = 518\n",
      "DID NOT TRAIN..., replay memory = 519\n",
      "DID NOT TRAIN..., replay memory = 520\n",
      "DID NOT TRAIN..., replay memory = 521\n",
      "DID NOT TRAIN..., replay memory = 522\n",
      "DID NOT TRAIN..., replay memory = 523\n",
      "DID NOT TRAIN..., replay memory = 524\n",
      "DID NOT TRAIN..., replay memory = 525\n",
      "DID NOT TRAIN..., replay memory = 526\n",
      "DID NOT TRAIN..., replay memory = 527\n",
      "DID NOT TRAIN..., replay memory = 528\n",
      "DID NOT TRAIN..., replay memory = 529\n",
      "DID NOT TRAIN..., replay memory = 530\n",
      "DID NOT TRAIN..., replay memory = 531\n",
      "DID NOT TRAIN..., replay memory = 532\n",
      "DID NOT TRAIN..., replay memory = 533\n",
      "DID NOT TRAIN..., replay memory = 534\n",
      "DID NOT TRAIN..., replay memory = 535\n",
      "DID NOT TRAIN..., replay memory = 536\n",
      "DID NOT TRAIN..., replay memory = 537\n",
      "DID NOT TRAIN..., replay memory = 538\n",
      "DID NOT TRAIN..., replay memory = 539\n",
      "DID NOT TRAIN..., replay memory = 540\n",
      "DID NOT TRAIN..., replay memory = 541\n",
      "DID NOT TRAIN..., replay memory = 542\n",
      "DID NOT TRAIN..., replay memory = 543\n",
      "DID NOT TRAIN..., replay memory = 544\n",
      "DID NOT TRAIN..., replay memory = 545\n",
      "DID NOT TRAIN..., replay memory = 546\n",
      "DID NOT TRAIN..., replay memory = 547\n",
      "DID NOT TRAIN..., replay memory = 548\n",
      "DID NOT TRAIN..., replay memory = 549\n",
      "DID NOT TRAIN..., replay memory = 550\n",
      "DID NOT TRAIN..., replay memory = 551\n",
      "DID NOT TRAIN..., replay memory = 552\n",
      "DID NOT TRAIN..., replay memory = 553\n",
      "DID NOT TRAIN..., replay memory = 554\n",
      "DID NOT TRAIN..., replay memory = 555\n",
      "DID NOT TRAIN..., replay memory = 556\n",
      "DID NOT TRAIN..., replay memory = 557\n",
      "DID NOT TRAIN..., replay memory = 558\n",
      "DID NOT TRAIN..., replay memory = 559\n",
      "DID NOT TRAIN..., replay memory = 560\n",
      "DID NOT TRAIN..., replay memory = 561\n",
      "DID NOT TRAIN..., replay memory = 562\n",
      "DID NOT TRAIN..., replay memory = 563\n",
      "DID NOT TRAIN..., replay memory = 564\n",
      "DID NOT TRAIN..., replay memory = 565\n",
      "DID NOT TRAIN..., replay memory = 566\n",
      "DID NOT TRAIN..., replay memory = 567\n",
      "DID NOT TRAIN..., replay memory = 568\n",
      "DID NOT TRAIN..., replay memory = 569\n",
      "DID NOT TRAIN..., replay memory = 570\n",
      "DID NOT TRAIN..., replay memory = 571\n",
      "DID NOT TRAIN..., replay memory = 572\n",
      "DID NOT TRAIN..., replay memory = 573\n",
      "DID NOT TRAIN..., replay memory = 574\n",
      "DID NOT TRAIN..., replay memory = 575\n",
      "DID NOT TRAIN..., replay memory = 576\n",
      "DID NOT TRAIN..., replay memory = 577\n",
      "DID NOT TRAIN..., replay memory = 578\n",
      "DID NOT TRAIN..., replay memory = 579\n",
      "DID NOT TRAIN..., replay memory = 580\n",
      "DID NOT TRAIN..., replay memory = 581\n",
      "DID NOT TRAIN..., replay memory = 582\n",
      "DID NOT TRAIN..., replay memory = 583\n",
      "DID NOT TRAIN..., replay memory = 584\n",
      "DID NOT TRAIN..., replay memory = 585\n",
      "DID NOT TRAIN..., replay memory = 586\n",
      "DID NOT TRAIN..., replay memory = 587\n",
      "DID NOT TRAIN..., replay memory = 588\n",
      "DID NOT TRAIN..., replay memory = 589\n",
      "DID NOT TRAIN..., replay memory = 590\n",
      "DID NOT TRAIN..., replay memory = 591\n",
      "DID NOT TRAIN..., replay memory = 592\n",
      "DID NOT TRAIN..., replay memory = 593\n",
      "DID NOT TRAIN..., replay memory = 594\n",
      "DID NOT TRAIN..., replay memory = 595\n",
      "DID NOT TRAIN..., replay memory = 596\n",
      "DID NOT TRAIN..., replay memory = 597\n",
      "DID NOT TRAIN..., replay memory = 598\n",
      "DID NOT TRAIN..., replay memory = 599\n",
      "DID NOT TRAIN..., replay memory = 600\n",
      "Finished! | Return: -374.34439420805245 | average reward: -1.8717219710402622\n",
      "Episode 3\n",
      "DID NOT TRAIN..., replay memory = 601\n",
      "DID NOT TRAIN..., replay memory = 602\n",
      "DID NOT TRAIN..., replay memory = 603\n",
      "DID NOT TRAIN..., replay memory = 604\n",
      "DID NOT TRAIN..., replay memory = 605\n",
      "DID NOT TRAIN..., replay memory = 606\n",
      "DID NOT TRAIN..., replay memory = 607\n",
      "DID NOT TRAIN..., replay memory = 608\n",
      "DID NOT TRAIN..., replay memory = 609\n",
      "DID NOT TRAIN..., replay memory = 610\n",
      "DID NOT TRAIN..., replay memory = 611\n",
      "DID NOT TRAIN..., replay memory = 612\n",
      "DID NOT TRAIN..., replay memory = 613\n",
      "DID NOT TRAIN..., replay memory = 614\n",
      "DID NOT TRAIN..., replay memory = 615\n",
      "DID NOT TRAIN..., replay memory = 616\n",
      "DID NOT TRAIN..., replay memory = 617\n",
      "DID NOT TRAIN..., replay memory = 618\n",
      "DID NOT TRAIN..., replay memory = 619\n",
      "DID NOT TRAIN..., replay memory = 620\n",
      "DID NOT TRAIN..., replay memory = 621\n",
      "DID NOT TRAIN..., replay memory = 622\n",
      "DID NOT TRAIN..., replay memory = 623\n",
      "DID NOT TRAIN..., replay memory = 624\n",
      "DID NOT TRAIN..., replay memory = 625\n",
      "DID NOT TRAIN..., replay memory = 626\n",
      "DID NOT TRAIN..., replay memory = 627\n",
      "DID NOT TRAIN..., replay memory = 628\n",
      "DID NOT TRAIN..., replay memory = 629\n",
      "DID NOT TRAIN..., replay memory = 630\n",
      "DID NOT TRAIN..., replay memory = 631\n",
      "DID NOT TRAIN..., replay memory = 632\n",
      "DID NOT TRAIN..., replay memory = 633\n",
      "DID NOT TRAIN..., replay memory = 634\n",
      "DID NOT TRAIN..., replay memory = 635\n",
      "DID NOT TRAIN..., replay memory = 636\n",
      "DID NOT TRAIN..., replay memory = 637\n",
      "DID NOT TRAIN..., replay memory = 638\n",
      "DID NOT TRAIN..., replay memory = 639\n",
      "DID NOT TRAIN..., replay memory = 640\n",
      "DID NOT TRAIN..., replay memory = 641\n",
      "DID NOT TRAIN..., replay memory = 642\n",
      "DID NOT TRAIN..., replay memory = 643\n",
      "DID NOT TRAIN..., replay memory = 644\n",
      "DID NOT TRAIN..., replay memory = 645\n",
      "DID NOT TRAIN..., replay memory = 646\n",
      "DID NOT TRAIN..., replay memory = 647\n",
      "DID NOT TRAIN..., replay memory = 648\n",
      "DID NOT TRAIN..., replay memory = 649\n",
      "DID NOT TRAIN..., replay memory = 650\n",
      "DID NOT TRAIN..., replay memory = 651\n",
      "DID NOT TRAIN..., replay memory = 652\n",
      "DID NOT TRAIN..., replay memory = 653\n",
      "DID NOT TRAIN..., replay memory = 654\n",
      "DID NOT TRAIN..., replay memory = 655\n",
      "DID NOT TRAIN..., replay memory = 656\n",
      "DID NOT TRAIN..., replay memory = 657\n",
      "DID NOT TRAIN..., replay memory = 658\n",
      "DID NOT TRAIN..., replay memory = 659\n",
      "DID NOT TRAIN..., replay memory = 660\n",
      "DID NOT TRAIN..., replay memory = 661\n",
      "DID NOT TRAIN..., replay memory = 662\n",
      "DID NOT TRAIN..., replay memory = 663\n",
      "DID NOT TRAIN..., replay memory = 664\n",
      "DID NOT TRAIN..., replay memory = 665\n",
      "DID NOT TRAIN..., replay memory = 666\n",
      "DID NOT TRAIN..., replay memory = 667\n",
      "DID NOT TRAIN..., replay memory = 668\n",
      "DID NOT TRAIN..., replay memory = 669\n",
      "DID NOT TRAIN..., replay memory = 670\n",
      "DID NOT TRAIN..., replay memory = 671\n",
      "DID NOT TRAIN..., replay memory = 672\n",
      "DID NOT TRAIN..., replay memory = 673\n",
      "DID NOT TRAIN..., replay memory = 674\n",
      "DID NOT TRAIN..., replay memory = 675\n",
      "DID NOT TRAIN..., replay memory = 676\n",
      "DID NOT TRAIN..., replay memory = 677\n",
      "DID NOT TRAIN..., replay memory = 678\n",
      "DID NOT TRAIN..., replay memory = 679\n",
      "DID NOT TRAIN..., replay memory = 680\n",
      "DID NOT TRAIN..., replay memory = 681\n",
      "DID NOT TRAIN..., replay memory = 682\n",
      "DID NOT TRAIN..., replay memory = 683\n",
      "DID NOT TRAIN..., replay memory = 684\n",
      "DID NOT TRAIN..., replay memory = 685\n",
      "DID NOT TRAIN..., replay memory = 686\n",
      "DID NOT TRAIN..., replay memory = 687\n",
      "DID NOT TRAIN..., replay memory = 688\n",
      "DID NOT TRAIN..., replay memory = 689\n",
      "DID NOT TRAIN..., replay memory = 690\n",
      "DID NOT TRAIN..., replay memory = 691\n",
      "DID NOT TRAIN..., replay memory = 692\n",
      "DID NOT TRAIN..., replay memory = 693\n",
      "DID NOT TRAIN..., replay memory = 694\n",
      "DID NOT TRAIN..., replay memory = 695\n",
      "DID NOT TRAIN..., replay memory = 696\n",
      "DID NOT TRAIN..., replay memory = 697\n",
      "DID NOT TRAIN..., replay memory = 698\n",
      "DID NOT TRAIN..., replay memory = 699\n",
      "DID NOT TRAIN..., replay memory = 700\n",
      "DID NOT TRAIN..., replay memory = 701\n",
      "DID NOT TRAIN..., replay memory = 702\n",
      "DID NOT TRAIN..., replay memory = 703\n",
      "DID NOT TRAIN..., replay memory = 704\n",
      "DID NOT TRAIN..., replay memory = 705\n",
      "DID NOT TRAIN..., replay memory = 706\n",
      "DID NOT TRAIN..., replay memory = 707\n",
      "DID NOT TRAIN..., replay memory = 708\n",
      "DID NOT TRAIN..., replay memory = 709\n",
      "DID NOT TRAIN..., replay memory = 710\n",
      "DID NOT TRAIN..., replay memory = 711\n",
      "DID NOT TRAIN..., replay memory = 712\n",
      "DID NOT TRAIN..., replay memory = 713\n",
      "DID NOT TRAIN..., replay memory = 714\n",
      "DID NOT TRAIN..., replay memory = 715\n",
      "DID NOT TRAIN..., replay memory = 716\n",
      "DID NOT TRAIN..., replay memory = 717\n",
      "DID NOT TRAIN..., replay memory = 718\n",
      "DID NOT TRAIN..., replay memory = 719\n",
      "DID NOT TRAIN..., replay memory = 720\n",
      "DID NOT TRAIN..., replay memory = 721\n",
      "DID NOT TRAIN..., replay memory = 722\n",
      "DID NOT TRAIN..., replay memory = 723\n",
      "DID NOT TRAIN..., replay memory = 724\n",
      "DID NOT TRAIN..., replay memory = 725\n",
      "DID NOT TRAIN..., replay memory = 726\n",
      "DID NOT TRAIN..., replay memory = 727\n",
      "DID NOT TRAIN..., replay memory = 728\n",
      "DID NOT TRAIN..., replay memory = 729\n",
      "DID NOT TRAIN..., replay memory = 730\n",
      "DID NOT TRAIN..., replay memory = 731\n",
      "DID NOT TRAIN..., replay memory = 732\n",
      "DID NOT TRAIN..., replay memory = 733\n",
      "DID NOT TRAIN..., replay memory = 734\n",
      "DID NOT TRAIN..., replay memory = 735\n",
      "DID NOT TRAIN..., replay memory = 736\n",
      "DID NOT TRAIN..., replay memory = 737\n",
      "DID NOT TRAIN..., replay memory = 738\n",
      "DID NOT TRAIN..., replay memory = 739\n",
      "DID NOT TRAIN..., replay memory = 740\n",
      "DID NOT TRAIN..., replay memory = 741\n",
      "DID NOT TRAIN..., replay memory = 742\n",
      "DID NOT TRAIN..., replay memory = 743\n",
      "DID NOT TRAIN..., replay memory = 744\n",
      "DID NOT TRAIN..., replay memory = 745\n",
      "DID NOT TRAIN..., replay memory = 746\n",
      "DID NOT TRAIN..., replay memory = 747\n",
      "DID NOT TRAIN..., replay memory = 748\n",
      "DID NOT TRAIN..., replay memory = 749\n",
      "DID NOT TRAIN..., replay memory = 750\n",
      "DID NOT TRAIN..., replay memory = 751\n",
      "DID NOT TRAIN..., replay memory = 752\n",
      "DID NOT TRAIN..., replay memory = 753\n",
      "DID NOT TRAIN..., replay memory = 754\n",
      "DID NOT TRAIN..., replay memory = 755\n",
      "DID NOT TRAIN..., replay memory = 756\n",
      "DID NOT TRAIN..., replay memory = 757\n",
      "DID NOT TRAIN..., replay memory = 758\n",
      "DID NOT TRAIN..., replay memory = 759\n",
      "DID NOT TRAIN..., replay memory = 760\n",
      "DID NOT TRAIN..., replay memory = 761\n",
      "DID NOT TRAIN..., replay memory = 762\n",
      "DID NOT TRAIN..., replay memory = 763\n",
      "DID NOT TRAIN..., replay memory = 764\n",
      "DID NOT TRAIN..., replay memory = 765\n",
      "DID NOT TRAIN..., replay memory = 766\n",
      "DID NOT TRAIN..., replay memory = 767\n",
      "DID NOT TRAIN..., replay memory = 768\n",
      "DID NOT TRAIN..., replay memory = 769\n",
      "DID NOT TRAIN..., replay memory = 770\n",
      "DID NOT TRAIN..., replay memory = 771\n",
      "DID NOT TRAIN..., replay memory = 772\n",
      "DID NOT TRAIN..., replay memory = 773\n",
      "DID NOT TRAIN..., replay memory = 774\n",
      "DID NOT TRAIN..., replay memory = 775\n",
      "DID NOT TRAIN..., replay memory = 776\n",
      "DID NOT TRAIN..., replay memory = 777\n",
      "DID NOT TRAIN..., replay memory = 778\n",
      "DID NOT TRAIN..., replay memory = 779\n",
      "DID NOT TRAIN..., replay memory = 780\n",
      "DID NOT TRAIN..., replay memory = 781\n",
      "DID NOT TRAIN..., replay memory = 782\n",
      "DID NOT TRAIN..., replay memory = 783\n",
      "DID NOT TRAIN..., replay memory = 784\n",
      "DID NOT TRAIN..., replay memory = 785\n",
      "DID NOT TRAIN..., replay memory = 786\n",
      "DID NOT TRAIN..., replay memory = 787\n",
      "DID NOT TRAIN..., replay memory = 788\n",
      "DID NOT TRAIN..., replay memory = 789\n",
      "DID NOT TRAIN..., replay memory = 790\n",
      "DID NOT TRAIN..., replay memory = 791\n",
      "DID NOT TRAIN..., replay memory = 792\n",
      "DID NOT TRAIN..., replay memory = 793\n",
      "DID NOT TRAIN..., replay memory = 794\n",
      "DID NOT TRAIN..., replay memory = 795\n",
      "DID NOT TRAIN..., replay memory = 796\n",
      "DID NOT TRAIN..., replay memory = 797\n",
      "DID NOT TRAIN..., replay memory = 798\n",
      "DID NOT TRAIN..., replay memory = 799\n",
      "DID NOT TRAIN..., replay memory = 800\n",
      "Finished! | Return: -10.180871674101455 | average reward: -0.050904358370507274\n",
      "Episode 4\n",
      "DID NOT TRAIN..., replay memory = 801\n",
      "DID NOT TRAIN..., replay memory = 802\n",
      "DID NOT TRAIN..., replay memory = 803\n",
      "DID NOT TRAIN..., replay memory = 804\n",
      "DID NOT TRAIN..., replay memory = 805\n",
      "DID NOT TRAIN..., replay memory = 806\n",
      "DID NOT TRAIN..., replay memory = 807\n",
      "DID NOT TRAIN..., replay memory = 808\n",
      "DID NOT TRAIN..., replay memory = 809\n",
      "DID NOT TRAIN..., replay memory = 810\n",
      "DID NOT TRAIN..., replay memory = 811\n",
      "DID NOT TRAIN..., replay memory = 812\n",
      "DID NOT TRAIN..., replay memory = 813\n",
      "DID NOT TRAIN..., replay memory = 814\n",
      "DID NOT TRAIN..., replay memory = 815\n",
      "DID NOT TRAIN..., replay memory = 816\n",
      "DID NOT TRAIN..., replay memory = 817\n",
      "DID NOT TRAIN..., replay memory = 818\n",
      "DID NOT TRAIN..., replay memory = 819\n",
      "DID NOT TRAIN..., replay memory = 820\n",
      "DID NOT TRAIN..., replay memory = 821\n",
      "DID NOT TRAIN..., replay memory = 822\n",
      "DID NOT TRAIN..., replay memory = 823\n",
      "DID NOT TRAIN..., replay memory = 824\n",
      "DID NOT TRAIN..., replay memory = 825\n",
      "DID NOT TRAIN..., replay memory = 826\n",
      "DID NOT TRAIN..., replay memory = 827\n",
      "DID NOT TRAIN..., replay memory = 828\n",
      "DID NOT TRAIN..., replay memory = 829\n",
      "DID NOT TRAIN..., replay memory = 830\n",
      "DID NOT TRAIN..., replay memory = 831\n",
      "DID NOT TRAIN..., replay memory = 832\n",
      "DID NOT TRAIN..., replay memory = 833\n",
      "DID NOT TRAIN..., replay memory = 834\n",
      "DID NOT TRAIN..., replay memory = 835\n",
      "DID NOT TRAIN..., replay memory = 836\n",
      "DID NOT TRAIN..., replay memory = 837\n",
      "DID NOT TRAIN..., replay memory = 838\n",
      "DID NOT TRAIN..., replay memory = 839\n",
      "DID NOT TRAIN..., replay memory = 840\n",
      "DID NOT TRAIN..., replay memory = 841\n",
      "DID NOT TRAIN..., replay memory = 842\n",
      "DID NOT TRAIN..., replay memory = 843\n",
      "DID NOT TRAIN..., replay memory = 844\n",
      "DID NOT TRAIN..., replay memory = 845\n",
      "DID NOT TRAIN..., replay memory = 846\n",
      "DID NOT TRAIN..., replay memory = 847\n",
      "DID NOT TRAIN..., replay memory = 848\n",
      "DID NOT TRAIN..., replay memory = 849\n",
      "DID NOT TRAIN..., replay memory = 850\n",
      "DID NOT TRAIN..., replay memory = 851\n",
      "DID NOT TRAIN..., replay memory = 852\n",
      "DID NOT TRAIN..., replay memory = 853\n",
      "DID NOT TRAIN..., replay memory = 854\n",
      "DID NOT TRAIN..., replay memory = 855\n",
      "DID NOT TRAIN..., replay memory = 856\n",
      "DID NOT TRAIN..., replay memory = 857\n",
      "DID NOT TRAIN..., replay memory = 858\n",
      "DID NOT TRAIN..., replay memory = 859\n",
      "DID NOT TRAIN..., replay memory = 860\n",
      "DID NOT TRAIN..., replay memory = 861\n",
      "DID NOT TRAIN..., replay memory = 862\n",
      "DID NOT TRAIN..., replay memory = 863\n",
      "DID NOT TRAIN..., replay memory = 864\n",
      "DID NOT TRAIN..., replay memory = 865\n",
      "DID NOT TRAIN..., replay memory = 866\n",
      "DID NOT TRAIN..., replay memory = 867\n",
      "DID NOT TRAIN..., replay memory = 868\n",
      "DID NOT TRAIN..., replay memory = 869\n",
      "DID NOT TRAIN..., replay memory = 870\n",
      "DID NOT TRAIN..., replay memory = 871\n",
      "DID NOT TRAIN..., replay memory = 872\n",
      "DID NOT TRAIN..., replay memory = 873\n",
      "DID NOT TRAIN..., replay memory = 874\n",
      "DID NOT TRAIN..., replay memory = 875\n",
      "DID NOT TRAIN..., replay memory = 876\n",
      "DID NOT TRAIN..., replay memory = 877\n",
      "DID NOT TRAIN..., replay memory = 878\n",
      "DID NOT TRAIN..., replay memory = 879\n",
      "DID NOT TRAIN..., replay memory = 880\n",
      "DID NOT TRAIN..., replay memory = 881\n",
      "DID NOT TRAIN..., replay memory = 882\n",
      "DID NOT TRAIN..., replay memory = 883\n",
      "DID NOT TRAIN..., replay memory = 884\n",
      "DID NOT TRAIN..., replay memory = 885\n",
      "DID NOT TRAIN..., replay memory = 886\n",
      "DID NOT TRAIN..., replay memory = 887\n",
      "DID NOT TRAIN..., replay memory = 888\n",
      "DID NOT TRAIN..., replay memory = 889\n",
      "DID NOT TRAIN..., replay memory = 890\n",
      "DID NOT TRAIN..., replay memory = 891\n",
      "DID NOT TRAIN..., replay memory = 892\n",
      "DID NOT TRAIN..., replay memory = 893\n",
      "DID NOT TRAIN..., replay memory = 894\n",
      "DID NOT TRAIN..., replay memory = 895\n",
      "DID NOT TRAIN..., replay memory = 896\n",
      "DID NOT TRAIN..., replay memory = 897\n",
      "DID NOT TRAIN..., replay memory = 898\n",
      "DID NOT TRAIN..., replay memory = 899\n",
      "DID NOT TRAIN..., replay memory = 900\n",
      "DID NOT TRAIN..., replay memory = 901\n",
      "DID NOT TRAIN..., replay memory = 902\n",
      "DID NOT TRAIN..., replay memory = 903\n",
      "DID NOT TRAIN..., replay memory = 904\n",
      "DID NOT TRAIN..., replay memory = 905\n",
      "DID NOT TRAIN..., replay memory = 906\n",
      "DID NOT TRAIN..., replay memory = 907\n",
      "DID NOT TRAIN..., replay memory = 908\n",
      "DID NOT TRAIN..., replay memory = 909\n",
      "DID NOT TRAIN..., replay memory = 910\n",
      "DID NOT TRAIN..., replay memory = 911\n",
      "DID NOT TRAIN..., replay memory = 912\n",
      "DID NOT TRAIN..., replay memory = 913\n",
      "DID NOT TRAIN..., replay memory = 914\n",
      "DID NOT TRAIN..., replay memory = 915\n",
      "DID NOT TRAIN..., replay memory = 916\n",
      "DID NOT TRAIN..., replay memory = 917\n",
      "DID NOT TRAIN..., replay memory = 918\n",
      "DID NOT TRAIN..., replay memory = 919\n",
      "DID NOT TRAIN..., replay memory = 920\n",
      "DID NOT TRAIN..., replay memory = 921\n",
      "DID NOT TRAIN..., replay memory = 922\n",
      "DID NOT TRAIN..., replay memory = 923\n",
      "DID NOT TRAIN..., replay memory = 924\n",
      "DID NOT TRAIN..., replay memory = 925\n",
      "DID NOT TRAIN..., replay memory = 926\n",
      "DID NOT TRAIN..., replay memory = 927\n",
      "DID NOT TRAIN..., replay memory = 928\n",
      "DID NOT TRAIN..., replay memory = 929\n",
      "DID NOT TRAIN..., replay memory = 930\n",
      "DID NOT TRAIN..., replay memory = 931\n",
      "DID NOT TRAIN..., replay memory = 932\n",
      "DID NOT TRAIN..., replay memory = 933\n",
      "DID NOT TRAIN..., replay memory = 934\n",
      "DID NOT TRAIN..., replay memory = 935\n",
      "DID NOT TRAIN..., replay memory = 936\n",
      "DID NOT TRAIN..., replay memory = 937\n",
      "DID NOT TRAIN..., replay memory = 938\n",
      "DID NOT TRAIN..., replay memory = 939\n",
      "DID NOT TRAIN..., replay memory = 940\n",
      "DID NOT TRAIN..., replay memory = 941\n",
      "DID NOT TRAIN..., replay memory = 942\n",
      "DID NOT TRAIN..., replay memory = 943\n",
      "DID NOT TRAIN..., replay memory = 944\n",
      "DID NOT TRAIN..., replay memory = 945\n",
      "DID NOT TRAIN..., replay memory = 946\n",
      "DID NOT TRAIN..., replay memory = 947\n",
      "DID NOT TRAIN..., replay memory = 948\n",
      "DID NOT TRAIN..., replay memory = 949\n",
      "DID NOT TRAIN..., replay memory = 950\n",
      "DID NOT TRAIN..., replay memory = 951\n",
      "DID NOT TRAIN..., replay memory = 952\n",
      "DID NOT TRAIN..., replay memory = 953\n",
      "DID NOT TRAIN..., replay memory = 954\n",
      "DID NOT TRAIN..., replay memory = 955\n",
      "DID NOT TRAIN..., replay memory = 956\n",
      "DID NOT TRAIN..., replay memory = 957\n",
      "DID NOT TRAIN..., replay memory = 958\n",
      "DID NOT TRAIN..., replay memory = 959\n",
      "DID NOT TRAIN..., replay memory = 960\n",
      "DID NOT TRAIN..., replay memory = 961\n",
      "DID NOT TRAIN..., replay memory = 962\n",
      "DID NOT TRAIN..., replay memory = 963\n",
      "DID NOT TRAIN..., replay memory = 964\n",
      "DID NOT TRAIN..., replay memory = 965\n",
      "DID NOT TRAIN..., replay memory = 966\n",
      "DID NOT TRAIN..., replay memory = 967\n",
      "DID NOT TRAIN..., replay memory = 968\n",
      "DID NOT TRAIN..., replay memory = 969\n",
      "DID NOT TRAIN..., replay memory = 970\n",
      "DID NOT TRAIN..., replay memory = 971\n",
      "DID NOT TRAIN..., replay memory = 972\n",
      "DID NOT TRAIN..., replay memory = 973\n",
      "DID NOT TRAIN..., replay memory = 974\n",
      "DID NOT TRAIN..., replay memory = 975\n",
      "DID NOT TRAIN..., replay memory = 976\n",
      "DID NOT TRAIN..., replay memory = 977\n",
      "DID NOT TRAIN..., replay memory = 978\n",
      "DID NOT TRAIN..., replay memory = 979\n",
      "DID NOT TRAIN..., replay memory = 980\n",
      "DID NOT TRAIN..., replay memory = 981\n",
      "DID NOT TRAIN..., replay memory = 982\n",
      "DID NOT TRAIN..., replay memory = 983\n",
      "DID NOT TRAIN..., replay memory = 984\n",
      "DID NOT TRAIN..., replay memory = 985\n",
      "DID NOT TRAIN..., replay memory = 986\n",
      "DID NOT TRAIN..., replay memory = 987\n",
      "DID NOT TRAIN..., replay memory = 988\n",
      "DID NOT TRAIN..., replay memory = 989\n",
      "DID NOT TRAIN..., replay memory = 990\n",
      "DID NOT TRAIN..., replay memory = 991\n",
      "DID NOT TRAIN..., replay memory = 992\n",
      "DID NOT TRAIN..., replay memory = 993\n",
      "DID NOT TRAIN..., replay memory = 994\n",
      "DID NOT TRAIN..., replay memory = 995\n",
      "DID NOT TRAIN..., replay memory = 996\n",
      "DID NOT TRAIN..., replay memory = 997\n",
      "DID NOT TRAIN..., replay memory = 998\n",
      "DID NOT TRAIN..., replay memory = 999\n",
      "Finished! | Return: -267.24492471957444 | average reward: -1.3362246235978723\n",
      "Episode 5\n",
      "Finished! | Return: -259.1728890992093 | average reward: -1.2958644454960466\n",
      "Episode 6\n",
      "Finished! | Return: -348.1901161708621 | average reward: -1.7409505808543104\n",
      "Episode 7\n",
      "Finished! | Return: -6.372042044413018 | average reward: -0.03186021022206509\n",
      "Episode 8\n",
      "Finished! | Return: -606.2454608580723 | average reward: -3.0312273042903617\n",
      "Episode 9\n",
      "Finished! | Return: -760.6700375229951 | average reward: -3.8033501876149756\n",
      "Test Rewards: [[-1.9554442820326643, -2.252059925046975, -2.6843720896932166, -3.3458646073870297, -4.13291392764353, -5.265583193027113, -6.653956761100069, -8.2674933201812, -10.201355595295329, -12.340472463899903, -12.543220049429179, -10.951443819165524, -9.253433129506115, -7.705838861760367, -6.249760039863339, -4.857389126192266, -3.6203219859425126, -2.795933117247042, -2.0832580367528415, -1.5731683807800396, -1.1907678289365937, -0.9052628724013629, -0.6204176997515408, -0.4540266006803189, -0.2981039346497774, -0.199343045578733, -0.15340016530262815, -0.131405882857744, -0.10661122694689305, -0.09437133402155906, -0.07877517940317384, -0.07299427829323363, -0.070710761396734, -0.0683395431482001, -0.06833162830857502, -0.0684136481847705, -0.06883338801696105, -0.06867768712536157, -0.0916854775401149, -0.09298145009015973, -0.09400706035054478, -0.09425306401707359, -0.09345970948513406, -0.09012729792295748, -0.08726874146968373, -0.0839417048776107, -0.07904121918120069, -0.07430463610371074, -0.07035885607395578, -0.06569947146902547, -0.0647735904007205, -0.07015353350582466, -0.07065974581984505, -0.06930068539931618, -0.06962686247132562, -0.07202879152235647, -0.10969318147657636, -0.11371134320145823, -0.11857456242395611, -0.12353984127119916, -0.12815910224482388, -0.1321709367169769, -0.13542918272796578, -0.13785606607250384, -0.13941179349385283, -0.14007529100097826, -0.13983270239332315, -0.1386716251323005, -0.13658009000864668, -0.13355015809124116, -0.12879884773817665, -0.1571967074712927, -0.1689197250974699, -0.18170442403029785, -0.19582347735010747, -0.21174631549478984, -0.22617504860668172, -0.2955843224211604, -0.33772489053641536, -0.48854029639643703, -0.7289978797628043, -1.091421953130816, -1.6436197546169444, -2.4077017900911204, -3.4699186679304854, -4.902606010176406, -6.760040579720734, -9.051659167361748, -11.095312798319762, -13.803728312049566, -14.911747984116188, -12.710687902471756, -10.467919242548463, -8.319892207916778, -6.399900793122337, -4.67900082411438, -3.2859439368130965, -2.2513339816245783, -1.5755502391063492, -1.2020275256127817, -0.9349325704312028, -0.5656877212409812, -0.31127364496049614, -0.25858352696389003, -0.16793333407574682, -0.15333224480801075, -0.09845083932043738, -0.0620628547464129, -0.03811192272303162, -0.022507060882627265, -0.01251561473016506, -0.0063480029862483045, -0.002881358634486029, -0.0014843535782298977, -0.0019183175289610326, -0.0017579776707568066, -0.001677088304196084, -0.001668676144455683, -0.0019931356381011956, -0.00429441269133069, -0.004750945900155836, -0.0019691803945508265, -0.0008334988084120819, -0.0011469541352808188, -0.0009310343346431577, -0.0009121075196430854, -0.00122062014812275, -0.0012461020312462224, -0.0012086536468424872, -0.0008132610463120844, -0.0009167035719104613, -0.0009294732822616929, -0.0011752862936555554, -0.0009832692828707157, -0.000983989215751694, -0.001923292741735219, -0.008405672300782402, -0.0017360931949303917, -0.0017183738365152239, -0.0021127373728665588, -0.001981808623899024, -0.0019058026093320528, -0.0018765067579036153, -0.0023470212379144836, -0.004035979842293154, -0.013432462223521683, -0.00701013930703925, -0.004678501516219759, -0.004412210195729849, -0.01080741481308655, -0.006910380806055429, -0.006718490589363705, -0.003586103636568939, -0.003087296099213798, -0.00304818740290552, -0.0029818205038496296, -0.006412278004580309, -0.0041329769069814015, -0.0026839219556480773, -0.0060499207005858275, -0.004481032984114272, -0.002650362250790899, -0.006435637200480557, -0.0036638339189477395, -0.0025582477735424055, -0.0024992529036499006, -0.005556799881200708, -0.003949446908596427, -0.0020875687121787267, -0.002325892622429691, -0.002233825763196724, -0.002169383641972364, -0.0021279760808700023, -0.002658175462503599, -0.0025811113361317406, -0.0025233844629888925, -0.002466348894064321, -0.002413000031089572, -0.006221491903323485, -0.005197838832974507, -0.0023011728062208793, -0.0013417438374067417, -0.0013837900610034171, -0.0014626612385457722, -0.001327517388482882, -0.001315197928809079, -0.0017084390922927637, -0.001536847484782856, -0.0014568523886190874, -0.001492300546617293, -0.001570732117005284, -0.0022976229918792827, -0.002456222714668574, -0.0010754784428612984, -0.0012739057879616377, -0.0011019015462086607, -0.0010958916267681596, -0.0014386680346580804, -0.0012432666061774737, -0.001193481808272547], [-0.9916182389756572, -1.297746670989923, -1.8017007347342635, -2.328120663985289, -3.264273440600331, -4.533816339793872, -6.176982319587676, -8.197514942122039, -10.539139845214317, -13.078072525777277, -14.515233903220283, -12.435266981596849, -10.313380147084182, -8.456946912612063, -6.553462932007825, -4.935742501838106, -3.5484034021300164, -2.4122906456467406, -1.819647453834431, -1.2674193773031694, -0.9687298564037446, -0.7555156392943296, -0.4296221258796098, -0.3476183127532448, -0.23310458990907823, -0.20494722485763286, -0.1330362597681148, -0.08516015003070912, -0.05348451322117489, -0.032682867593320515, -0.019162862905777754, -0.011107978666907227, -0.0032422498233465576, -0.0016435802471886606, -0.0019409284535989487, -0.0018051655490128064, -0.0017369335599875095, -0.001735626286814768, -0.0019720838163792154, -0.0018475673026574348, -0.001783771941560245, -0.001782373426282324, -0.001996099561565207, -0.0018765296982176094, -0.001813969121695998, -0.0018106585583231528, -0.0020264166262454436, -0.001909232943262088, -0.0018459606933004951, -0.0018381163163346248, -0.002082325585370762, -0.001966884437335873, -0.0019010266137478929, -0.0018838787568338689, -0.002201810309420375, -0.0020899818228722927, -0.0020201096342133858, -0.0019860775279302596, -0.002473748464894084, -0.002376216904372242, -0.0023080105528565545, -0.0022530827036431693, -0.005533939051447103, -0.003625846320326929, -0.0019625936065757995, -0.00235901344135856, -0.0022564443061588954, -0.002186679310883918, -0.002138336360845588, -0.0028358431424038975, -0.00295449234493472, -0.008698031390729995, -0.003402752375722919, -0.006677081581844679, -0.0045386998592435255, -0.002981072762500382, -0.006362817050066838, -0.004153128695086214, -0.0026548359945726733, -0.005956704873444832, -0.003928218952294088, -0.0023172436429467294, -0.005345531354831104, -0.0038387394228632413, -0.001937349811888801, -0.0020499827323224445, -0.001945762074758307, -0.0018887773622322242, -0.0018847540092327628, -0.002060451329258109, -0.0019506019422143128, -0.0018894149010115974, -0.0019652824654837866, -0.0023364122344774513, -0.0022122146724365497, -0.002133042204354053, -0.0020809500498337346, -0.002890109783353356, -0.002822089127880526, -0.002778951399638517, -0.0027318094907078077, -0.0026712815411221373, -0.006039932191850159, -0.0039071959038717565, -0.0023639816746881996, -0.00548659041170905, -0.0056097589338744685, -0.010663827669881842, -0.005786730288052926, -0.0027860470162406454, -0.0010615623068959924, -0.0002660851253871217, -0.0002497372217867142, -0.0002473052121796619, -0.0002686146587281839, -8.355088786826228e-05, -0.0003357550745494097, -0.00019147204665793065, -0.0003397721253675372, -0.00018857097533748937, -0.00036376251604506535, -0.00018450681121005792, -0.00041613289611296464, -0.00018641895332449036, -0.000516721456771274, -0.0018454365664873475, -0.003961424629278109, -0.0021154659842835336, -0.0010431203164378937, -0.0005057693706045612, -0.0003912361638923788, -0.0006956371097243542, -0.00029439060144195717, -0.00046323312855186464, -0.00030347684047030864, -0.0003376083417909405, -0.00038119941880719393, -0.0002804769004441393, -0.000536546725711334, -0.00029647753587203486, -0.0005284424512149387, -0.0002698084074561518, -0.00037605780758328015, -0.0003077662393117908, -0.0002918065466003353, -0.004201828286901703, -0.015120522419635806, -0.0027872135390432855, -0.0023470927877099514, -0.002101548000155361, -0.001961549690290341, -0.0018812374015848936, -0.0018500471819047713, -0.002353868620043187, -0.0022388685972470884, -0.0021636835892615085, -0.0021125160437693866, -0.0052949833711962435, -0.0035849190666830985, -0.001818980362621174, -0.002022960155195584, -0.0019068475449905925, -0.0018444602141821276, -0.001837929939166139, -0.0020690579191034804, -0.0019538865706900644, -0.0018889969009399945, -0.0029928400878080543, -0.0073548086421401085, -0.0024037939303712006, -0.002669087943146619, -0.002609328767856208, -0.0025550429885264404, -0.0024968195946085403, -0.0057611929553558466, -0.003824648441955772, -0.0021632036679475573, -0.0026626002445871047, -0.0025885667236814802, -0.0025317814287833715, -0.0024747045384746007, -0.0024212143661703706, -0.002868614448117929, -0.002823831952619841, -0.0027822409117911747, -0.002727350518010268, -0.002660425313786803, -0.005688687550649987, -0.004083737331502049, -0.00220566531982728, -0.002486268449245161, -0.0024070047961160966, -0.002345338773529133, -0.0022930587678326704, -0.005405412194620305, -0.0037648279660441957, -0.001941989548752312, -0.0021477811220017616, -0.0020422842047036183, -0.0019783206540470426], [-8.001463947834472, -8.313439708890723, -8.718279464985237, -9.302945616336267, -10.014344811429284, -9.903081949067618, -9.212820916292948, -8.649354027640362, -8.06738672921511, -7.4842529655635435, -6.9013307130477, -6.448205879276323, -6.05165095356401, -5.724777755997083, -5.477920002673417, -5.318607582244176, -5.251730447208853, -5.279732886887507, -5.400298147520015, -5.741466583513402, -6.29908935672253, -7.222375278479906, -8.439450397271886, -9.897428006288198, -11.409451025457633, -10.589371785289638, -9.43949951693416, -8.25073414331112, -7.070548428289869, -5.948861521317594, -4.928458049164627, -4.0380506840926955, -3.2903242916949624, -2.6843329245403798, -2.210087713886495, -1.8533057045850407, -1.5991901136045836, -1.431118982213796, -1.3770925472951316, -1.5256519397881856, -1.8899463305915927, -2.4981735855507563, -3.389522429806281, -4.605399770647758, -6.174175211407749, -7.996813566577747, -10.177110412385433, -12.536300692329755, -13.926397654600853, -11.97486488769861, -9.985877132377164, -8.063259890966464, -6.314685334445257, -4.910597077939371, -3.7419300740043075, -2.7375164609024765, -2.0721088894993223, -1.5648708187126767, -1.1845372131522927, -0.9032723203505797, -0.5493885026401745, -0.4315719513515223, -0.34387897062090256, -0.2790120267909755, -0.23226218131768656, -0.20119426125108364, -0.1855719708323239, -0.09086169534468302, -0.056271436064725275, -0.033665697708297006, -0.019213136651315018, -0.010419866982588028, -0.005751827097530851, -0.006799538863058761, -0.0070925642350713235, -0.0036198379288249747, -0.002717281253332838, -0.0026567772353259383, -0.006012488234564411, -0.0039020453589525893, -0.002344606510738343, -0.005443038767253688, -0.003811418997113071, -0.0019784310906403374, -0.0021921474268701154, -0.00208983345780695, -0.002025354065723038, -0.001997218015280881, -0.0037228746437297476, -0.0026209768256028796, -0.004700324665049333, -0.013810819648567441, -0.006709525229329889, -0.0040508820929749815, -0.0028787846808549155, -0.0028080223937477964, -0.005977737782049726, -0.004115863882954646, -0.002388571938607828, -0.004645749131554568, -0.015845981151196172, -0.008645725342176114, -0.005084839545507166, -0.0072164837498447645, -0.006176958016811638, -0.0036821198287394965, -0.006357599179552892, -0.004993094806414044, -0.002868148310907538, -0.005592109229188954, -0.0044125489128072825, -0.0022590096824350227, -0.002251025440994639, -0.0029415365939218195, -0.009034348125112557, -0.003042759304681044, -0.0029627140973358494, -0.00609424591240704, -0.005198980474388607, -0.007805947496211232, -0.0036492066505370885, -0.0014259543351490369, -0.0007239231447358329, -0.0008397490732891413, -0.0007584092294953028, -0.0006656719457846896, -0.0008612031675218504, -0.0005846838683198124, -0.0005846458397048993, -0.004627538053452197, -0.017061679335771837, -0.00693969386581704, -0.002362080705483534, -0.0023518552528260356, -0.0022772425150958658, -0.00222006476689781, -0.0021850661109649857, -0.0029429351097386377, -0.002201308130749319, -0.0028074795099534908, -0.0027451253245359395, -0.002698012508335801, -0.004820516221641555, -0.013274331084110077, -0.0073912839295246675, -0.005278655363982378, -0.003686756211165477, -0.004170518002553363, -0.008665412928122763, -0.004250090728152333, -0.007022642282371376, -0.005368121379409018, -0.0034098366251749963, -0.006551219393430668, -0.004594718551813323, -0.0027725595515774026, -0.005554365944570378, -0.004877647580833082, -0.002391207290182383, -0.002054541768026512, -0.0019845317739496547, -0.0019538088285697233, -0.002408453308201808, -0.002305967823928124, -0.0022357633806311832, -0.0021836214068281247, -0.005058495974881819, -0.00331102719528271, -0.0018966497786672427, -0.0025309885305306668, -0.002425241760902819, -0.0023544728116028737, -0.002296439452306071, -0.0022536050028343206, -0.0026683935324295447, -0.002600916837292528, -0.0025457519230099074, -0.0024883471979687526, -0.002435141243003119, -0.0028137879756678624, -0.0027652719477553995, -0.0027193569571370654, -0.002661958455625635, -0.0025974010921808875, -0.005501335643700545, -0.004115795174344727, -0.002113908566791952, -0.002205529814526073, -0.0021145430247619503, -0.0020556128658147255, -0.003465765106908909, -0.005118305755348187, -0.00215572224772614, -0.000855660870377019, -0.0009877677454713633, -0.0008210585153094285, -0.0022584784857375556, -0.0038273878852549716, -0.003224339498286932, -0.0029139818071090215], [-0.10299748817652145, -0.09649082342052831, -0.09011937941505209, -0.08162404929350948, -0.07427219270738718, -0.07053675034051764, -0.0665653442164051, -0.06272610518263168, -0.05963316861990046, -0.058282466551393665, -0.06025614358462198, -0.06562936062699123, -0.04354029586532497, -0.012830678496559389, -0.00666141195039261, -0.003737487150371467, -0.005954168496018684, -0.005270666291880642, -0.0027074493805411617, -0.002449526016810247, -0.0023880481660996104, -0.002333281823589533, -0.005547796495731162, -0.0037288607992985853, -0.002006754678167953, -0.0023604678318191524, -0.002262142133520095, -0.0021941916829792624, -0.0021469517284403946, -0.00280921750250152, -0.002742518098448905, -0.0026946073152106513, -0.0026417969510033022, -0.0025801522437510402, -0.003240607145672934, -0.0061005383747660315, -0.0074244594813225595, -0.014612865643673995, -0.008539177076406095, -0.004714986370916601, -0.002367686283637763, -0.0010066140299467047, -0.00034383877382414307, -0.000247525943054255, -0.00045779020780599596, -0.00024595500844298607, -0.0006588944156223375, -0.0003212872640266755, -0.001032670342321197, -0.0005678891357974991, -0.00047563413372144283, -0.0008678458994171036, -0.0005862001394124096, -0.0015134132880733767, -0.0010846518105664808, -0.0008997668909872867, -0.0018758223193162905, -0.0015462334066666857, -0.0013764083136058962, -0.002732601723959207, -0.0025058807899268395, -0.0023817331439528995, -0.002302896907896368, -0.004040269234569369, -0.004093270266965325, -0.004215742661420155, -0.004361312558493877, -0.004501085627194878, -0.004617368438983418, -0.004699538520968553, -0.007286021927270712, -0.008127669041788164, -0.009168152721613419, -0.010450100847175632, -0.012048391461858274, -0.014076974310572987, -0.016701234965442287, -0.020157556189036974, -0.02478276973744873, -0.03233760122709388, -0.03113540022012655, -0.040055121831247764, -0.041742554947005024, -0.042257989574396006, -0.058253404958330576, -0.052571348442457456, -0.05534196017909712, -0.05815902699928699, -0.06107423941704501, -0.06528946758144655, -0.06482338695184388, -0.06799749742290453, -0.0670238602734549, -0.06802328786603724, -0.07047240652746552, -0.06914099541097239, -0.06951271024278394, -0.07139356239530655, -0.06974894648457762, -0.06959073788925162, -0.06982460185671077, -0.07158141956611067, -0.06986786271009332, -0.06959527086017801, -0.06971549577303704, -0.07023329983789045, -0.07229493828729469, -0.07077838137679754, -0.07086647229107601, -0.0725263225850286, -0.07077590020185447, -0.07046794294233956, -0.07059389351067816, -0.07227869535565072, -0.07053768537640898, -0.07023832427872967, -0.06938505561572052, -0.07645492746731535, -0.07395062554245073, -0.0718116729144495, -0.0708961608317552, -0.07044168958788553, -0.0704209759382812, -0.07083090451324424, -0.07281207231084577, -0.07125981254946949, -0.07130024513678662, -0.07293317275301744, -0.06975180409280889, -0.08001408230944007, -0.07943123735084194, -0.07557933134702088, -0.07339222434058432, -0.08397830148867476, -0.08366467069235611, -0.08108939445378843, -0.079639088979945, -0.07639237937570739, -0.0739510831824548, -0.07215899820928669, -0.07090820367574154, -0.07012542921989955, -0.06976537197932137, -0.06980660949260008, -0.0702496125313205, -0.07223661318418867, -0.07067416046150068, -0.07068128451086864, -0.06976411172300005, -0.08119474089851593, -0.08080269966320552, -0.07826173017033038, -0.07583144040312072, -0.07461988875823705, -0.07517692234379243, -0.07282304320006973, -0.07026915624237247, -0.08379813496819907, -0.08379634216727301, -0.08166411160248742, -0.08124008643361082, -0.08012158441518706, -0.0771941643836188, -0.0752814530887443, -0.07406689376337974, -0.07467808785238317, -0.07215462205253753, -0.07074238592400546, -0.06979414656448073, -0.06925587186799712, -0.06909688874275305, -0.06930715730039337, -0.0685632929591177, -0.07957656574939019, -0.07693056685448266, -0.08071216407403935, -0.0780815938620993, -0.075435720683724, -0.07556988682556552, -0.07189492512493384, -0.06895163181131334, -0.06569904790250279, -0.06507145496192465, -0.0645735421075479, -0.06424981690997734, -0.06408520806055738, -0.06407198411058872, -0.06420921770570827, -0.06450268663162834, -0.06496519860296415, -0.06561736828441361, -0.06648892002458501, -0.06762064392680146, -0.07018720312549528, -0.06891775861642159, -0.07150978334296615, -0.10669895236718979, -0.18233290072757483, -0.21748486154468433, -0.24574282697251676], [-2.6800395887027357, -2.9097349784594577, -3.413856528139059, -4.206310441976899, -5.298021936511532, -6.685576057595752, -8.33876591063468, -10.192744756155824, -12.151787405708351, -12.080188156742599, -10.57942314582189, -9.030695123638319, -7.5066967369344875, -6.084105914822403, -4.82155233662128, -3.6878001814600188, -2.8423694952272442, -2.176174011382631, -1.6623173887070988, -1.1543102262179308, -0.9243065976179631, -0.7619743750015112, -0.6532512051535292, -0.5887639416376624, -0.6088069079182941, -0.6861613172891982, -0.8097330104498989, -0.9905921812446818, -1.2443739048844251, -1.59172446021889, -2.0582911729496454, -2.6736550713675094, -3.468366788477385, -4.46581133349149, -5.879110961952898, -7.583366278616332, -9.784043721285062, -12.21844325399106, -14.368225398203766, -12.463069277728934, -10.421769058269383, -8.43157512166692, -6.610118524701754, -5.228538065822567, -3.8840357802496017, -2.831016837755014, -2.037509542770282, -1.5384891275289807, -1.1646180705156355, -0.8001568537168455, -0.546880698028468, -0.3601286943457742, -0.23989589670305095, -0.17631049007519797, -0.15252406518973655, -0.13062671425194772, -0.10572849861889398, -0.09352289125552096, -0.07766501021237708, -0.07146574499882456, -0.06889576866056868, -0.06674832758391383, -0.06491297222667301, -0.06330147533824078, -0.06184151320015329, -0.06047204841105802, -0.05977668625202345, -0.08127946101745567, -0.08105633880226844, -0.08090013135139723, -0.07877473983270662, -0.07854913584442434, -0.07759525905737688, -0.07479914946034041, -0.07296875762530401, -0.07171973433690818, -0.07097725498766846, -0.07069709614617277, -0.07086153388310074, -0.07007854711164276, -0.0825522299733407, -0.08234974518050528, -0.07999720866854755, -0.0790970719163987, -0.07636758560993304, -0.0747170075190683, -0.07372931651952279, -0.07446167286971175, -0.07219922890437722, -0.0710982889651178, -0.07047127380659352, -0.07028117083584501, -0.07051555866256153, -0.07230535681929497, -0.07062719924888025, -0.07043666958802032, -0.07067796714410908, -0.06998809459641592, -0.08754257219154925, -0.08814984858544091, -0.088182238640739, -0.08586948337449607, -0.08491326866068326, -0.083330130312176, -0.08112358251186971, -0.07719416916126122, -0.07377040504344487, -0.07103101785818411, -0.06881636403494687, -0.06700482773942021, -0.06550246716584635, -0.0642355353748953, -0.06179294598947024, -0.07374486521176772, -0.07143546161093899, -0.07175605081999123, -0.07019838326830223, -0.07020104396167774, -0.0706239598589395, -0.07260838493954558, -0.07105320415344045, -0.07108299481955192, -0.07269486656071501, -0.07091961331602599, -0.07057441853629846, -0.07066840837748616, -0.0723247447497758, -0.07056787246245497, -0.07024268476722235, -0.07034089451812228, -0.07198596153179367, -0.06987171513477719, -0.07045583988726135, -0.07231607840975207, -0.07068002036739153, -0.07056228923952798, -0.07088207535544963, -0.07277502056796219, -0.07116907859209698, -0.07111622784914642, -0.07264712798595283, -0.0708228167044347, -0.07039235598470929, -0.07039312157053312, -0.07194319431794287, -0.0701155626530085, -0.06965710531964266, -0.06959570813194534, -0.0699263496004604, -0.07178512856876489, -0.07013620574879109, -0.069981304361927, -0.07023667798021836, -0.07203438659047989, -0.07035487992821819, -0.07015417388820809, -0.07037202994120194, -0.06958512653503014, -0.08331268346967255, -0.08327018534923654, -0.08111093166696604, -0.08064598555544465, -0.07947927395635593, -0.0764987222173893, -0.07343325326655564, -0.0740359961096425, -0.09445645562201618, -0.09601948091392982, -0.09705908151735396, -0.09717611565266741, -0.09617979603890067, -0.09261178261264735, -0.08940712909935104, -0.08579921336657247, -0.08066955337878712, -0.07571250795036799, -0.07162455584142072, -0.06816578613406475, -0.06387076657485426, -0.06432498469055824, -0.06487548414062502, -0.06653983504814937, -0.0998350228819059, -0.10100401913497387, -0.10914177474347167, -0.10901597888337099, -0.15654902931135145, -0.17040800231233477, -0.186657850846431, -0.2054432531305861, -0.2272984230978142, -0.25314152471461354, -0.2843198219101678, -0.3204764805638875, -0.48979062842930904, -0.7314392136157214, -1.0950481805807475, -1.6257033169506505, -2.382180067866238, -3.434552553529312], [-2.0366524311192404, -2.3694892035328845, -2.7932097395654076, -3.37066778894977, -4.114786142636251, -5.029984075825515, -6.229795499072148, -7.690189848235216, -9.322034247490537, -11.445165422360372, -12.878251723229779, -11.340988028956012, -9.729731705723234, -7.753328386297981, -6.380011122986916, -4.890571215906485, -3.8932731138817975, -3.0641569147192653, -2.393438966463377, -1.8278882085058044, -1.437119156415135, -1.139280130621, -0.9142778252627222, -0.7453527809371343, -0.6191345258515668, -0.5252861840127226, -0.45600297928562117, -0.40550869079262264, -0.36961631930762023, -0.34537530673332073, -0.33080604119283286, -0.32471386893143106, -0.32513337132702086, -0.34054596891208117, -0.3720114323245864, -0.4224154843842112, -0.49644443174806446, -0.5984613069716017, -0.8314866337371424, -1.0700197049511795, -1.3914339689929878, -1.819077551050964, -2.5595606631065273, -3.3631388804587576, -4.382993884611703, -5.636854324399073, -7.114389694668884, -9.103324213225555, -10.939784927667661, -13.415018662356067, -13.009461044309612, -11.172291648778687, -9.366739873000887, -7.342206483526019, -5.766340199977382, -4.423830646694654, -3.238795603613002, -2.343253980479248, -1.768988090118516, -1.3364767246920457, -0.9095101216572273, -0.7005450821819776, -0.517209055812996, -0.2836300412994989, -0.2127582756275224, -0.1613974523220467, -0.12049327111558636, -0.09417456002729903, -0.06959062460900284, -0.05514841056754339, -0.03223250663755007, -0.02994325618499057, -0.02961856490093185, -0.027520385462526633, -0.026226054519249763, -0.027938265739544284, -0.02745895480822401, -0.02571910171026936, -0.029405242771702624, -0.0293658563527172, -0.029094251928722104, -0.028527673757014527, -0.026431076604130813, -0.026083406158076944, -0.024105848326865225, -0.022845113819420112, -0.021984045218764972, -0.021033388029954428, -0.019993628576856912, -0.018878877431376537, -0.017725319610165467, -0.016604244192723615, -0.015001916068847862, -0.011969061951110489, -0.011678929301018883, -0.01128164913609135, -0.009640325341430077, -0.008525277084211741, -0.007968388945421399, -0.00809996561884875, -0.009176577479837663, -0.011628838214190246, -0.016136650950670715, -0.027583561986743426, -0.006623482354036667, -0.013159375822703906, -0.02382048589717247, -0.04442557012607114, -0.026106277587329703, -0.048543522116836324, -0.0351020016305142, -0.06069014471151875, -0.05435267042490917, -0.0481749809302599, -0.05031386345564883, -0.052340890587113206, -0.054252332480314976, -0.056065879667261044, -0.05643509032521152, -0.07542148251028316, -0.07063835913601561, -0.09774548505059719, -0.09992580141452086, -0.10223621597931888, -0.1040263570795475, -0.10490439481603417, -0.10465540453918616, -0.103197296537585, -0.09912696223372074, -0.09373806925626559, -0.09195594514053394, -0.08979210099167338, -0.08714834451890069, -0.08401489493301405, -0.080404347493991, -0.0763704145247343, -0.0720368343499636, -0.06524161433871613, -0.057796355576477554, -0.05611016390306661, -0.05160072758312197, -0.05076337359356099, -0.047444160845365874, -0.05624832371612064, -0.05653652164961189, -0.056333938585585774, -0.05358611395122094, -0.05372941234422043, -0.055586131154787596, -0.06011733330215954, -0.06284776809587332, -0.06835140245195445, -0.06370490805696928, -0.06674123579300545, -0.06888167844473063, -0.07142715635530195, -0.0770698478657305, -0.07351086646677238, -0.07417364977874175, -0.07404770855099543, -0.08848901283215786, -0.08896191528454361, -0.08866826664311742, -0.0859523516488998, -0.08417968689939419, -0.07988733070845452, -0.08035895406038328, -0.07921904200707645, -0.07738121312427093, -0.07487752929192154, -0.07177976234745721, -0.0682258178334784, -0.06446164518722468, -0.061768468197556506, -0.0607733194337904, -0.06042152128854445, -0.06205694874675325, -0.03969426833760487, -0.04974898603861825, -0.032314595288150665, -0.021312496806835897, -0.011808926433572208, -0.007560678635182512, -0.006993103432299654, -0.005326958305064426, -0.004422662768489495, -0.003988353187264657, -0.0038327169153707656, -0.0038313055165070486, -0.0039039027298294064, -0.0039993788835110955, -0.004085623586288246, -0.004142942774381674, -0.004159853397808015, -0.004130592152455452, -0.004053932309410926, -0.0039331176140528345, -0.007298367156661118, -0.014214253230309113, -0.012623532221014656], [-2.081359315294862, -2.1835893376099187, -2.5736897322704646, -3.3035332640892614, -4.221836063204681, -5.622941037879223, -7.411757893693715, -9.547710682735142, -11.860666888557477, -14.018080051116213, -12.249027943215372, -10.399139178275083, -8.558826076345701, -6.834899467070142, -5.315307020686345, -4.04994667908789, -2.7088813689063627, -2.008916401804, -1.5168250809575012, -1.149673112833963, -0.877930508914034, -0.6405811703685644, -0.47422853743094795, -0.2681976630152984, -0.20220833858671397, -0.15569364037635797, -0.12845118197191985, -0.10547057671588188, -0.09223844670752492, -0.09032302841079115, -0.041613528480735594, -0.012600988228318516, -0.004682038821833869, -0.0012477991254192357, -0.0033774850712891494, -0.0006966153890939423, -0.0025503235620957035, -0.000672583568834415, -0.0016929040166130864, -0.0055257673053596985, -0.004021146537162956, -0.011518892320861614, -0.0077743685846142635, -0.005619508368491845, -0.015263647261058062, -0.010679215764948076, -0.007664304371942421, -0.01556288691994, -0.012883093847154352, -0.010806798291124475, -0.01826471213948329, -0.016423269972171636, -0.014141901152949379, -0.014941386112823115, -0.017597155695217165, -0.015595991875558487, -0.01598906921836435, -0.017047136942188186, -0.02015470673011067, -0.018187310079229538, -0.020524225770696968, -0.018681977963446443, -0.018958052630463643, -0.021461827951149995, -0.02090861141726763, -0.019180200628933716, -0.017994046309993145, -0.01895290094802107, -0.017780833352110427, -0.021052979222055623, -0.01927307308157198, -0.0295703518198147, -0.029370268832631555, -0.02938947172477998, -0.02932151402388447, -0.029005137375665745, -0.028394298415603644, -0.026751234635451687, -0.029723973704886, -0.029383588240491563, -0.029918276533853205, -0.029489531408341235, -0.027336912322445856, -0.02858593673559946, -0.02809153520957372, -0.027213374954189025, -0.025562161528466514, -0.024897501457614202, -0.03321278405398413, -0.03375780045102468, -0.034249505004127524, -0.03448820095214414, -0.03356411140700742, -0.03604706512501592, -0.03318171890081416, -0.03173622005795386, -0.030498615881244844, -0.029632789252862286, -0.028921000860591132, -0.0283213373917264, -0.027805049590846502, -0.02734868932290247, -0.0269325958012211, -0.026539755505109102, -0.026154932426149826, -0.02812267118852939, -0.04487457615214279, -0.04726055133998197, -0.05040085397257656, -0.052841264682196014, -0.08165457933970842, -0.09342491918982679, -0.10841130558278074, -0.12748935401735184, -0.1536381659653793, -0.1710950034203132, -0.2077712354537692, -0.2568092631477748, -0.32259892941365675, -0.5136685379001248, -0.6769906927868395, -0.9299440001407205, -1.2822854394904373, -1.7809491667555255, -2.4503546844490622, -3.4131291286295515, -4.608487846753074, -6.302624015212027, -8.171983525943995, -10.293612182823901, -12.546870636497733, -14.53282624035969, -12.345675507456825, -10.162819220359417, -8.398266487673538, -6.673504678447176, -5.160958553813111, -3.836015974233191, -2.967740772788456, -2.1807246275126824, -1.5913540531115185, -1.1590379812726919, -0.8489655317449888, -0.6542081890358551, -0.48626183173574306, -0.37762296090064607, -0.3056456601319861, -0.24156589672289835, -0.2060218598860459, -0.17792606474649095, -0.15331776693031837, -0.13047378128558793, -0.11631397517151418, -0.10404503555685331, -0.09684728317779434, -0.10271832294666196, -0.10429881299439869, -0.10489748626107473, -0.10433644976662663, -0.10256465179730236, -0.09709131142696882, -0.09307852702133625, -0.09083350103422651, -0.0927328738952127, -0.08827252273250201, -0.08608379032988582, -0.08519170786725076, -0.08552359821386282, -0.08965456391799803, -0.08593409002761324, -0.08521131960686068, -0.11163374785865822, -0.1159333433608093, -0.12003350131712998, -0.12354084016706224, -0.12222021769829408, -0.1519862474121389, -0.16252097233431934, -0.17380416382179112, -0.18502260796818493, -0.2039086116098418, -0.22131172731725243, -0.24169427492043305, -0.26614709124843444, -0.296128104734358, -0.3303057794717374, -0.4765007629753773, -0.7041297411731468, -1.0514650937198795, -1.598698907693607, -2.3911570465341287, -3.504884023515416, -4.881733655742687, -6.653213763287605, -8.821110865847258, -11.314215947892315, -13.983238077740548, -14.969986914389256, -12.907289859806342, -10.766552091090206], [-0.045841347359198106, -0.04159576648361251, -0.04027692254395537, -0.03862078063814584, -0.036720734410951875, -0.034740499810995515, -0.032955201966459215, -0.03293394928652885, -0.02147738169610477, -0.022092829730870445, -0.03317791164572382, -0.03335552728189991, -0.03391005587917237, -0.03447498553475195, -0.034825238559010305, -0.034831773502982596, -0.03443545714383978, -0.03283594323377614, -0.03179380895174778, -0.04002781253454336, -0.04157438471518281, -0.04302639963354316, -0.044259360796456176, -0.04520024228042799, -0.04580712555325854, -0.0460562655730465, -0.045934374286915464, -0.045434797934223864, -0.044556941663684846, -0.043308869297123576, -0.04171356962709219, -0.03902002373114108, -0.03707255206581351, -0.03455990754460933, -0.03166086656225397, -0.03312007419140871, -0.0332803358761887, -0.03309317939764824, -0.03251831002719148, -0.031585874492323224, -0.030405249607762183, -0.02919066374731055, -0.027027925544900824, -0.021839836685155947, -0.018040491948941948, -0.015226325939192214, -0.013114117931987156, -0.011503941636822291, -0.010253647739896017, -0.009261293766523508, -0.008453062122658134, -0.00777499112484944, -0.007187391459603438, -0.007141208103114031, -0.00893542945539485, -0.0199282472796714, -0.016722026323426963, -0.014137739856857092, -0.026368445669070296, -0.024872108601969794, -0.024110457581968756, -0.02360516283401413, -0.02311284022105221, -0.022581891531293138, -0.022145455702301656, -0.021349407446246346, -0.016702093767895245, -0.015701874919863877, -0.01775942335833207, -0.016905774444740965, -0.015711973343142668, -0.01970576333407209, -0.018771710090031386, -0.018035238291067693, -0.017053353784442064, -0.01951737932169563, -0.01792496205140167, -0.028144122090565157, -0.027656811665938346, -0.02745995437181931, -0.02722962755624559, -0.02563086484457322, -0.0330438811612893, -0.03354360495208108, -0.03389270310648231, -0.03503705078299845, -0.03513026646548526, -0.032899091701186454, -0.02905713142040195, -0.02854963459206262, -0.026990687873379035, -0.031435541301538764, -0.03165963004230509, -0.03165534272402272, -0.03131603544703039, -0.029822504332066086, -0.028801987266117778, -0.027901996275854497, -0.027080901488241448, -0.026304000942918782, -0.025541597329560413, -0.024767762177498112, -0.031615211761632525, -0.03192803191128269, -0.03212494063239806, -0.03203684154779373, -0.031589120626265656, -0.030788114995206284, -0.028924742324649602, -0.03107180649976688, -0.031126278587585827, -0.03088472741629422, -0.030299036456978803, -0.02861073986452349, -0.03275650937794422, -0.03309954116750888, -0.03317773469447347, -0.03289350066807732, -0.03222393476843809, -0.0312180692954001, -0.03000972314013151, -0.02804812358795391, -0.024074911430506527, -0.02394848894299235, -0.022574442607698537, -0.025420347736803295, -0.026294986123136216, -0.02451252994707117, -0.030533917091378357, -0.03066985337955588, -0.030605885676971808, -0.030229817755743318, -0.02952640768114918, -0.027776553223285184, -0.030227252441333053, -0.030231740413221, -0.029967419735943714, -0.029382097999481157, -0.027722119160986592, -0.030470282611147103, -0.035076383622058845, -0.035768551134369574, -0.03622684275422782, -0.03633157228039814, -0.03602401610137342, -0.03529484301882297, -0.034184042338770274, -0.03279238592665671, -0.030026379334524858, -0.027155896797368354, -0.02521972841622979, -0.02846074239679375, -0.029834079256941926, -0.026224030100920274, -0.028484478063147904, -0.028239555670151403, -0.027735279915906158, -0.02699439189536181, -0.025365193952503452, -0.025312459147639386, -0.02489430694352111, -0.023544950126350224, -0.029730362450074328, -0.02979612626497382, -0.02975768946070243, -0.029457966651521353, -0.028850528371382817, -0.02719250566365015, -0.03043696706847838, -0.030502646265022998, -0.029517551914627838, -0.02995042076373076, -0.030532706592577737, -0.0312945938308897, -0.03227715021269533, -0.03353575920713287, -0.03594499272420625, -0.036107001213847606, -0.03586488492422136, -0.035201240210949135, -0.034148783969559046, -0.03280009680652001, -0.030714191403743433, -0.029218024863452024, -0.028949506096841954, -0.02759109634640609, -0.03530011626946041, -0.03613895507896697, -0.03685436518404867, -0.037282484958503434, -0.03732975797391331, -0.03605208440112555, -0.04668100585994777, -0.04942400034047351, -0.052288247805424334, -0.05669431859300893, -0.10066441313818353, -0.11779507354437593, -0.14029220962268926, -0.1697473039648054], [-8.136532417416527, -8.577736435164523, -9.161259452217383, -9.851045903097178, -10.04463055467468, -9.435619912505105, -8.797867377106071, -8.152918833884781, -7.523711878079189, -6.933266170919424, -6.403169664312811, -5.952253041837937, -5.594477893535647, -5.354088143676937, -5.27493560236503, -5.363316739910962, -5.745135096676383, -6.470825283331723, -7.519550692417019, -8.854368541212857, -10.41707592636795, -11.496577285531929, -10.346909649943148, -9.12677067689066, -7.796330206257435, -6.618986408677267, -5.520290552673231, -4.538542986775848, -3.6960174526694067, -2.999037765669676, -2.4417175228519796, -2.007312421761032, -1.6383985573327793, -1.5035532064469597, -1.6075556583003658, -1.960211649851697, -2.588587138337797, -3.532447191149162, -4.835856332300114, -6.118026666732377, -8.039885236611672, -10.27379420584436, -12.801136788143571, -13.920673279151073, -12.053177626683011, -10.120797748696171, -8.230444375429228, -6.496428688911368, -5.00109629931756, -3.6361558597274986, -2.431026450779102, -1.8383581485951466, -1.3996971771019768, -1.0823865829440837, -0.7610452089354565, -0.455986858757656, -0.24083773729416838, -0.1538346265076452, -0.09685680537668949, -0.054334243153488906, -0.04292435930384399, -0.042022111908384376, -0.03301586946165221, -0.029368018810822794, -0.013551953296566081, -0.006258071944009481, -0.005720854909411761, -0.0060918194404536155, -0.006485502047672386, -0.006907930169966234, -0.007371338913677593, -0.011037157868472034, -0.028294830041913317, -0.024825909566618735, -0.056776822833296485, -0.057571543661619075, -0.06127636771599921, -0.06719597060633378, -0.07505553442862098, -0.08491455089510569, -0.09713244707464588, -0.1123785308829127, -0.13168511714676978, -0.15654846895297037, -0.18908795853382265, -0.23227996250681668, -0.29028939743611926, -0.3689276145849583, -0.4762681535532771, -0.622646092894226, -0.850005421846673, -1.168262003920566, -1.609866255590292, -2.215340810821664, -3.031057691161484, -4.253480618268186, -5.6734063122649525, -7.4066924949882536, -9.765087233657667, -12.026170864873475, -14.308953897324654, -13.02672120874903, -10.804602259861555, -8.667166255906105, -6.735796254322506, -5.41811216028761, -4.274173400326404, -3.3235774079498124, -2.5616775417133337, -1.9686359865552245, -1.5143885687318668, -1.0468566377097217, -0.6794380522298205, -0.43933991361583336, -0.2958140313443728, -0.24703758474418758, -0.20920749646597234, -0.179323776766108, -0.15524722487827705, -0.1354993982630256, -0.11657861199980986, -0.09156312292581412, -0.0842522767748858, -0.07759797719373195, -0.07201916831672733, -0.06591054376019838, -0.04508312454801832, -0.04563639516867204, -0.04927012932974399, -0.05656837512225121, -0.02974702893878721, -0.03627879378062532, -0.006638547094374206, -0.010590235316877574, -0.017632473144060818, -0.029582849645369124, -0.02148153042660944, -0.016861853279437095, -0.03619632607024187, -0.02995221847163707, -0.02668717894944927, -0.025072783181017303, -0.02426498943892046, -0.023936884448594403, -0.042935188664174395, -0.04459972077615264, -0.0471399479776975, -0.050194789434023675, -0.05357307662693094, -0.057200738549758476, -0.06108828728546544, -0.06531280570831566, -0.07001092591624779, -0.07538099057314122, -0.08169396931909753, -0.0893139630490836, -0.09873044627065548, -0.11060594068273817, -0.12584475736854933, -0.1456909787478982, -0.17186716350958378, -0.20676949064700398, -0.25374018948169746, -0.31639359844583925, -0.4839440337687388, -0.6365121779922601, -0.8458679392748951, -1.1315851591997559, -1.6257992492620095, -2.1942805222012134, -2.9930155365930236, -3.997945844039116, -5.2714383022034195, -6.822403103762951, -8.705991639514084, -10.785708466278344, -12.936537580801396, -13.416063055921331, -11.319826180251072, -9.266137629023216, -7.574640982515913, -6.175545388381371, -4.925172466196044, -3.859945299800484, -2.9885775324758863, -2.2975700882175363, -1.734406493450154, -1.3107124005692568, -0.8599017001191492, -0.5340170044919307, -0.36161509787927076, -0.2990159140853366, -0.25146519340243256, -0.21483714042336624, -0.18612464148552263, -0.16058092171641883, -0.13749134678049943, -0.1303040038192903, -0.12425327799897212, -0.11901929246327213], [-8.007379433692918, -7.937388453990618, -7.994012077774493, -8.176143656919892, -8.477261346523013, -8.88857645470688, -9.487776973717944, -10.15322906253041, -9.721624084023304, -9.090886037563724, -8.543196167381055, -7.995474164646665, -7.467283489588934, -6.977844974140897, -6.5449613052638025, -6.18282803316804, -5.927914318086488, -5.864729499787803, -5.9483881267708005, -6.222214225383855, -6.6866409210510405, -7.431093725761485, -8.218797731234464, -9.061405649136839, -10.189617759048955, -10.528158754164263, -9.611056665966172, -8.650566182037137, -7.553575726792817, -6.603707465317265, -5.827168003901218, -5.254090886187924, -4.895019523413445, -4.689930888281121, -4.754554337072505, -5.046919037860281, -5.54927183141355, -6.252134395981999, -7.158656269336135, -8.203646159366908, -9.355582158730595, -10.562943175178626, -10.763576455860745, -9.681842796053946, -8.574388331073308, -7.482909736999509, -6.451364400480907, -5.519529601261713, -4.717382820552935, -4.056362008379154, -3.5585140281537693, -3.279071233582492, -3.318145865438346, -3.760707198930983, -4.614592940162135, -5.5357936288890315, -6.6426942690921775, -7.903707611409335, -9.269845540760887, -11.107845824453065, -11.616703608663135, -10.414381031660445, -9.144117482756924, -7.853634114968909, -6.599982831547569, -5.437592860690517, -4.4070329886075665, -3.5295223120211703, -2.807918298076834, -2.231719689761277, -1.7830468743830674, -1.4382788420520423, -1.159800695740585, -1.0053779396878153, -0.9081435205622762, -0.8606576616614526, -0.8560315390703064, -0.9316116280016308, -1.0515045446195752, -1.229297905119072, -1.5326165852550842, -2.103598902039731, -2.938024057615849, -4.089616244913047, -5.33613030728332, -6.837392139999377, -8.559859960618402, -10.967884959361747, -13.368833153230531, -13.341696833903251, -11.55620723670708, -9.712213222862056, -7.915665537177121, -6.275770867887732, -4.868303031579293, -3.478875509198681, -2.3121207692276737, -1.7551080638448697, -1.3503085677704707, -1.0708873287585758, -0.6410683653706396, -0.5576007872060884, -0.32654944473223724, -0.17905310069060862, -0.0837575405999447, -0.06162711576893125, -0.04048269090687882, -0.027464904862100625, -0.019945779898481904, -0.04445529257368838, -0.020803286355668867, -0.038861439604593775, -0.028159482190377942, -0.04421607815914904, -0.040040620215855735, -0.0351960702782735, -0.04791647957190167, -0.06645332293547164, -0.061461200457544836, -0.06079351009029028, -0.07106042182131024, -0.07722605559722741, -0.07525852089210948, -0.07645798148862955, -0.07698027566004341, -0.0767763075922964, -0.07582703873290289, -0.07414104841750369, -0.07176109492968996, -0.06878086550006826, -0.06681484821993178, -0.06172290917985257, -0.05317137735126186, -0.05365230976496331, -0.053750001624724014, -0.045203755726745336, -0.03463427653446256, -0.027083608864536764, -0.015606255341843907, -0.012877345248386006, -0.01813868818603092, -0.02760435312158933, -0.017347155810101985, -0.008339631987030884, -0.004518293011833593, -0.0021845481339040624, -0.001335429283043496, -0.005070962585680767, -0.012928868774614476, -0.027276353163315552, -0.05649781792369184, -0.04823456971081703, -0.04485085629544343, -0.043162019552212286, -0.07194313758985452, -0.06901916145301552, -0.09262737803859585, -0.11602047280707532, -0.12840130365400848, -0.14452787596395306, -0.16470529269130085, -0.189797916629522, -0.22126884298766272, -0.261296181592471, -0.3129732780425784, -0.3806069917966131, -0.47013278685047255, -0.5896651030725545, -0.7501907156987865, -0.9663812433871369, -1.2574316523368358, -1.6477009036540562, -2.16671616600504, -2.845284347805089, -3.918216513149385, -5.144528112747278, -6.636629209051919, -8.947324533685812, -10.872644627408029, -13.016156112770858, -13.29410665102857, -11.585793625882447, -9.421576305172989, -7.69648263697815, -5.855662495718617, -4.648200082526594, -3.6298449051347035, -2.467535134265091, -1.91118000962897, -1.4806627814294755, -1.1499333408035861, -0.8817003688633241, -0.6821540122308632, -0.5336911524683413, -0.4208920424281318, -0.29637012295407894, -0.257508501184589, -0.2225741760316099, -0.19569623169621642, -0.17470765388557807]]\n",
      "Average Test Reward: -1.503660789738572\n"
     ]
    }
   ],
   "source": [
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "\n",
    "# Test the best agent by loading the best weights\n",
    "dir_path = 'best_dqn_weights'\n",
    "\n",
    "dqn.load_weights(path=dir_path)\n",
    "Epsilon = 1.0\n",
    "test_episodes = 10\n",
    "test_rewards = []\n",
    "for _ in range(test_episodes):\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    test_rewards.append(reward)\n",
    "\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env = gym.make(f'{EnvName}')\n",
    "state = env.reset()\n",
    "ListOfRewards = []\n",
    "Done = False\n",
    "while not Done:\n",
    "    Q = dqn.Main(state.reshape(-1, state.shape[0]))\n",
    "    action = np.argmax(Q)\n",
    "    action = PendulumActionConverter(action)\n",
    "    AStep = np.array([action])\n",
    "    action = PendulumInverseActionConverter(action)\n",
    "    env.render()\n",
    "    SNext, reward, Done, Info = env.step(AStep)\n",
    "    # DQN.UpdateReplayMemory((state, action, reward, SNext, Done))\n",
    "    # DQN.Train(Done, reward)\n",
    "    # ListOfRewards.append(reward)\n",
    "    # all_rewards.append(reward)\n",
    "    # all_sum_rewards.append(np.sum(ListOfRewards))\n",
    "    state = SNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab646d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Main\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Main\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Target\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Target\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 1stHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ 2ndHiddenLayer (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,066</span> (19.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,066\u001b[0m (19.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from best_dqn_weights\n",
      "Episode 0\n",
      "DID NOT TRAIN..., replay memory = 1\n",
      "DID NOT TRAIN..., replay memory = 2\n",
      "DID NOT TRAIN..., replay memory = 3\n",
      "DID NOT TRAIN..., replay memory = 4\n",
      "DID NOT TRAIN..., replay memory = 5\n",
      "DID NOT TRAIN..., replay memory = 6\n",
      "DID NOT TRAIN..., replay memory = 7\n",
      "DID NOT TRAIN..., replay memory = 8\n",
      "DID NOT TRAIN..., replay memory = 9\n",
      "DID NOT TRAIN..., replay memory = 10\n",
      "DID NOT TRAIN..., replay memory = 11\n",
      "DID NOT TRAIN..., replay memory = 12\n",
      "DID NOT TRAIN..., replay memory = 13\n",
      "DID NOT TRAIN..., replay memory = 14\n",
      "DID NOT TRAIN..., replay memory = 15\n",
      "DID NOT TRAIN..., replay memory = 16\n",
      "DID NOT TRAIN..., replay memory = 17\n",
      "DID NOT TRAIN..., replay memory = 18\n",
      "DID NOT TRAIN..., replay memory = 19\n",
      "DID NOT TRAIN..., replay memory = 20\n",
      "DID NOT TRAIN..., replay memory = 21\n",
      "DID NOT TRAIN..., replay memory = 22\n",
      "DID NOT TRAIN..., replay memory = 23\n",
      "DID NOT TRAIN..., replay memory = 24\n",
      "DID NOT TRAIN..., replay memory = 25\n",
      "DID NOT TRAIN..., replay memory = 26\n",
      "DID NOT TRAIN..., replay memory = 27\n",
      "DID NOT TRAIN..., replay memory = 28\n",
      "DID NOT TRAIN..., replay memory = 29\n",
      "DID NOT TRAIN..., replay memory = 30\n",
      "DID NOT TRAIN..., replay memory = 31\n",
      "DID NOT TRAIN..., replay memory = 32\n",
      "DID NOT TRAIN..., replay memory = 33\n",
      "DID NOT TRAIN..., replay memory = 34\n",
      "DID NOT TRAIN..., replay memory = 35\n",
      "DID NOT TRAIN..., replay memory = 36\n",
      "DID NOT TRAIN..., replay memory = 37\n",
      "DID NOT TRAIN..., replay memory = 38\n",
      "DID NOT TRAIN..., replay memory = 39\n",
      "DID NOT TRAIN..., replay memory = 40\n",
      "DID NOT TRAIN..., replay memory = 41\n",
      "DID NOT TRAIN..., replay memory = 42\n",
      "DID NOT TRAIN..., replay memory = 43\n",
      "DID NOT TRAIN..., replay memory = 44\n",
      "DID NOT TRAIN..., replay memory = 45\n",
      "DID NOT TRAIN..., replay memory = 46\n",
      "DID NOT TRAIN..., replay memory = 47\n",
      "DID NOT TRAIN..., replay memory = 48\n",
      "DID NOT TRAIN..., replay memory = 49\n",
      "DID NOT TRAIN..., replay memory = 50\n",
      "DID NOT TRAIN..., replay memory = 51\n",
      "DID NOT TRAIN..., replay memory = 52\n",
      "DID NOT TRAIN..., replay memory = 53\n",
      "DID NOT TRAIN..., replay memory = 54\n",
      "DID NOT TRAIN..., replay memory = 55\n",
      "DID NOT TRAIN..., replay memory = 56\n",
      "DID NOT TRAIN..., replay memory = 57\n",
      "DID NOT TRAIN..., replay memory = 58\n",
      "DID NOT TRAIN..., replay memory = 59\n",
      "DID NOT TRAIN..., replay memory = 60\n",
      "DID NOT TRAIN..., replay memory = 61\n",
      "DID NOT TRAIN..., replay memory = 62\n",
      "DID NOT TRAIN..., replay memory = 63\n",
      "DID NOT TRAIN..., replay memory = 64\n",
      "DID NOT TRAIN..., replay memory = 65\n",
      "DID NOT TRAIN..., replay memory = 66\n",
      "DID NOT TRAIN..., replay memory = 67\n",
      "DID NOT TRAIN..., replay memory = 68\n",
      "DID NOT TRAIN..., replay memory = 69\n",
      "DID NOT TRAIN..., replay memory = 70\n",
      "DID NOT TRAIN..., replay memory = 71\n",
      "DID NOT TRAIN..., replay memory = 72\n",
      "DID NOT TRAIN..., replay memory = 73\n",
      "DID NOT TRAIN..., replay memory = 74\n",
      "DID NOT TRAIN..., replay memory = 75\n",
      "DID NOT TRAIN..., replay memory = 76\n",
      "DID NOT TRAIN..., replay memory = 77\n",
      "DID NOT TRAIN..., replay memory = 78\n",
      "DID NOT TRAIN..., replay memory = 79\n",
      "DID NOT TRAIN..., replay memory = 80\n",
      "DID NOT TRAIN..., replay memory = 81\n",
      "DID NOT TRAIN..., replay memory = 82\n",
      "DID NOT TRAIN..., replay memory = 83\n",
      "DID NOT TRAIN..., replay memory = 84\n",
      "DID NOT TRAIN..., replay memory = 85\n",
      "DID NOT TRAIN..., replay memory = 86\n",
      "DID NOT TRAIN..., replay memory = 87\n",
      "DID NOT TRAIN..., replay memory = 88\n",
      "DID NOT TRAIN..., replay memory = 89\n",
      "DID NOT TRAIN..., replay memory = 90\n",
      "DID NOT TRAIN..., replay memory = 91\n",
      "DID NOT TRAIN..., replay memory = 92\n",
      "DID NOT TRAIN..., replay memory = 93\n",
      "DID NOT TRAIN..., replay memory = 94\n",
      "DID NOT TRAIN..., replay memory = 95\n",
      "DID NOT TRAIN..., replay memory = 96\n",
      "DID NOT TRAIN..., replay memory = 97\n",
      "DID NOT TRAIN..., replay memory = 98\n",
      "DID NOT TRAIN..., replay memory = 99\n",
      "DID NOT TRAIN..., replay memory = 100\n",
      "DID NOT TRAIN..., replay memory = 101\n",
      "DID NOT TRAIN..., replay memory = 102\n",
      "DID NOT TRAIN..., replay memory = 103\n",
      "DID NOT TRAIN..., replay memory = 104\n",
      "DID NOT TRAIN..., replay memory = 105\n",
      "DID NOT TRAIN..., replay memory = 106\n",
      "DID NOT TRAIN..., replay memory = 107\n",
      "DID NOT TRAIN..., replay memory = 108\n",
      "DID NOT TRAIN..., replay memory = 109\n",
      "DID NOT TRAIN..., replay memory = 110\n",
      "DID NOT TRAIN..., replay memory = 111\n",
      "DID NOT TRAIN..., replay memory = 112\n",
      "DID NOT TRAIN..., replay memory = 113\n",
      "DID NOT TRAIN..., replay memory = 114\n",
      "DID NOT TRAIN..., replay memory = 115\n",
      "DID NOT TRAIN..., replay memory = 116\n",
      "DID NOT TRAIN..., replay memory = 117\n",
      "DID NOT TRAIN..., replay memory = 118\n",
      "DID NOT TRAIN..., replay memory = 119\n",
      "DID NOT TRAIN..., replay memory = 120\n",
      "DID NOT TRAIN..., replay memory = 121\n",
      "DID NOT TRAIN..., replay memory = 122\n",
      "DID NOT TRAIN..., replay memory = 123\n",
      "DID NOT TRAIN..., replay memory = 124\n",
      "DID NOT TRAIN..., replay memory = 125\n",
      "DID NOT TRAIN..., replay memory = 126\n",
      "DID NOT TRAIN..., replay memory = 127\n",
      "DID NOT TRAIN..., replay memory = 128\n",
      "DID NOT TRAIN..., replay memory = 129\n",
      "DID NOT TRAIN..., replay memory = 130\n",
      "DID NOT TRAIN..., replay memory = 131\n",
      "DID NOT TRAIN..., replay memory = 132\n",
      "DID NOT TRAIN..., replay memory = 133\n",
      "DID NOT TRAIN..., replay memory = 134\n",
      "DID NOT TRAIN..., replay memory = 135\n",
      "DID NOT TRAIN..., replay memory = 136\n",
      "DID NOT TRAIN..., replay memory = 137\n",
      "DID NOT TRAIN..., replay memory = 138\n",
      "DID NOT TRAIN..., replay memory = 139\n",
      "DID NOT TRAIN..., replay memory = 140\n",
      "DID NOT TRAIN..., replay memory = 141\n",
      "DID NOT TRAIN..., replay memory = 142\n",
      "DID NOT TRAIN..., replay memory = 143\n",
      "DID NOT TRAIN..., replay memory = 144\n",
      "DID NOT TRAIN..., replay memory = 145\n",
      "DID NOT TRAIN..., replay memory = 146\n",
      "DID NOT TRAIN..., replay memory = 147\n",
      "DID NOT TRAIN..., replay memory = 148\n",
      "DID NOT TRAIN..., replay memory = 149\n",
      "DID NOT TRAIN..., replay memory = 150\n",
      "DID NOT TRAIN..., replay memory = 151\n",
      "DID NOT TRAIN..., replay memory = 152\n",
      "DID NOT TRAIN..., replay memory = 153\n",
      "DID NOT TRAIN..., replay memory = 154\n",
      "DID NOT TRAIN..., replay memory = 155\n",
      "DID NOT TRAIN..., replay memory = 156\n",
      "DID NOT TRAIN..., replay memory = 157\n",
      "DID NOT TRAIN..., replay memory = 158\n",
      "DID NOT TRAIN..., replay memory = 159\n",
      "DID NOT TRAIN..., replay memory = 160\n",
      "DID NOT TRAIN..., replay memory = 161\n",
      "DID NOT TRAIN..., replay memory = 162\n",
      "DID NOT TRAIN..., replay memory = 163\n",
      "DID NOT TRAIN..., replay memory = 164\n",
      "DID NOT TRAIN..., replay memory = 165\n",
      "DID NOT TRAIN..., replay memory = 166\n",
      "DID NOT TRAIN..., replay memory = 167\n",
      "DID NOT TRAIN..., replay memory = 168\n",
      "DID NOT TRAIN..., replay memory = 169\n",
      "DID NOT TRAIN..., replay memory = 170\n",
      "DID NOT TRAIN..., replay memory = 171\n",
      "DID NOT TRAIN..., replay memory = 172\n",
      "DID NOT TRAIN..., replay memory = 173\n",
      "DID NOT TRAIN..., replay memory = 174\n",
      "DID NOT TRAIN..., replay memory = 175\n",
      "DID NOT TRAIN..., replay memory = 176\n",
      "DID NOT TRAIN..., replay memory = 177\n",
      "DID NOT TRAIN..., replay memory = 178\n",
      "DID NOT TRAIN..., replay memory = 179\n",
      "DID NOT TRAIN..., replay memory = 180\n",
      "DID NOT TRAIN..., replay memory = 181\n",
      "DID NOT TRAIN..., replay memory = 182\n",
      "DID NOT TRAIN..., replay memory = 183\n",
      "DID NOT TRAIN..., replay memory = 184\n",
      "DID NOT TRAIN..., replay memory = 185\n",
      "DID NOT TRAIN..., replay memory = 186\n",
      "DID NOT TRAIN..., replay memory = 187\n",
      "DID NOT TRAIN..., replay memory = 188\n",
      "DID NOT TRAIN..., replay memory = 189\n",
      "DID NOT TRAIN..., replay memory = 190\n",
      "DID NOT TRAIN..., replay memory = 191\n",
      "DID NOT TRAIN..., replay memory = 192\n",
      "DID NOT TRAIN..., replay memory = 193\n",
      "DID NOT TRAIN..., replay memory = 194\n",
      "DID NOT TRAIN..., replay memory = 195\n",
      "DID NOT TRAIN..., replay memory = 196\n",
      "DID NOT TRAIN..., replay memory = 197\n",
      "DID NOT TRAIN..., replay memory = 198\n",
      "DID NOT TRAIN..., replay memory = 199\n",
      "DID NOT TRAIN..., replay memory = 200\n",
      "Finished! | Return: -351.6994212424263 | average reward: -1.7584971062121315\n",
      "Episode 1\n",
      "DID NOT TRAIN..., replay memory = 201\n",
      "DID NOT TRAIN..., replay memory = 202\n",
      "DID NOT TRAIN..., replay memory = 203\n",
      "DID NOT TRAIN..., replay memory = 204\n",
      "DID NOT TRAIN..., replay memory = 205\n",
      "DID NOT TRAIN..., replay memory = 206\n",
      "DID NOT TRAIN..., replay memory = 207\n",
      "DID NOT TRAIN..., replay memory = 208\n",
      "DID NOT TRAIN..., replay memory = 209\n",
      "DID NOT TRAIN..., replay memory = 210\n",
      "DID NOT TRAIN..., replay memory = 211\n",
      "DID NOT TRAIN..., replay memory = 212\n",
      "DID NOT TRAIN..., replay memory = 213\n",
      "DID NOT TRAIN..., replay memory = 214\n",
      "DID NOT TRAIN..., replay memory = 215\n",
      "DID NOT TRAIN..., replay memory = 216\n",
      "DID NOT TRAIN..., replay memory = 217\n",
      "DID NOT TRAIN..., replay memory = 218\n",
      "DID NOT TRAIN..., replay memory = 219\n",
      "DID NOT TRAIN..., replay memory = 220\n",
      "DID NOT TRAIN..., replay memory = 221\n",
      "DID NOT TRAIN..., replay memory = 222\n",
      "DID NOT TRAIN..., replay memory = 223\n",
      "DID NOT TRAIN..., replay memory = 224\n",
      "DID NOT TRAIN..., replay memory = 225\n",
      "DID NOT TRAIN..., replay memory = 226\n",
      "DID NOT TRAIN..., replay memory = 227\n",
      "DID NOT TRAIN..., replay memory = 228\n",
      "DID NOT TRAIN..., replay memory = 229\n",
      "DID NOT TRAIN..., replay memory = 230\n",
      "DID NOT TRAIN..., replay memory = 231\n",
      "DID NOT TRAIN..., replay memory = 232\n",
      "DID NOT TRAIN..., replay memory = 233\n",
      "DID NOT TRAIN..., replay memory = 234\n",
      "DID NOT TRAIN..., replay memory = 235\n",
      "DID NOT TRAIN..., replay memory = 236\n",
      "DID NOT TRAIN..., replay memory = 237\n",
      "DID NOT TRAIN..., replay memory = 238\n",
      "DID NOT TRAIN..., replay memory = 239\n",
      "DID NOT TRAIN..., replay memory = 240\n",
      "DID NOT TRAIN..., replay memory = 241\n",
      "DID NOT TRAIN..., replay memory = 242\n",
      "DID NOT TRAIN..., replay memory = 243\n",
      "DID NOT TRAIN..., replay memory = 244\n",
      "DID NOT TRAIN..., replay memory = 245\n",
      "DID NOT TRAIN..., replay memory = 246\n",
      "DID NOT TRAIN..., replay memory = 247\n",
      "DID NOT TRAIN..., replay memory = 248\n",
      "DID NOT TRAIN..., replay memory = 249\n",
      "DID NOT TRAIN..., replay memory = 250\n",
      "DID NOT TRAIN..., replay memory = 251\n",
      "DID NOT TRAIN..., replay memory = 252\n",
      "DID NOT TRAIN..., replay memory = 253\n",
      "DID NOT TRAIN..., replay memory = 254\n",
      "DID NOT TRAIN..., replay memory = 255\n",
      "DID NOT TRAIN..., replay memory = 256\n",
      "DID NOT TRAIN..., replay memory = 257\n",
      "DID NOT TRAIN..., replay memory = 258\n",
      "DID NOT TRAIN..., replay memory = 259\n",
      "DID NOT TRAIN..., replay memory = 260\n",
      "DID NOT TRAIN..., replay memory = 261\n",
      "DID NOT TRAIN..., replay memory = 262\n",
      "DID NOT TRAIN..., replay memory = 263\n",
      "DID NOT TRAIN..., replay memory = 264\n",
      "DID NOT TRAIN..., replay memory = 265\n",
      "DID NOT TRAIN..., replay memory = 266\n",
      "DID NOT TRAIN..., replay memory = 267\n",
      "DID NOT TRAIN..., replay memory = 268\n",
      "DID NOT TRAIN..., replay memory = 269\n",
      "DID NOT TRAIN..., replay memory = 270\n",
      "DID NOT TRAIN..., replay memory = 271\n",
      "DID NOT TRAIN..., replay memory = 272\n",
      "DID NOT TRAIN..., replay memory = 273\n",
      "DID NOT TRAIN..., replay memory = 274\n",
      "DID NOT TRAIN..., replay memory = 275\n",
      "DID NOT TRAIN..., replay memory = 276\n",
      "DID NOT TRAIN..., replay memory = 277\n",
      "DID NOT TRAIN..., replay memory = 278\n",
      "DID NOT TRAIN..., replay memory = 279\n",
      "DID NOT TRAIN..., replay memory = 280\n",
      "DID NOT TRAIN..., replay memory = 281\n",
      "DID NOT TRAIN..., replay memory = 282\n",
      "DID NOT TRAIN..., replay memory = 283\n",
      "DID NOT TRAIN..., replay memory = 284\n",
      "DID NOT TRAIN..., replay memory = 285\n",
      "DID NOT TRAIN..., replay memory = 286\n",
      "DID NOT TRAIN..., replay memory = 287\n",
      "DID NOT TRAIN..., replay memory = 288\n",
      "DID NOT TRAIN..., replay memory = 289\n",
      "DID NOT TRAIN..., replay memory = 290\n",
      "DID NOT TRAIN..., replay memory = 291\n",
      "DID NOT TRAIN..., replay memory = 292\n",
      "DID NOT TRAIN..., replay memory = 293\n",
      "DID NOT TRAIN..., replay memory = 294\n",
      "DID NOT TRAIN..., replay memory = 295\n",
      "DID NOT TRAIN..., replay memory = 296\n",
      "DID NOT TRAIN..., replay memory = 297\n",
      "DID NOT TRAIN..., replay memory = 298\n",
      "DID NOT TRAIN..., replay memory = 299\n",
      "DID NOT TRAIN..., replay memory = 300\n",
      "DID NOT TRAIN..., replay memory = 301\n",
      "DID NOT TRAIN..., replay memory = 302\n",
      "DID NOT TRAIN..., replay memory = 303\n",
      "DID NOT TRAIN..., replay memory = 304\n",
      "DID NOT TRAIN..., replay memory = 305\n",
      "DID NOT TRAIN..., replay memory = 306\n",
      "DID NOT TRAIN..., replay memory = 307\n",
      "DID NOT TRAIN..., replay memory = 308\n",
      "DID NOT TRAIN..., replay memory = 309\n",
      "DID NOT TRAIN..., replay memory = 310\n",
      "DID NOT TRAIN..., replay memory = 311\n",
      "DID NOT TRAIN..., replay memory = 312\n",
      "DID NOT TRAIN..., replay memory = 313\n",
      "DID NOT TRAIN..., replay memory = 314\n",
      "DID NOT TRAIN..., replay memory = 315\n",
      "DID NOT TRAIN..., replay memory = 316\n",
      "DID NOT TRAIN..., replay memory = 317\n",
      "DID NOT TRAIN..., replay memory = 318\n",
      "DID NOT TRAIN..., replay memory = 319\n",
      "DID NOT TRAIN..., replay memory = 320\n",
      "DID NOT TRAIN..., replay memory = 321\n",
      "DID NOT TRAIN..., replay memory = 322\n",
      "DID NOT TRAIN..., replay memory = 323\n",
      "DID NOT TRAIN..., replay memory = 324\n",
      "DID NOT TRAIN..., replay memory = 325\n",
      "DID NOT TRAIN..., replay memory = 326\n",
      "DID NOT TRAIN..., replay memory = 327\n",
      "DID NOT TRAIN..., replay memory = 328\n",
      "DID NOT TRAIN..., replay memory = 329\n",
      "DID NOT TRAIN..., replay memory = 330\n",
      "DID NOT TRAIN..., replay memory = 331\n",
      "DID NOT TRAIN..., replay memory = 332\n",
      "DID NOT TRAIN..., replay memory = 333\n",
      "DID NOT TRAIN..., replay memory = 334\n",
      "DID NOT TRAIN..., replay memory = 335\n",
      "DID NOT TRAIN..., replay memory = 336\n",
      "DID NOT TRAIN..., replay memory = 337\n",
      "DID NOT TRAIN..., replay memory = 338\n",
      "DID NOT TRAIN..., replay memory = 339\n",
      "DID NOT TRAIN..., replay memory = 340\n",
      "DID NOT TRAIN..., replay memory = 341\n",
      "DID NOT TRAIN..., replay memory = 342\n",
      "DID NOT TRAIN..., replay memory = 343\n",
      "DID NOT TRAIN..., replay memory = 344\n",
      "DID NOT TRAIN..., replay memory = 345\n",
      "DID NOT TRAIN..., replay memory = 346\n",
      "DID NOT TRAIN..., replay memory = 347\n",
      "DID NOT TRAIN..., replay memory = 348\n",
      "DID NOT TRAIN..., replay memory = 349\n",
      "DID NOT TRAIN..., replay memory = 350\n",
      "DID NOT TRAIN..., replay memory = 351\n",
      "DID NOT TRAIN..., replay memory = 352\n",
      "DID NOT TRAIN..., replay memory = 353\n",
      "DID NOT TRAIN..., replay memory = 354\n",
      "DID NOT TRAIN..., replay memory = 355\n",
      "DID NOT TRAIN..., replay memory = 356\n",
      "DID NOT TRAIN..., replay memory = 357\n",
      "DID NOT TRAIN..., replay memory = 358\n",
      "DID NOT TRAIN..., replay memory = 359\n",
      "DID NOT TRAIN..., replay memory = 360\n",
      "DID NOT TRAIN..., replay memory = 361\n",
      "DID NOT TRAIN..., replay memory = 362\n",
      "DID NOT TRAIN..., replay memory = 363\n",
      "DID NOT TRAIN..., replay memory = 364\n",
      "DID NOT TRAIN..., replay memory = 365\n",
      "DID NOT TRAIN..., replay memory = 366\n",
      "DID NOT TRAIN..., replay memory = 367\n",
      "DID NOT TRAIN..., replay memory = 368\n",
      "DID NOT TRAIN..., replay memory = 369\n",
      "DID NOT TRAIN..., replay memory = 370\n",
      "DID NOT TRAIN..., replay memory = 371\n",
      "DID NOT TRAIN..., replay memory = 372\n",
      "DID NOT TRAIN..., replay memory = 373\n",
      "DID NOT TRAIN..., replay memory = 374\n",
      "DID NOT TRAIN..., replay memory = 375\n",
      "DID NOT TRAIN..., replay memory = 376\n",
      "DID NOT TRAIN..., replay memory = 377\n",
      "DID NOT TRAIN..., replay memory = 378\n",
      "DID NOT TRAIN..., replay memory = 379\n",
      "DID NOT TRAIN..., replay memory = 380\n",
      "DID NOT TRAIN..., replay memory = 381\n",
      "DID NOT TRAIN..., replay memory = 382\n",
      "DID NOT TRAIN..., replay memory = 383\n",
      "DID NOT TRAIN..., replay memory = 384\n",
      "DID NOT TRAIN..., replay memory = 385\n",
      "DID NOT TRAIN..., replay memory = 386\n",
      "DID NOT TRAIN..., replay memory = 387\n",
      "DID NOT TRAIN..., replay memory = 388\n",
      "DID NOT TRAIN..., replay memory = 389\n",
      "DID NOT TRAIN..., replay memory = 390\n",
      "DID NOT TRAIN..., replay memory = 391\n",
      "DID NOT TRAIN..., replay memory = 392\n",
      "DID NOT TRAIN..., replay memory = 393\n",
      "DID NOT TRAIN..., replay memory = 394\n",
      "DID NOT TRAIN..., replay memory = 395\n",
      "DID NOT TRAIN..., replay memory = 396\n",
      "DID NOT TRAIN..., replay memory = 397\n",
      "DID NOT TRAIN..., replay memory = 398\n",
      "DID NOT TRAIN..., replay memory = 399\n",
      "DID NOT TRAIN..., replay memory = 400\n",
      "Finished! | Return: -123.25169647951117 | average reward: -0.6162584823975559\n",
      "Episode 2\n",
      "DID NOT TRAIN..., replay memory = 401\n",
      "DID NOT TRAIN..., replay memory = 402\n",
      "DID NOT TRAIN..., replay memory = 403\n",
      "DID NOT TRAIN..., replay memory = 404\n",
      "DID NOT TRAIN..., replay memory = 405\n",
      "DID NOT TRAIN..., replay memory = 406\n",
      "DID NOT TRAIN..., replay memory = 407\n",
      "DID NOT TRAIN..., replay memory = 408\n",
      "DID NOT TRAIN..., replay memory = 409\n",
      "DID NOT TRAIN..., replay memory = 410\n",
      "DID NOT TRAIN..., replay memory = 411\n",
      "DID NOT TRAIN..., replay memory = 412\n",
      "DID NOT TRAIN..., replay memory = 413\n",
      "DID NOT TRAIN..., replay memory = 414\n",
      "DID NOT TRAIN..., replay memory = 415\n",
      "DID NOT TRAIN..., replay memory = 416\n",
      "DID NOT TRAIN..., replay memory = 417\n",
      "DID NOT TRAIN..., replay memory = 418\n",
      "DID NOT TRAIN..., replay memory = 419\n",
      "DID NOT TRAIN..., replay memory = 420\n",
      "DID NOT TRAIN..., replay memory = 421\n",
      "DID NOT TRAIN..., replay memory = 422\n",
      "DID NOT TRAIN..., replay memory = 423\n",
      "DID NOT TRAIN..., replay memory = 424\n",
      "DID NOT TRAIN..., replay memory = 425\n",
      "DID NOT TRAIN..., replay memory = 426\n",
      "DID NOT TRAIN..., replay memory = 427\n",
      "DID NOT TRAIN..., replay memory = 428\n",
      "DID NOT TRAIN..., replay memory = 429\n",
      "DID NOT TRAIN..., replay memory = 430\n",
      "DID NOT TRAIN..., replay memory = 431\n",
      "DID NOT TRAIN..., replay memory = 432\n",
      "DID NOT TRAIN..., replay memory = 433\n",
      "DID NOT TRAIN..., replay memory = 434\n",
      "DID NOT TRAIN..., replay memory = 435\n",
      "DID NOT TRAIN..., replay memory = 436\n",
      "DID NOT TRAIN..., replay memory = 437\n",
      "DID NOT TRAIN..., replay memory = 438\n",
      "DID NOT TRAIN..., replay memory = 439\n",
      "DID NOT TRAIN..., replay memory = 440\n",
      "DID NOT TRAIN..., replay memory = 441\n",
      "DID NOT TRAIN..., replay memory = 442\n",
      "DID NOT TRAIN..., replay memory = 443\n",
      "DID NOT TRAIN..., replay memory = 444\n",
      "DID NOT TRAIN..., replay memory = 445\n",
      "DID NOT TRAIN..., replay memory = 446\n",
      "DID NOT TRAIN..., replay memory = 447\n",
      "DID NOT TRAIN..., replay memory = 448\n",
      "DID NOT TRAIN..., replay memory = 449\n",
      "DID NOT TRAIN..., replay memory = 450\n",
      "DID NOT TRAIN..., replay memory = 451\n",
      "DID NOT TRAIN..., replay memory = 452\n",
      "DID NOT TRAIN..., replay memory = 453\n",
      "DID NOT TRAIN..., replay memory = 454\n",
      "DID NOT TRAIN..., replay memory = 455\n",
      "DID NOT TRAIN..., replay memory = 456\n",
      "DID NOT TRAIN..., replay memory = 457\n",
      "DID NOT TRAIN..., replay memory = 458\n",
      "DID NOT TRAIN..., replay memory = 459\n",
      "DID NOT TRAIN..., replay memory = 460\n",
      "DID NOT TRAIN..., replay memory = 461\n",
      "DID NOT TRAIN..., replay memory = 462\n",
      "DID NOT TRAIN..., replay memory = 463\n",
      "DID NOT TRAIN..., replay memory = 464\n",
      "DID NOT TRAIN..., replay memory = 465\n",
      "DID NOT TRAIN..., replay memory = 466\n",
      "DID NOT TRAIN..., replay memory = 467\n",
      "DID NOT TRAIN..., replay memory = 468\n",
      "DID NOT TRAIN..., replay memory = 469\n",
      "DID NOT TRAIN..., replay memory = 470\n",
      "DID NOT TRAIN..., replay memory = 471\n",
      "DID NOT TRAIN..., replay memory = 472\n",
      "DID NOT TRAIN..., replay memory = 473\n",
      "DID NOT TRAIN..., replay memory = 474\n",
      "DID NOT TRAIN..., replay memory = 475\n",
      "DID NOT TRAIN..., replay memory = 476\n",
      "DID NOT TRAIN..., replay memory = 477\n",
      "DID NOT TRAIN..., replay memory = 478\n",
      "DID NOT TRAIN..., replay memory = 479\n",
      "DID NOT TRAIN..., replay memory = 480\n",
      "DID NOT TRAIN..., replay memory = 481\n",
      "DID NOT TRAIN..., replay memory = 482\n",
      "DID NOT TRAIN..., replay memory = 483\n",
      "DID NOT TRAIN..., replay memory = 484\n",
      "DID NOT TRAIN..., replay memory = 485\n",
      "DID NOT TRAIN..., replay memory = 486\n",
      "DID NOT TRAIN..., replay memory = 487\n",
      "DID NOT TRAIN..., replay memory = 488\n",
      "DID NOT TRAIN..., replay memory = 489\n",
      "DID NOT TRAIN..., replay memory = 490\n",
      "DID NOT TRAIN..., replay memory = 491\n",
      "DID NOT TRAIN..., replay memory = 492\n",
      "DID NOT TRAIN..., replay memory = 493\n",
      "DID NOT TRAIN..., replay memory = 494\n",
      "DID NOT TRAIN..., replay memory = 495\n",
      "DID NOT TRAIN..., replay memory = 496\n",
      "DID NOT TRAIN..., replay memory = 497\n",
      "DID NOT TRAIN..., replay memory = 498\n",
      "DID NOT TRAIN..., replay memory = 499\n",
      "DID NOT TRAIN..., replay memory = 500\n",
      "DID NOT TRAIN..., replay memory = 501\n",
      "DID NOT TRAIN..., replay memory = 502\n",
      "DID NOT TRAIN..., replay memory = 503\n",
      "DID NOT TRAIN..., replay memory = 504\n",
      "DID NOT TRAIN..., replay memory = 505\n",
      "DID NOT TRAIN..., replay memory = 506\n",
      "DID NOT TRAIN..., replay memory = 507\n",
      "DID NOT TRAIN..., replay memory = 508\n",
      "DID NOT TRAIN..., replay memory = 509\n",
      "DID NOT TRAIN..., replay memory = 510\n",
      "DID NOT TRAIN..., replay memory = 511\n",
      "DID NOT TRAIN..., replay memory = 512\n",
      "DID NOT TRAIN..., replay memory = 513\n",
      "DID NOT TRAIN..., replay memory = 514\n",
      "DID NOT TRAIN..., replay memory = 515\n",
      "DID NOT TRAIN..., replay memory = 516\n",
      "DID NOT TRAIN..., replay memory = 517\n",
      "DID NOT TRAIN..., replay memory = 518\n",
      "DID NOT TRAIN..., replay memory = 519\n",
      "DID NOT TRAIN..., replay memory = 520\n",
      "DID NOT TRAIN..., replay memory = 521\n",
      "DID NOT TRAIN..., replay memory = 522\n",
      "DID NOT TRAIN..., replay memory = 523\n",
      "DID NOT TRAIN..., replay memory = 524\n",
      "DID NOT TRAIN..., replay memory = 525\n",
      "DID NOT TRAIN..., replay memory = 526\n",
      "DID NOT TRAIN..., replay memory = 527\n",
      "DID NOT TRAIN..., replay memory = 528\n",
      "DID NOT TRAIN..., replay memory = 529\n",
      "DID NOT TRAIN..., replay memory = 530\n",
      "DID NOT TRAIN..., replay memory = 531\n",
      "DID NOT TRAIN..., replay memory = 532\n",
      "DID NOT TRAIN..., replay memory = 533\n",
      "DID NOT TRAIN..., replay memory = 534\n",
      "DID NOT TRAIN..., replay memory = 535\n",
      "DID NOT TRAIN..., replay memory = 536\n",
      "DID NOT TRAIN..., replay memory = 537\n",
      "DID NOT TRAIN..., replay memory = 538\n",
      "DID NOT TRAIN..., replay memory = 539\n",
      "DID NOT TRAIN..., replay memory = 540\n",
      "DID NOT TRAIN..., replay memory = 541\n",
      "DID NOT TRAIN..., replay memory = 542\n",
      "DID NOT TRAIN..., replay memory = 543\n",
      "DID NOT TRAIN..., replay memory = 544\n",
      "DID NOT TRAIN..., replay memory = 545\n",
      "DID NOT TRAIN..., replay memory = 546\n",
      "DID NOT TRAIN..., replay memory = 547\n",
      "DID NOT TRAIN..., replay memory = 548\n",
      "DID NOT TRAIN..., replay memory = 549\n",
      "DID NOT TRAIN..., replay memory = 550\n",
      "DID NOT TRAIN..., replay memory = 551\n",
      "DID NOT TRAIN..., replay memory = 552\n",
      "DID NOT TRAIN..., replay memory = 553\n",
      "DID NOT TRAIN..., replay memory = 554\n",
      "DID NOT TRAIN..., replay memory = 555\n",
      "DID NOT TRAIN..., replay memory = 556\n",
      "DID NOT TRAIN..., replay memory = 557\n",
      "DID NOT TRAIN..., replay memory = 558\n",
      "DID NOT TRAIN..., replay memory = 559\n",
      "DID NOT TRAIN..., replay memory = 560\n",
      "DID NOT TRAIN..., replay memory = 561\n",
      "DID NOT TRAIN..., replay memory = 562\n",
      "DID NOT TRAIN..., replay memory = 563\n",
      "DID NOT TRAIN..., replay memory = 564\n",
      "DID NOT TRAIN..., replay memory = 565\n",
      "DID NOT TRAIN..., replay memory = 566\n",
      "DID NOT TRAIN..., replay memory = 567\n",
      "DID NOT TRAIN..., replay memory = 568\n",
      "DID NOT TRAIN..., replay memory = 569\n",
      "DID NOT TRAIN..., replay memory = 570\n",
      "DID NOT TRAIN..., replay memory = 571\n",
      "DID NOT TRAIN..., replay memory = 572\n",
      "DID NOT TRAIN..., replay memory = 573\n",
      "DID NOT TRAIN..., replay memory = 574\n",
      "DID NOT TRAIN..., replay memory = 575\n",
      "DID NOT TRAIN..., replay memory = 576\n",
      "DID NOT TRAIN..., replay memory = 577\n",
      "DID NOT TRAIN..., replay memory = 578\n",
      "DID NOT TRAIN..., replay memory = 579\n",
      "DID NOT TRAIN..., replay memory = 580\n",
      "DID NOT TRAIN..., replay memory = 581\n",
      "DID NOT TRAIN..., replay memory = 582\n",
      "DID NOT TRAIN..., replay memory = 583\n",
      "DID NOT TRAIN..., replay memory = 584\n",
      "DID NOT TRAIN..., replay memory = 585\n",
      "DID NOT TRAIN..., replay memory = 586\n",
      "DID NOT TRAIN..., replay memory = 587\n",
      "DID NOT TRAIN..., replay memory = 588\n",
      "DID NOT TRAIN..., replay memory = 589\n",
      "DID NOT TRAIN..., replay memory = 590\n",
      "DID NOT TRAIN..., replay memory = 591\n",
      "DID NOT TRAIN..., replay memory = 592\n",
      "DID NOT TRAIN..., replay memory = 593\n",
      "DID NOT TRAIN..., replay memory = 594\n",
      "DID NOT TRAIN..., replay memory = 595\n",
      "DID NOT TRAIN..., replay memory = 596\n",
      "DID NOT TRAIN..., replay memory = 597\n",
      "DID NOT TRAIN..., replay memory = 598\n",
      "DID NOT TRAIN..., replay memory = 599\n",
      "DID NOT TRAIN..., replay memory = 600\n",
      "Finished! | Return: -136.22606981256598 | average reward: -0.6811303490628299\n",
      "Episode 3\n",
      "DID NOT TRAIN..., replay memory = 601\n",
      "DID NOT TRAIN..., replay memory = 602\n",
      "DID NOT TRAIN..., replay memory = 603\n",
      "DID NOT TRAIN..., replay memory = 604\n",
      "DID NOT TRAIN..., replay memory = 605\n",
      "DID NOT TRAIN..., replay memory = 606\n",
      "DID NOT TRAIN..., replay memory = 607\n",
      "DID NOT TRAIN..., replay memory = 608\n",
      "DID NOT TRAIN..., replay memory = 609\n",
      "DID NOT TRAIN..., replay memory = 610\n",
      "DID NOT TRAIN..., replay memory = 611\n",
      "DID NOT TRAIN..., replay memory = 612\n",
      "DID NOT TRAIN..., replay memory = 613\n",
      "DID NOT TRAIN..., replay memory = 614\n",
      "DID NOT TRAIN..., replay memory = 615\n",
      "DID NOT TRAIN..., replay memory = 616\n",
      "DID NOT TRAIN..., replay memory = 617\n",
      "DID NOT TRAIN..., replay memory = 618\n",
      "DID NOT TRAIN..., replay memory = 619\n",
      "DID NOT TRAIN..., replay memory = 620\n",
      "DID NOT TRAIN..., replay memory = 621\n",
      "DID NOT TRAIN..., replay memory = 622\n",
      "DID NOT TRAIN..., replay memory = 623\n",
      "DID NOT TRAIN..., replay memory = 624\n",
      "DID NOT TRAIN..., replay memory = 625\n",
      "DID NOT TRAIN..., replay memory = 626\n",
      "DID NOT TRAIN..., replay memory = 627\n",
      "DID NOT TRAIN..., replay memory = 628\n",
      "DID NOT TRAIN..., replay memory = 629\n",
      "DID NOT TRAIN..., replay memory = 630\n",
      "DID NOT TRAIN..., replay memory = 631\n",
      "DID NOT TRAIN..., replay memory = 632\n",
      "DID NOT TRAIN..., replay memory = 633\n",
      "DID NOT TRAIN..., replay memory = 634\n",
      "DID NOT TRAIN..., replay memory = 635\n",
      "DID NOT TRAIN..., replay memory = 636\n",
      "DID NOT TRAIN..., replay memory = 637\n",
      "DID NOT TRAIN..., replay memory = 638\n",
      "DID NOT TRAIN..., replay memory = 639\n",
      "DID NOT TRAIN..., replay memory = 640\n",
      "DID NOT TRAIN..., replay memory = 641\n",
      "DID NOT TRAIN..., replay memory = 642\n",
      "DID NOT TRAIN..., replay memory = 643\n",
      "DID NOT TRAIN..., replay memory = 644\n",
      "DID NOT TRAIN..., replay memory = 645\n",
      "DID NOT TRAIN..., replay memory = 646\n",
      "DID NOT TRAIN..., replay memory = 647\n",
      "DID NOT TRAIN..., replay memory = 648\n",
      "DID NOT TRAIN..., replay memory = 649\n",
      "DID NOT TRAIN..., replay memory = 650\n",
      "DID NOT TRAIN..., replay memory = 651\n",
      "DID NOT TRAIN..., replay memory = 652\n",
      "DID NOT TRAIN..., replay memory = 653\n",
      "DID NOT TRAIN..., replay memory = 654\n",
      "DID NOT TRAIN..., replay memory = 655\n",
      "DID NOT TRAIN..., replay memory = 656\n",
      "DID NOT TRAIN..., replay memory = 657\n",
      "DID NOT TRAIN..., replay memory = 658\n",
      "DID NOT TRAIN..., replay memory = 659\n",
      "DID NOT TRAIN..., replay memory = 660\n",
      "DID NOT TRAIN..., replay memory = 661\n",
      "DID NOT TRAIN..., replay memory = 662\n",
      "DID NOT TRAIN..., replay memory = 663\n",
      "DID NOT TRAIN..., replay memory = 664\n",
      "DID NOT TRAIN..., replay memory = 665\n",
      "DID NOT TRAIN..., replay memory = 666\n",
      "DID NOT TRAIN..., replay memory = 667\n",
      "DID NOT TRAIN..., replay memory = 668\n",
      "DID NOT TRAIN..., replay memory = 669\n",
      "DID NOT TRAIN..., replay memory = 670\n",
      "DID NOT TRAIN..., replay memory = 671\n",
      "DID NOT TRAIN..., replay memory = 672\n",
      "DID NOT TRAIN..., replay memory = 673\n",
      "DID NOT TRAIN..., replay memory = 674\n",
      "DID NOT TRAIN..., replay memory = 675\n",
      "DID NOT TRAIN..., replay memory = 676\n",
      "DID NOT TRAIN..., replay memory = 677\n",
      "DID NOT TRAIN..., replay memory = 678\n",
      "DID NOT TRAIN..., replay memory = 679\n",
      "DID NOT TRAIN..., replay memory = 680\n",
      "DID NOT TRAIN..., replay memory = 681\n",
      "DID NOT TRAIN..., replay memory = 682\n",
      "DID NOT TRAIN..., replay memory = 683\n",
      "DID NOT TRAIN..., replay memory = 684\n",
      "DID NOT TRAIN..., replay memory = 685\n",
      "DID NOT TRAIN..., replay memory = 686\n",
      "DID NOT TRAIN..., replay memory = 687\n",
      "DID NOT TRAIN..., replay memory = 688\n",
      "DID NOT TRAIN..., replay memory = 689\n",
      "DID NOT TRAIN..., replay memory = 690\n",
      "DID NOT TRAIN..., replay memory = 691\n",
      "DID NOT TRAIN..., replay memory = 692\n",
      "DID NOT TRAIN..., replay memory = 693\n",
      "DID NOT TRAIN..., replay memory = 694\n",
      "DID NOT TRAIN..., replay memory = 695\n",
      "DID NOT TRAIN..., replay memory = 696\n",
      "DID NOT TRAIN..., replay memory = 697\n",
      "DID NOT TRAIN..., replay memory = 698\n",
      "DID NOT TRAIN..., replay memory = 699\n",
      "DID NOT TRAIN..., replay memory = 700\n",
      "DID NOT TRAIN..., replay memory = 701\n",
      "DID NOT TRAIN..., replay memory = 702\n",
      "DID NOT TRAIN..., replay memory = 703\n",
      "DID NOT TRAIN..., replay memory = 704\n",
      "DID NOT TRAIN..., replay memory = 705\n",
      "DID NOT TRAIN..., replay memory = 706\n",
      "DID NOT TRAIN..., replay memory = 707\n",
      "DID NOT TRAIN..., replay memory = 708\n",
      "DID NOT TRAIN..., replay memory = 709\n",
      "DID NOT TRAIN..., replay memory = 710\n",
      "DID NOT TRAIN..., replay memory = 711\n",
      "DID NOT TRAIN..., replay memory = 712\n",
      "DID NOT TRAIN..., replay memory = 713\n",
      "DID NOT TRAIN..., replay memory = 714\n",
      "DID NOT TRAIN..., replay memory = 715\n",
      "DID NOT TRAIN..., replay memory = 716\n",
      "DID NOT TRAIN..., replay memory = 717\n",
      "DID NOT TRAIN..., replay memory = 718\n",
      "DID NOT TRAIN..., replay memory = 719\n",
      "DID NOT TRAIN..., replay memory = 720\n",
      "DID NOT TRAIN..., replay memory = 721\n",
      "DID NOT TRAIN..., replay memory = 722\n",
      "DID NOT TRAIN..., replay memory = 723\n",
      "DID NOT TRAIN..., replay memory = 724\n",
      "DID NOT TRAIN..., replay memory = 725\n",
      "DID NOT TRAIN..., replay memory = 726\n",
      "DID NOT TRAIN..., replay memory = 727\n",
      "DID NOT TRAIN..., replay memory = 728\n",
      "DID NOT TRAIN..., replay memory = 729\n",
      "DID NOT TRAIN..., replay memory = 730\n",
      "DID NOT TRAIN..., replay memory = 731\n",
      "DID NOT TRAIN..., replay memory = 732\n",
      "DID NOT TRAIN..., replay memory = 733\n",
      "DID NOT TRAIN..., replay memory = 734\n",
      "DID NOT TRAIN..., replay memory = 735\n",
      "DID NOT TRAIN..., replay memory = 736\n",
      "DID NOT TRAIN..., replay memory = 737\n",
      "DID NOT TRAIN..., replay memory = 738\n",
      "DID NOT TRAIN..., replay memory = 739\n",
      "DID NOT TRAIN..., replay memory = 740\n",
      "DID NOT TRAIN..., replay memory = 741\n",
      "DID NOT TRAIN..., replay memory = 742\n",
      "DID NOT TRAIN..., replay memory = 743\n",
      "DID NOT TRAIN..., replay memory = 744\n",
      "DID NOT TRAIN..., replay memory = 745\n",
      "DID NOT TRAIN..., replay memory = 746\n",
      "DID NOT TRAIN..., replay memory = 747\n",
      "DID NOT TRAIN..., replay memory = 748\n",
      "DID NOT TRAIN..., replay memory = 749\n",
      "DID NOT TRAIN..., replay memory = 750\n",
      "DID NOT TRAIN..., replay memory = 751\n",
      "DID NOT TRAIN..., replay memory = 752\n",
      "DID NOT TRAIN..., replay memory = 753\n",
      "DID NOT TRAIN..., replay memory = 754\n",
      "DID NOT TRAIN..., replay memory = 755\n",
      "DID NOT TRAIN..., replay memory = 756\n",
      "DID NOT TRAIN..., replay memory = 757\n",
      "DID NOT TRAIN..., replay memory = 758\n",
      "DID NOT TRAIN..., replay memory = 759\n",
      "DID NOT TRAIN..., replay memory = 760\n",
      "DID NOT TRAIN..., replay memory = 761\n",
      "DID NOT TRAIN..., replay memory = 762\n",
      "DID NOT TRAIN..., replay memory = 763\n",
      "DID NOT TRAIN..., replay memory = 764\n",
      "DID NOT TRAIN..., replay memory = 765\n",
      "DID NOT TRAIN..., replay memory = 766\n",
      "DID NOT TRAIN..., replay memory = 767\n",
      "DID NOT TRAIN..., replay memory = 768\n",
      "DID NOT TRAIN..., replay memory = 769\n",
      "DID NOT TRAIN..., replay memory = 770\n",
      "DID NOT TRAIN..., replay memory = 771\n",
      "DID NOT TRAIN..., replay memory = 772\n",
      "DID NOT TRAIN..., replay memory = 773\n",
      "DID NOT TRAIN..., replay memory = 774\n",
      "DID NOT TRAIN..., replay memory = 775\n",
      "DID NOT TRAIN..., replay memory = 776\n",
      "DID NOT TRAIN..., replay memory = 777\n",
      "DID NOT TRAIN..., replay memory = 778\n",
      "DID NOT TRAIN..., replay memory = 779\n",
      "DID NOT TRAIN..., replay memory = 780\n",
      "DID NOT TRAIN..., replay memory = 781\n",
      "DID NOT TRAIN..., replay memory = 782\n",
      "DID NOT TRAIN..., replay memory = 783\n",
      "DID NOT TRAIN..., replay memory = 784\n",
      "DID NOT TRAIN..., replay memory = 785\n",
      "DID NOT TRAIN..., replay memory = 786\n",
      "DID NOT TRAIN..., replay memory = 787\n",
      "DID NOT TRAIN..., replay memory = 788\n",
      "DID NOT TRAIN..., replay memory = 789\n",
      "DID NOT TRAIN..., replay memory = 790\n",
      "DID NOT TRAIN..., replay memory = 791\n",
      "DID NOT TRAIN..., replay memory = 792\n",
      "DID NOT TRAIN..., replay memory = 793\n",
      "DID NOT TRAIN..., replay memory = 794\n",
      "DID NOT TRAIN..., replay memory = 795\n",
      "DID NOT TRAIN..., replay memory = 796\n",
      "DID NOT TRAIN..., replay memory = 797\n",
      "DID NOT TRAIN..., replay memory = 798\n",
      "DID NOT TRAIN..., replay memory = 799\n",
      "DID NOT TRAIN..., replay memory = 800\n",
      "Finished! | Return: -135.31571404481122 | average reward: -0.6765785702240561\n",
      "Episode 4\n",
      "DID NOT TRAIN..., replay memory = 801\n",
      "DID NOT TRAIN..., replay memory = 802\n",
      "DID NOT TRAIN..., replay memory = 803\n",
      "DID NOT TRAIN..., replay memory = 804\n",
      "DID NOT TRAIN..., replay memory = 805\n",
      "DID NOT TRAIN..., replay memory = 806\n",
      "DID NOT TRAIN..., replay memory = 807\n",
      "DID NOT TRAIN..., replay memory = 808\n",
      "DID NOT TRAIN..., replay memory = 809\n",
      "DID NOT TRAIN..., replay memory = 810\n",
      "DID NOT TRAIN..., replay memory = 811\n",
      "DID NOT TRAIN..., replay memory = 812\n",
      "DID NOT TRAIN..., replay memory = 813\n",
      "DID NOT TRAIN..., replay memory = 814\n",
      "DID NOT TRAIN..., replay memory = 815\n",
      "DID NOT TRAIN..., replay memory = 816\n",
      "DID NOT TRAIN..., replay memory = 817\n",
      "DID NOT TRAIN..., replay memory = 818\n",
      "DID NOT TRAIN..., replay memory = 819\n",
      "DID NOT TRAIN..., replay memory = 820\n",
      "DID NOT TRAIN..., replay memory = 821\n",
      "DID NOT TRAIN..., replay memory = 822\n",
      "DID NOT TRAIN..., replay memory = 823\n",
      "DID NOT TRAIN..., replay memory = 824\n",
      "DID NOT TRAIN..., replay memory = 825\n",
      "DID NOT TRAIN..., replay memory = 826\n",
      "DID NOT TRAIN..., replay memory = 827\n",
      "DID NOT TRAIN..., replay memory = 828\n",
      "DID NOT TRAIN..., replay memory = 829\n",
      "DID NOT TRAIN..., replay memory = 830\n",
      "DID NOT TRAIN..., replay memory = 831\n",
      "DID NOT TRAIN..., replay memory = 832\n",
      "DID NOT TRAIN..., replay memory = 833\n",
      "DID NOT TRAIN..., replay memory = 834\n",
      "DID NOT TRAIN..., replay memory = 835\n",
      "DID NOT TRAIN..., replay memory = 836\n",
      "DID NOT TRAIN..., replay memory = 837\n",
      "DID NOT TRAIN..., replay memory = 838\n",
      "DID NOT TRAIN..., replay memory = 839\n",
      "DID NOT TRAIN..., replay memory = 840\n",
      "DID NOT TRAIN..., replay memory = 841\n",
      "DID NOT TRAIN..., replay memory = 842\n",
      "DID NOT TRAIN..., replay memory = 843\n",
      "DID NOT TRAIN..., replay memory = 844\n",
      "DID NOT TRAIN..., replay memory = 845\n",
      "DID NOT TRAIN..., replay memory = 846\n",
      "DID NOT TRAIN..., replay memory = 847\n",
      "DID NOT TRAIN..., replay memory = 848\n",
      "DID NOT TRAIN..., replay memory = 849\n",
      "DID NOT TRAIN..., replay memory = 850\n",
      "DID NOT TRAIN..., replay memory = 851\n",
      "DID NOT TRAIN..., replay memory = 852\n",
      "DID NOT TRAIN..., replay memory = 853\n",
      "DID NOT TRAIN..., replay memory = 854\n",
      "DID NOT TRAIN..., replay memory = 855\n",
      "DID NOT TRAIN..., replay memory = 856\n",
      "DID NOT TRAIN..., replay memory = 857\n",
      "DID NOT TRAIN..., replay memory = 858\n",
      "DID NOT TRAIN..., replay memory = 859\n",
      "DID NOT TRAIN..., replay memory = 860\n",
      "DID NOT TRAIN..., replay memory = 861\n",
      "DID NOT TRAIN..., replay memory = 862\n",
      "DID NOT TRAIN..., replay memory = 863\n",
      "DID NOT TRAIN..., replay memory = 864\n",
      "DID NOT TRAIN..., replay memory = 865\n",
      "DID NOT TRAIN..., replay memory = 866\n",
      "DID NOT TRAIN..., replay memory = 867\n",
      "DID NOT TRAIN..., replay memory = 868\n",
      "DID NOT TRAIN..., replay memory = 869\n",
      "DID NOT TRAIN..., replay memory = 870\n",
      "DID NOT TRAIN..., replay memory = 871\n",
      "DID NOT TRAIN..., replay memory = 872\n",
      "DID NOT TRAIN..., replay memory = 873\n",
      "DID NOT TRAIN..., replay memory = 874\n",
      "DID NOT TRAIN..., replay memory = 875\n",
      "DID NOT TRAIN..., replay memory = 876\n",
      "DID NOT TRAIN..., replay memory = 877\n",
      "DID NOT TRAIN..., replay memory = 878\n",
      "DID NOT TRAIN..., replay memory = 879\n",
      "DID NOT TRAIN..., replay memory = 880\n",
      "DID NOT TRAIN..., replay memory = 881\n",
      "DID NOT TRAIN..., replay memory = 882\n",
      "DID NOT TRAIN..., replay memory = 883\n",
      "DID NOT TRAIN..., replay memory = 884\n",
      "DID NOT TRAIN..., replay memory = 885\n",
      "DID NOT TRAIN..., replay memory = 886\n",
      "DID NOT TRAIN..., replay memory = 887\n",
      "DID NOT TRAIN..., replay memory = 888\n",
      "DID NOT TRAIN..., replay memory = 889\n",
      "DID NOT TRAIN..., replay memory = 890\n",
      "DID NOT TRAIN..., replay memory = 891\n",
      "DID NOT TRAIN..., replay memory = 892\n",
      "DID NOT TRAIN..., replay memory = 893\n",
      "DID NOT TRAIN..., replay memory = 894\n",
      "DID NOT TRAIN..., replay memory = 895\n",
      "DID NOT TRAIN..., replay memory = 896\n",
      "DID NOT TRAIN..., replay memory = 897\n",
      "DID NOT TRAIN..., replay memory = 898\n",
      "DID NOT TRAIN..., replay memory = 899\n",
      "DID NOT TRAIN..., replay memory = 900\n",
      "DID NOT TRAIN..., replay memory = 901\n",
      "DID NOT TRAIN..., replay memory = 902\n",
      "DID NOT TRAIN..., replay memory = 903\n",
      "DID NOT TRAIN..., replay memory = 904\n",
      "DID NOT TRAIN..., replay memory = 905\n",
      "DID NOT TRAIN..., replay memory = 906\n",
      "DID NOT TRAIN..., replay memory = 907\n",
      "DID NOT TRAIN..., replay memory = 908\n",
      "DID NOT TRAIN..., replay memory = 909\n",
      "DID NOT TRAIN..., replay memory = 910\n",
      "DID NOT TRAIN..., replay memory = 911\n",
      "DID NOT TRAIN..., replay memory = 912\n",
      "DID NOT TRAIN..., replay memory = 913\n",
      "DID NOT TRAIN..., replay memory = 914\n",
      "DID NOT TRAIN..., replay memory = 915\n",
      "DID NOT TRAIN..., replay memory = 916\n",
      "DID NOT TRAIN..., replay memory = 917\n",
      "DID NOT TRAIN..., replay memory = 918\n",
      "DID NOT TRAIN..., replay memory = 919\n",
      "DID NOT TRAIN..., replay memory = 920\n",
      "DID NOT TRAIN..., replay memory = 921\n",
      "DID NOT TRAIN..., replay memory = 922\n",
      "DID NOT TRAIN..., replay memory = 923\n",
      "DID NOT TRAIN..., replay memory = 924\n",
      "DID NOT TRAIN..., replay memory = 925\n",
      "DID NOT TRAIN..., replay memory = 926\n",
      "DID NOT TRAIN..., replay memory = 927\n",
      "DID NOT TRAIN..., replay memory = 928\n",
      "DID NOT TRAIN..., replay memory = 929\n",
      "DID NOT TRAIN..., replay memory = 930\n",
      "DID NOT TRAIN..., replay memory = 931\n",
      "DID NOT TRAIN..., replay memory = 932\n",
      "DID NOT TRAIN..., replay memory = 933\n",
      "DID NOT TRAIN..., replay memory = 934\n",
      "DID NOT TRAIN..., replay memory = 935\n",
      "DID NOT TRAIN..., replay memory = 936\n",
      "DID NOT TRAIN..., replay memory = 937\n",
      "DID NOT TRAIN..., replay memory = 938\n",
      "DID NOT TRAIN..., replay memory = 939\n",
      "DID NOT TRAIN..., replay memory = 940\n",
      "DID NOT TRAIN..., replay memory = 941\n",
      "DID NOT TRAIN..., replay memory = 942\n",
      "DID NOT TRAIN..., replay memory = 943\n",
      "DID NOT TRAIN..., replay memory = 944\n",
      "DID NOT TRAIN..., replay memory = 945\n",
      "DID NOT TRAIN..., replay memory = 946\n",
      "DID NOT TRAIN..., replay memory = 947\n",
      "DID NOT TRAIN..., replay memory = 948\n",
      "DID NOT TRAIN..., replay memory = 949\n",
      "DID NOT TRAIN..., replay memory = 950\n",
      "DID NOT TRAIN..., replay memory = 951\n",
      "DID NOT TRAIN..., replay memory = 952\n",
      "DID NOT TRAIN..., replay memory = 953\n",
      "DID NOT TRAIN..., replay memory = 954\n",
      "DID NOT TRAIN..., replay memory = 955\n",
      "DID NOT TRAIN..., replay memory = 956\n",
      "DID NOT TRAIN..., replay memory = 957\n",
      "DID NOT TRAIN..., replay memory = 958\n",
      "DID NOT TRAIN..., replay memory = 959\n",
      "DID NOT TRAIN..., replay memory = 960\n",
      "DID NOT TRAIN..., replay memory = 961\n",
      "DID NOT TRAIN..., replay memory = 962\n",
      "DID NOT TRAIN..., replay memory = 963\n",
      "DID NOT TRAIN..., replay memory = 964\n",
      "DID NOT TRAIN..., replay memory = 965\n",
      "DID NOT TRAIN..., replay memory = 966\n",
      "DID NOT TRAIN..., replay memory = 967\n",
      "DID NOT TRAIN..., replay memory = 968\n",
      "DID NOT TRAIN..., replay memory = 969\n",
      "DID NOT TRAIN..., replay memory = 970\n",
      "DID NOT TRAIN..., replay memory = 971\n",
      "DID NOT TRAIN..., replay memory = 972\n",
      "DID NOT TRAIN..., replay memory = 973\n",
      "DID NOT TRAIN..., replay memory = 974\n",
      "DID NOT TRAIN..., replay memory = 975\n",
      "DID NOT TRAIN..., replay memory = 976\n",
      "DID NOT TRAIN..., replay memory = 977\n",
      "DID NOT TRAIN..., replay memory = 978\n",
      "DID NOT TRAIN..., replay memory = 979\n",
      "DID NOT TRAIN..., replay memory = 980\n",
      "DID NOT TRAIN..., replay memory = 981\n",
      "DID NOT TRAIN..., replay memory = 982\n",
      "DID NOT TRAIN..., replay memory = 983\n",
      "DID NOT TRAIN..., replay memory = 984\n",
      "DID NOT TRAIN..., replay memory = 985\n",
      "DID NOT TRAIN..., replay memory = 986\n",
      "DID NOT TRAIN..., replay memory = 987\n",
      "DID NOT TRAIN..., replay memory = 988\n",
      "DID NOT TRAIN..., replay memory = 989\n",
      "DID NOT TRAIN..., replay memory = 990\n",
      "DID NOT TRAIN..., replay memory = 991\n",
      "DID NOT TRAIN..., replay memory = 992\n",
      "DID NOT TRAIN..., replay memory = 993\n",
      "DID NOT TRAIN..., replay memory = 994\n",
      "DID NOT TRAIN..., replay memory = 995\n",
      "DID NOT TRAIN..., replay memory = 996\n",
      "DID NOT TRAIN..., replay memory = 997\n",
      "DID NOT TRAIN..., replay memory = 998\n",
      "DID NOT TRAIN..., replay memory = 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Viewer.__del__ at 0x000002688BBD8280>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\p2300575\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 165, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\p2300575\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 83, in close\n",
      "    self.window.close()\n",
      "  File \"C:\\Users\\p2300575\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 299, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"C:\\Users\\p2300575\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\_weakrefset.py\", line 114, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: <weakref at 0x000002688E546B80; to 'Win32Window' at 0x000002688C291AC0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! | Return: -251.6355947287577 | average reward: -1.2581779736437886\n",
      "Episode 5\n",
      "Finished! | Return: -242.8397495817667 | average reward: -1.2141987479088336\n",
      "Episode 6\n",
      "Finished! | Return: -688.6334400539816 | average reward: -3.443167200269908\n",
      "Episode 7\n",
      "Finished! | Return: -379.90035175854524 | average reward: -1.8995017587927263\n",
      "Episode 8\n",
      "Finished! | Return: -509.25548458548974 | average reward: -2.5462774229274485\n",
      "Episode 9\n",
      "Finished! | Return: -411.50021250303365 | average reward: -2.0575010625151684\n",
      "Test Rewards: [[-1.360768241254011, -1.7415987850831296, -2.3566990197385067, -3.2500898631799107, -4.470329119151151, -6.182376926245459, -8.17005018074026, -10.467504650263818, -12.953810076494284, -14.296959329260256, -12.254352702534051, -10.171335742191852, -8.16249689120849, -6.343837534957548, -4.794320457872284, -3.5417059399638964, -2.573669091991831, -1.94376755214045, -1.4692055187619308, -1.1187631679480805, -0.8657781289534399, -0.6913462301772781, -0.3910182214566206, -0.20204329552911224, -0.1326887605085683, -0.12201898179611648, -0.11974631083929539, -0.05766071751580161, -0.034588957790938214, -0.019800778102220112, -0.010744145105802662, -0.005837398196318389, -0.006626705398656948, -0.00731460015678259, -0.0036115282333852032, -0.0027736114717550786, -0.004184578529704622, -0.0068441830432680465, -0.00275197183198784, -0.0024925839326281093, -0.0024329615155001478, -0.005638345182852136, -0.008254178741315564, -0.005162251593806795, -0.011475632919586037, -0.007472824135720476, -0.0050213332802820495, -0.003554807152650636, -0.0026993847276082067, -0.0022114226404997134, -0.0019363156355480188, -0.001782048184017475, -0.0017033655766886964, -0.002733835448161396, -0.003134247179898473, -0.008027290397779788, -0.008535597963480447, -0.009496214335782974, -0.010883098626459971, -0.015164355166840357, -0.009380851568554538, -0.013110875918788957, -0.015470806535746123, -0.01855368461928318, -0.022649487729805094, -0.028172130908165286, -0.03627354474827966, -0.04280763120220355, -0.039761565144115676, -0.04122281217377084, -0.042555112155454274, -0.04235989826509745, -0.04973135295567029, -0.05236574028349591, -0.05677093308607128, -0.1028237949631596, -0.1038347963469468, -0.10679019951909696, -0.10651866312708566, -0.13824376066780716, -0.23371731009001873, -0.2662547480640943, -0.30883740993965697, -0.3595033437930612, -0.536264959540275, -0.8078853911846134, -1.2103636512433784, -1.7963834532313856, -2.338358425128658, -3.498996335537684, -4.937976906130015, -6.799513696194211, -9.086750357010892, -11.723826124665438, -14.550692757415282, -14.98360341915606, -12.695745846540875, -10.380530857917174, -8.046038776933557, -6.020518138565573, -4.3179159574584345, -2.9669637900064605, -2.0225829294904787, -1.5372911581702298, -0.9357097514819145, -0.5721369068623763, -0.4491290774460022, -0.3594957807952707, -0.29626929041857664, -0.25565984060222036, -0.13449381554480022, -0.12868329880846058, -0.08344080808912695, -0.053451241237502264, -0.043781718541050424, -0.0477142765444362, -0.01701177521822664, -0.01250519494467152, -0.009990268736675002, -0.008813387423509515, -0.008486216608365356, -0.015244616213340759, -0.017296677485471736, -0.020950983735250624, -0.02135955773781125, -0.026691925859098777, -0.037034909270399596, -0.09049620853631199, -0.08074986956234549, -0.07619341320997289, -0.07152849131768087, -0.08297241941126601, -0.0830898025719881, -0.08301457935713798, -0.08082006712083939, -0.08028008108137333, -0.07903488489811003, -0.07597522147609652, -0.0737973314500138, -0.07225193156313077, -0.07124552766495766, -0.07071830691257266, -0.0706386044409801, -0.07211994212897128, -0.07025546520410154, -0.06973940989901174, -0.06962478963706722, -0.06990368382944104, -0.07170940348542665, -0.07002745680896967, -0.06981324564013068, -0.07000169613715584, -0.0695608393392294, -0.09121017279803559, -0.09241843710582275, -0.09325924147017813, -0.0932682207962404, -0.09222432381715721, -0.08866874971729335, -0.08538733663994667, -0.08053942054572864, -0.07598054245800276, -0.07227553842478168, -0.0692028962525025, -0.06659239101314797, -0.06431048828610085, -0.06224992502434683, -0.05904230723120423, -0.06089404912410802, -0.061356727638714866, -0.0645997603301337, -0.068105814649159, -0.06732824984300992, -0.06982125522422118, -0.06849933121839188, -0.06887613671974925, -0.06924225204465413, -0.09255596113371292, -0.12271750775711912, -0.12934258669521756, -0.13708259604150738, -0.14538967855241375, -0.1540042575710977, -0.16261035990694434, -0.2576517876041052, -0.34783701106792225, -0.5310155588783606, -0.8928336734399156, -1.3354502169031008, -1.9713381489851207, -2.867804390116661, -4.10067724113513, -5.740376609478955, -7.825888674557174, -10.33037097213238, -13.13626272354607, -16.04906852559798, -14.087196423420211, -11.74668615546093, -9.322247246501346], [-1.9558669478109305, -2.158919570309032, -2.617451617306003, -3.2036494572223253, -4.163084285970251, -5.443111141722507, -7.045000621323353, -8.933843566944462, -11.029508567569438, -13.21469815593425, -12.262293047101279, -10.43633406886217, -8.708001052885693, -7.147404672260077, -5.7176398286625645, -4.430976694843481, -3.375099610925535, -2.5733642096604576, -1.9500350680214624, -1.4751922494274559, -1.1184989371695253, -0.8538747630516355, -0.5270049012452283, -0.420485076212908, -0.3405364094181622, -0.27992824709348374, -0.23339850626179265, -0.19698428778672336, -0.16807878560038778, -0.14482975688181374, -0.12526625200595282, -0.10726090788841719, -0.09694005093518801, -0.0909167831988293, -0.0894150323708151, -0.08378827137801619, -0.05467279297473118, -0.038127035240514466, -0.010139599451141748, -0.005112399975763005, -0.0021632267890268654, -0.0007304520694743229, -0.0005502438371031079, -0.0005199343556512703, -0.000784306622834905, -0.0005570354969248461, -0.0006520267814001722, -0.000635213145193661, -0.0005286555013661245, -0.0007652129212251367, -0.0004392804296202019, -0.00036854207125729154, -0.00037100992754601336, -0.0005407827898001548, -0.00037536812428306827, -0.0003829126187437344, -0.0005000253465322531, -0.0003427327567090447, -0.0006295210097287118, -0.0002731875577632472, -0.00043169522749241033, -0.0002877052934896608, -0.0024842839687243034, -0.004551588037160811, -0.003216359003789838, -0.0024366347468183437, -0.0019902242926749815, -0.001738803146632361, -0.0016043050327068833, -0.0015555942491726142, -0.0022374472373685324, -0.0020780743641838103, -0.0019834708326488216, -0.0019306283746944426, -0.0027415307270559222, -0.0026476538627221305, -0.002587867655020081, -0.0025327161981736008, -0.0033530555241184086, -0.0038013463376084062, -0.0029208546550884224, -0.006625387196466283, -0.0023086755830144605, -0.0021047823835669433, -0.002028092514513982, -0.0019863568318045557, -0.00260321678454501, -0.0025102292308272784, -0.002445792591268795, -0.005900313365902297, -0.00824041511592682, -0.003948329363115133, -0.0015440819979003365, -0.0005735301872543228, -0.0008678707360833646, -0.0006336561457610587, -0.0006932573477936854, -0.0007678948131885303, -0.0006193772648822667, -0.0007688590104548026, -0.0006152463661286331, -0.0005637404063181185, -0.0009032664905524058, -0.0006521969709376413, -0.0006905409231483621, -0.000822981419241181, -0.0006525774423016099, -0.0007666410327797743, -0.0006984555619495585, -0.0006059395871169902, -0.000825231317037016, -0.0005119666662791212, -0.0005438276767676938, -0.0006640974755010296, -0.0004987634756600723, -0.0006822286314623275, -0.0004729126306963946, -0.0004717598461167675, -0.0010303663619431495, -0.0035981978687626114, -0.002769269489685686, -0.0022996130610550294, -0.0020361988331757297, -0.001886972036186288, -0.004251315380132837, -0.00564921169351501, -0.002444284544473843, -0.0008787585399568734, -0.0006658480743238751, -0.000628309537218407, -0.0009586397585550782, -0.0007176184877631835, -0.0007438143319783647, -0.0009194991771235182, -0.0007357306023551206, -0.0008086622481892122, -0.0008498526244470844, -0.0007118792206637404, -0.0008393642846453117, -0.0007274441941540102, -0.0006476807217516184, -0.0011097982767859782, -0.0008320854167525298, -0.0007971069758482053, -0.0011838554912659387, -0.0009464708479165274, -0.0009171936113302396, -0.0013215753105992553, -0.0016099813993750848, -0.0015240733057550883, -0.0008233541654699185, -0.0009102916080575773, -0.0009029457668413864, -0.000779528759446576, -0.0009010897929533654, -0.0007941430310523098, -0.0007071605396863833, -0.001958539220622821, -0.0046079475446412525, -0.0021692263279008903, -0.0007965050411844283, -0.003718923359732966, -0.007281884655744687, -0.005142407501422899, -0.005299323973046527, -0.001059900555842268, -0.0036171986920226894, -0.009611823821879601, -0.032118830752479635, -0.01880969103215986, -0.011944504464576653, -0.010004056030510668, -0.010449003020563475, -0.0060010583896657225, -0.007422320914447748, -0.0070357944622656534, -0.003952265252208869, -0.0060814627720376276, -0.005451462061004524, -0.002824657849169087, -0.002551352786884268, -0.002494440657457222, -0.0024374239622286437, -0.004458826899965152, -0.014880315986755172, -0.008299691710927462, -0.005293470801194892, -0.006908454490959462, -0.006523947756694686, -0.0035436233580234543, -0.005605152573472924, -0.005263703444829528, -0.0025410043198537883, -0.0019928735544348913, -0.001935317670151128, -0.001925641881921503, -0.0021313525284514983, -0.0020244227381936352, -0.001960559964397411, -0.00193969715048737], [-0.05444463702165406, -0.049489161283083644, -0.039969391054964984, -0.03350441157877812, -0.03249313382718598, -0.04192331200080938, -0.04396771175095779, -0.04631689518897762, -0.04877139562428447, -0.05122777979212314, -0.05364581828854217, -0.056027536872753234, -0.05840439886373127, -0.060830182421605525, -0.0633780326502061, -0.06726083136124797, -0.06667448069928143, -0.06954952281192438, -0.06702744187314161, -0.07927179845354092, -0.07566513056221968, -0.08428874058445, -0.08163556797793584, -0.08595784553187119, -0.08348680988067206, -0.08223013246872185, -0.0803175077285987, -0.07664863942201992, -0.07358306398258642, -0.07117526265295207, -0.06928422452503916, -0.06780461540174076, -0.06665766217992944, -0.0657846703151736, -0.06514242312116834, -0.06469994219184433, -0.06443625106793992, -0.06433890055571201, -0.064403099014189, -0.06463135551535254, -0.06503359640346014, -0.06562776318368861, -0.06644094789832333, -0.06751117734933268, -0.07001002678150209, -0.07047808508855256, -0.06732921868585251, -0.06553851422933588, -0.06399514644267894, -0.06262777771705198, -0.061377076461864744, -0.060192167024313854, -0.05902800061055545, -0.05656344018257722, -0.06151761888666411, -0.10187395285209154, -0.10379044642651121, -0.10697392482510729, -0.11040896533306681, -0.11346022653402715, -0.11573675212217095, -0.1170042628369335, -0.11713063345649558, -0.11605535682854817, -0.11377787111944815, -0.10892284481824795, -0.10427963765264693, -0.09968128085576518, -0.09501133992295495, -0.09018795198023453, -0.08261582436918545, -0.08077231084078663, -0.08001955539044045, -0.07856325570502586, -0.07530054163540732, -0.07277586297032916, -0.07084724904078353, -0.06940250683086199, -0.06836076555535288, -0.06766543470883356, -0.06727943253988339, -0.06718212386948268, -0.06736761012393568, -0.06784417142347528, -0.06863479103870096, -0.0708988135756258, -0.07043924378158298, -0.10113375723687688, -0.10383052756921063, -0.1068281005312355, -0.10648020773232392, -0.15738771036813126, -0.17113322292281682, -0.18991659517300635, -0.20982077867047197, -0.23315144496587203, -0.2609158302755261, -0.2908489316882106, -0.4156133648332287, -0.6176673200588054, -0.8977487260540682, -1.3390504955751108, -1.975488622204849, -2.8720721960063926, -4.101587290291142, -5.734278622840344, -7.300407886454709, -9.63070658264085, -12.257900360683402, -15.013402715104602, -14.061421014342685, -11.816500299637873, -9.393561313303332, -7.361079200587871, -5.594918380672545, -4.04621794850581, -2.770197838462448, -1.8838904538947792, -1.4242650364582168, -0.9218676091625903, -0.7102172487372406, -0.557692627872426, -0.45315036391568686, -0.24172427200371577, -0.20866501630889167, -0.13621639694832918, -0.1365861813024239, -0.06312884306968213, -0.039380350266921424, -0.02386428330564693, -0.013886884854359405, -0.007912639581464272, -0.014431647114169893, -0.009679789001808232, -0.00679217177397456, -0.005102227288917948, -0.00416758968430474, -0.003696178797573437, -0.007248108932453662, -0.023984884253041603, -0.026716203852177222, -0.03423566008434414, -0.024028545763710874, -0.03160428153608412, -0.02980743113116113, -0.038859906116656774, -0.04021873470670917, -0.041936049721254906, -0.04372962582302202, -0.045430606603438166, -0.04694201178005112, -0.04821130478854919, -0.049212353699440124, -0.04993366441678208, -0.04909081223676768, -0.054876930495297675, -0.057337398245648596, -0.05983065365805682, -0.062423285898582676, -0.06632291176826881, -0.06571462227301467, -0.06918229985835814, -0.06670893482349387, -0.06659791608683763, -0.06674413577912329, -0.06715391244036222, -0.06784659330851667, -0.06885590495421577, -0.07135242160682756, -0.07007162599078488, -0.06944203203272122, -0.09005140763538365, -0.09108226928497833, -0.09169323696087998, -0.09144966798228454, -0.08872342634006247, -0.08694081493703638, -0.08460304200367139, -0.08059341116430532, -0.07725780947824046, -0.07477142503891675, -0.07297605564050313, -0.07176140280243684, -0.07105457384157378, -0.07081328045932703, -0.07102189996262373, -0.07273816204784349, -0.0712190034334649, -0.07116422561061897, -0.07269550091410823, -0.07087243215765657, -0.0704456452076717, -0.07045256803157615, -0.07201160192369717, -0.07019065425338848, -0.0697458156783188, -0.06970204026186134, -0.07005521950999044, -0.07194268930799601, -0.06891845328435217], [-0.02176297327763757, -0.011899204112493423, -0.006021612558479469, -0.00307981388120565, -0.002556727031332847, -0.004388300869166269, -0.0045209873610454485, -0.004725569784329896, -0.004961974913892481, -0.005206645010185667, -0.005446752968961863, -0.00567639768726108, -0.005894133085735599, -0.006101397252845629, -0.006301553151552516, -0.00649935159192188, -0.009758198646700512, -0.011256709611245311, -0.013156175176696884, -0.015596708060578864, -0.018784891060646697, -0.022951058299341263, -0.029734321608196404, -0.040369208082095584, -0.03640237036617797, -0.03616429258624885, -0.04509188836952717, -0.047642929225890966, -0.050329995806620675, -0.055026963252932846, -0.10326461867793192, -0.10379316688170714, -0.10656521293100346, -0.11022553683772823, -0.11392066823837807, -0.11712068609671926, -0.11950210498892017, -0.12087207247118134, -0.12112104639708514, -0.11751510545091527, -0.14953289571879821, -0.15617593476678107, -0.21812824329788544, -0.24676043965956682, -0.28181404211193156, -0.32125622126970754, -0.46688692902852935, -0.6986419991243874, -1.0506274624415226, -1.3635914075129494, -2.0062812134642782, -2.911421958000882, -4.151860333563812, -5.462797909858749, -7.424886831111639, -9.779104413909197, -12.42348268604402, -15.18606422072155, -13.793459657205538, -11.554293387959762, -9.364889217272966, -7.333094153615938, -5.451982128504385, -3.9392400945276647, -2.695137229237023, -1.8665335727189936, -1.411047620506809, -1.074764601176872, -0.8331543129638925, -0.47894305817299887, -0.38610899382415886, -0.3254581248124264, -0.1649862861336142, -0.1504328755662369, -0.0962093726040782, -0.060275934612745455, -0.03666050996114841, -0.021341158146365315, -0.011649523926330627, -0.005865888439928875, -0.005381046275100576, -0.009552446600408625, -0.0033051330006285016, -0.005773806809933091, -0.007037483677960493, -0.006271811447220559, -0.002781943600352435, -0.0010403617991801774, -0.0007277921255679195, -0.0007139852599638494, -0.0010048433454147073, -0.0007840331491068199, -0.0008085506380086877, -0.0009987643393921046, -0.0008134419712780736, -0.0008620505109099344, -0.0009783117154546315, -0.000816400298726453, -0.0008868107765529335, -0.0009329083422931316, -0.0007925743480961837, -0.0008919789655022258, -0.0008494622293186652, -0.0007387594860293193, -0.0008875656712426221, -0.000711764162867492, -0.0006553423148511497, -0.0012496008760701912, -0.0007287237870575493, -0.000916121754333127, -0.0006408354933590231, -0.0006293307523237708, -0.0008866137674423753, -0.0006697442342482524, -0.0007327561651347741, -0.0008007962302390974, -0.0006541968950222108, -0.0007926260714923184, -0.0006610098073154065, -0.004377657690880762, -0.012568254909640721, -0.00021800813660452284, -0.00037177250989567216, -0.0002058248608181152, -0.000647375640249157, -0.00016866199871654272, -0.0009806969039686966, -0.003424716518898092, -0.0020302320010588794, -0.0012187946784450224, -0.0007961141256257972, -0.0006670355464617119, -0.001286247364960681, -0.0009703427442947551, -0.0008776115828380792, -0.0015096875028544408, -0.0012347934085973906, -0.002731612122936862, -0.006576057487959719, -0.006293847264800116, -0.006448928116690139, -0.006913677754379627, -0.007621345797337607, -0.008550794597545371, -0.009718478126593844, -0.011176256447259185, -0.013014529508212264, -0.015370972360941123, -0.021063979132845738, -0.05415665194222484, -0.04141792868390439, -0.037471082038558264, -0.03869897600658229, -0.03873285053082299, -0.04617407692937604, -0.04861006329937155, -0.0510454952246993, -0.0549339054784595, -0.05280636072423927, -0.053386257983646324, -0.053757440932273366, -0.05392491916924907, -0.053890545591985334, -0.05237245559561874, -0.05690464585141216, -0.0589586578523709, -0.06104652727032026, -0.0632358334804791, -0.06560871029090028, -0.06938515839135571, -0.0699276881374698, -0.06861019555862906, -0.06899683310671122, -0.06974894473277603, -0.07202490905272359, -0.07062972142889822, -0.07092205923250593, -0.07278933334536702, -0.07116837950265842, -0.0710901746046223, -0.07259452148631836, -0.07105514794455399, -0.09628029482323633, -0.098267281618644, -0.09650533576040707, -0.1377847372657362, -0.14751010933208478, -0.15857927822894144, -0.17077998549737033, -0.18418132872677678, -0.1990821743992151, -0.21599505374375186, -0.23566018475724745, -0.25908848497518544, -0.28763605774665174, -0.3192760121032419, -0.44332468668019537, -0.6517192441522321, -0.9724836380618287, -1.4440355028410876], [-0.8015353172751796, -0.7546528752063871, -0.7745891229632333, -0.8306576096154461, -1.0367264798082423, -1.4107724775910164, -1.9907369807714124, -2.8277871817369995, -3.980312178927804, -5.500911032110571, -7.414690832627548, -9.692674355655598, -12.23400123546386, -14.877210119179107, -13.465089925207877, -11.298283944357607, -9.156834328107847, -7.172988907828723, -5.4514125703642655, -4.015647618366133, -2.7516187687764884, -1.9074709797103475, -1.4417754209234541, -1.0960644720660324, -0.706308106101467, -0.5530654036329804, -0.44672695556398256, -0.23866972340928078, -0.2052295623153088, -0.18576209382710554, -0.16626075074980082, -0.1617058387918304, -0.0788141430403586, -0.03774626958096784, -0.011940304604221158, -0.008750297391860338, -0.006962142483943746, -0.006894974536220124, -0.003582863448787906, -0.009656250457442287, -0.010413090789537444, -0.02021052683264473, -0.02405389553636749, -0.03216364928439433, -0.023834329800606353, -0.02976674065663714, -0.04029286677473797, -0.03652606778524992, -0.03751675288737098, -0.037373648935046064, -0.04505812440245277, -0.04729434359402013, -0.049489509307339315, -0.05158761940259754, -0.05357310482331368, -0.055456490181552784, -0.0572655505540133, -0.059040240697865176, -0.06083029103877952, -0.0626947994982554, -0.06470346789132712, -0.06805938585225421, -0.06719306358915154, -0.06855473451186461, -0.07131296235547681, -0.11129928030926323, -0.11549682870910968, -0.11809966220861434, -0.13911936616232864, -0.14447870503867796, -0.21039021954074408, -0.2375096779496018, -0.27090510666456424, -0.3121194832857639, -0.35971945780259823, -0.5232483893209723, -0.7813338028209503, -1.1680022883319807, -1.7303966376190216, -2.529251871110985, -3.6356704380068354, -5.120569691530144, -7.033274836495879, -9.37017676751102, -12.045780683085388, -14.89161553283547, -14.783797008677984, -12.479393844856554, -10.162088209156005, -7.843454732490534, -5.850019420780339, -4.037602509445342, -2.762099799895862, -1.87680037528126, -1.4220716285897046, -1.090039801645671, -0.8553203196975331, -0.5151774148058992, -0.2795106628248414, -0.2411121060634566, -0.11871177658351428, -0.08437190495150593, -0.08329688905315258, -0.05129916560915781, -0.030451210794962043, -0.017206722391897137, -0.009274173244578495, -0.005268809629039805, -0.0066477109092695046, -0.017518635243948946, -0.008649006152542098, -0.015602305085080363, -0.01208350430120314, -0.012625345625546316, -0.01541449073622992, -0.00818259127040254, -0.004580256364192601, -0.006384501740758184, -0.006004409090503752, -0.005806784891440823, -0.002649304687419049, -0.0015670434497474315, -0.0015933211013384318, -0.0016869049205382634, -0.0015610610373028766, -0.0013792474637821285, -0.001434915658797599, -0.0014827403516547216, -0.0014957866498756642, -0.0013739220640150004, -0.0013666772338637515, -0.0017295838408108942, -0.0015607042864120245, -0.0014909345342979548, -0.001521004968097964, -0.0016204552437408372, -0.001489845859178654, -0.001609518524917594, -0.0018049050344423317, -0.0011217156260437487, -0.001143999016490638, -0.0013592902253098773, -0.001188866326385949, -0.0011683397418943752, -0.0015914337323714588, -0.0013930826079473699, -0.0013206942542005136, -0.0013751181006520935, -0.0013944710811436083, -0.0012680964063717175, -0.0011813226604686824, -0.0012516284324737186, -0.0012092868680062356, -0.0010924223495172648, -0.0011412872176031013, -0.0012411547577245896, -0.0010920798856403093, -0.0011089558200251732, -0.0013490805600552488, -0.0011717740209430982, -0.0011483622073290023, -0.0015825294389879025, -0.0013802760501386863, -0.0013066251077119232, -0.001362010627957765, -0.0013810722423012027, -0.001254349329251465, -0.0012927351757200949, -0.0016189270413319576, -0.001431405961462634, -0.001362307952581214, -0.0014135748196242213, -0.0014352375836341174, -0.002451659711765891, -0.008405398997984103, -0.0046795188802580155, -0.013329851830029167, -0.006861083587734684, -0.004568834823327443, -0.0031267564927704343, -0.0030372670306183123, -0.006061928156524781, -0.004362102395233857, -0.0025139164118878473, -0.00537781682220937, -0.004085703075729898, -0.002040578261209364, -0.00204164670665024, -0.0019471739388020968, -0.0018972843632992563, -0.0026568569449322366, -0.0025552536467437314, -0.002489266264751244, -0.0024313778060530288, -0.0023772543889929057, -0.00543416615000049, -0.004090034073456751, -0.0051827427329362635, -0.0021945024175869837, -0.001730936927271295], [-0.0502026874048398, -0.04992672699185241, -0.06400462751437284, -0.0622533093655096, -0.05820809788894467, -0.057690263385168625, -0.05708991012550259, -0.05638895030717292, -0.0555674043740427, -0.05380349144660728, -0.0542982881084691, -0.05575593171911425, -0.05343365599667656, -0.05563883551337199, -0.08568194273712036, -0.08543913251484651, -0.08587603026186982, -0.08609709678671683, -0.08415998329892907, -0.08178981997494196, -0.08899111523586066, -0.13605094233093293, -0.14542996430688537, -0.1565251605553132, -0.1689880498529985, -0.18280618365145757, -0.19823473146192536, -0.21576989303212324, -0.23615692734837615, -0.2604305198684695, -0.2899893221058364, -0.3267102210951312, -0.3731114246863943, -0.42916323375018284, -0.623968554778717, -0.9213135241268091, -1.4005026408237156, -2.111087580582712, -3.1159406706332144, -4.071793325369044, -5.746319779631978, -8.003945581889077, -10.593886276656196, -13.486653959759856, -16.0924383999387, -13.497269132898591, -11.055467066884372, -8.717582300054767, -6.628060560398914, -4.879385106430427, -3.4979045975480534, -2.353125477391477, -1.7767023362576913, -1.346117374016297, -1.0313383204498634, -0.8078362394473814, -0.4831291552020808, -0.26091329245276845, -0.21951436823065573, -0.13952001557871027, -0.10388205419411779, -0.10621147797726302, -0.03909973036256489, -0.02259417920167979, -0.013427233519196034, -0.012130734692256593, -0.012286855894254177, -0.0075842443200738385, -0.009934871986805364, -0.02380988190596148, -0.021217088232083115, -0.016968466576953556, -0.013406992791919946, -0.01480560286961623, -0.02439049211718321, -0.023971583346922506, -0.021388627069955018, -0.018415030851534026, -0.017120117909610856, -0.019009919835200253, -0.01720705276593299, -0.01477354761528146, -0.012844324208507483, -0.014176323080965735, -0.012719623038577052, -0.01085233948519346, -0.00936329447859015, -0.008633644983265855, -0.009307250161812039, -0.007957210844447242, -0.006086061269616084, -0.008984127287237935, -0.007582913107057566, -0.008226327262842247, -0.007167199133584839, -0.005384745234081408, -0.012306666824824015, -0.03511620922938329, -0.03045605238489033, -0.02933215260225628, -0.02534270025245315, -0.023360856990433707, -0.023025673925643093, -0.024703804476190423, -0.031000650547955522, -0.013631414230763212, -0.015007580801634092, -0.02081646633007115, -0.008620279277064245, -0.01664418022511369, -0.01169879393499296, -0.011175987475585538, -0.016666109379391635, -0.012866278559736977, -0.012946792613131863, -0.014939429545884519, -0.017803171806014984, -0.015229935919190026, -0.015820633760925382, -0.018234496944173947, -0.020524321744150878, -0.007662089924065626, -0.014077278046314846, -0.009525222418089799, -0.01000478357306861, -0.012298508682020731, -0.0070934091918726135, -0.009404585239638002, -0.019417506827779974, -0.017312191294968415, -0.011822449306393803, -0.01245583850137863, -0.013458435465680202, -0.014920077622538426, -0.018257129079677546, -0.016050740845837692, -0.01772576279767381, -0.018032115252479202, -0.018174509644535805, -0.018935010299882756, -0.019654527092748595, -0.02784688859747012, -0.027224502756769197, -0.026956888971613767, -0.0266965098535897, -0.026270519713721345, -0.025649623759068832, -0.023505016426233424, -0.02181545790530899, -0.021273459016186002, -0.02060120129261376, -0.021720849152773676, -0.031242434209332665, -0.031171588783165255, -0.03141436902247767, -0.03099114257675997, -0.04977756711587486, -0.051124313020987466, -0.05501435046307789, -0.05941865976587067, -0.06433839107246006, -0.06987798017218434, -0.07623733807570816, -0.0848382848015234, -0.08920269002525409, -0.09350327579652606, -0.0977003762842921, -0.10181550473519858, -0.10591318135099327, -0.11009113110775892, -0.11447665395725029, -0.11922794670895887, -0.12453991129622102, -0.13065463309350805, -0.13787734904126953, -0.14404730779239927, -0.18596167597208896, -0.21382037169997004, -0.24915340871678887, -0.29472101876029494, -0.35432181033326293, -0.43316842810095235, -0.5383862454580919, -0.6796503830414421, -0.8699546732213587, -1.1264550553326607, -1.4713922294963906, -2.2616665653897594, -3.2241932559672932, -4.237468515451183, -5.498386131509619, -7.320719218372365, -9.649176006939982, -11.687434852856764, -14.30574449005804, -13.385766260480253, -11.350227215322894, -9.310373813821231, -7.390392613041679, -5.697304551777293], [-7.398475736591255, -7.378208691057023, -7.4814909662522, -7.592641888835978, -7.716431065223454, -7.848395855953996, -7.983758171561654, -8.117610836811156, -8.245111156503036, -8.361670647011447, -8.460609976910206, -8.624388275615994, -8.947857086458143, -9.408215884322805, -9.98653107182365, -9.770331719744183, -9.357787711715295, -8.903587715431808, -8.421437936842837, -7.9056130601295385, -7.41924281209082, -6.925798095454363, -6.566302673425516, -6.277857892367675, -6.253229260165003, -6.497336020655444, -7.002779250147695, -7.633853152770842, -8.535062323679314, -9.620876878390723, -10.881357538990974, -10.119987944862505, -9.147610896252667, -8.150647205276316, -7.165907261188879, -6.231457825759551, -5.38154902927062, -4.642596331489318, -4.030079013774207, -3.5160134091915762, -3.2889750048422113, -3.206270280311088, -3.383698803857849, -3.7000193508205017, -4.160283815930744, -4.731039677011094, -5.452738512674106, -6.500013977546107, -7.866641351873379, -9.44397637682054, -11.160717784032485, -11.452020159973863, -10.273320534399739, -9.030083969663126, -7.764982180556954, -6.376052477017536, -5.305039723493116, -4.356081781001421, -3.5479442946388597, -2.8842022900388895, -2.35591937889495, -1.862231308224451, -1.6880261544308086, -1.810530054301438, -2.2255518420828677, -2.961534014697649, -4.010229815840424, -5.1668944477963645, -6.859705199766763, -8.899301895397116, -11.206400926635217, -13.651034344626046, -12.963335355094117, -11.047214042538155, -9.123212756599813, -7.302074366210447, -5.787170888046977, -4.489282210867556, -3.4319799907259743, -2.4407548341092817, -1.7913734684678362, -1.3649410549333598, -1.0596413650536811, -0.8523052639575488, -0.5244907727697876, -0.29166463599693443, -0.14705303525683902, -0.06347035014547306, -0.07014443821484125, -0.024671831453764066, -0.014962707368326566, -0.013134787470643478, -0.011339085032841032, -0.009919383871921835, -0.008767383500216074, -0.007807199571373556, -0.007108476616232383, -0.006588942769403505, -0.005906042220051433, -0.006484955271862464, -0.0039271668445666355, -0.005805263954397454, -0.006280107614486337, -0.006862138214121619, -0.007548085269705269, -0.00835349228237689, -0.009311758705359288, -0.01047586998512109, -0.012265235232516563, -0.012220694457927235, -0.01379377764533738, -0.015884213036812096, -0.01996631775311955, -0.01762935010880754, -0.021105645901219945, -0.01913761287365282, -0.02241431344834644, -0.019808435892359876, -0.020555593070110397, -0.030959326715381624, -0.03101205348831299, -0.03171438987865109, -0.05968902657763746, -0.05890680816939259, -0.059464280856127566, -0.06045848748879174, -0.06020273243063617, -0.0643513554501559, -0.06381412900459883, -0.06687090121929262, -0.06579835005054555, -0.06581196276890898, -0.07116227627998123, -0.07173327041228006, -0.10814862254818856, -0.11992882612427343, -0.2224376153304778, -0.26431564835993976, -0.3206834479475156, -0.39653209138378503, -0.6832323757034342, -0.8809927759457862, -1.150113987983597, -1.5137342880196372, -2.000944198309445, -2.645855933603991, -3.482564883602389, -4.670161008441206, -6.154129987972427, -8.050941772726276, -10.086100367792216, -12.626583347799475, -14.329190920939926, -12.156208673105787, -10.24406544153053, -8.364658024969033, -6.624351639954429, -5.105674555053385, -3.8520098484626177, -2.9726496095253445, -2.1758919407102257, -1.5809652771482816, -1.1450460595055005, -0.8310544028831538, -0.6319938907449575, -0.4155766356680746, -0.27286375124833046, -0.18398538473694848, -0.14560890874176638, -0.1188287897363709, -0.1005606307518174, -0.08872605157648054, -0.08279039252677563, -0.07949509387197685, -0.07716225257091386, -0.07426210507594486, -0.08711550707550579, -0.08731530875119128, -0.0867072197829175, -0.08369753149552615, -0.08133566424312969, -0.07838777817745543, -0.07491004965200615, -0.07101895910173038, -0.0669312031409439, -0.06302460644176731, -0.059930473173774236, -0.05867301131184479, -0.06087915596776503, -0.06669342847551538, -0.0421399817478554, -0.02609067827100998, -0.01569195779748949, -0.009030068799709995, -0.004833668725039049, -0.0022733991085040774, -0.0008297088911461406, -0.00020944930256001812, -0.0002987420613753567, -0.0011449954396250232], [-4.004747443122836, -4.300501633387421, -4.954635130610029, -5.835616513345339, -7.078149893898034, -8.46205514842473, -10.203804724863618, -12.102300997426036, -11.216673615787093, -9.821877313196422, -8.39784400454226, -6.904812186420325, -5.660270589792268, -4.561393427569514, -3.6323360041535695, -2.876846211720996, -2.2840290676587722, -1.8336584581281878, -1.4575711916601632, -1.312430018318953, -1.2579930722898318, -1.2906107244749128, -1.4126826436633544, -1.6326980639937312, -1.964963907728203, -2.4268167195411015, -3.1265904363846957, -4.053401329949383, -5.2277007301877765, -6.650474374767273, -8.291437260248847, -10.083133305112074, -11.927322654500614, -12.70361189859525, -10.990297426933774, -9.474915304875049, -7.952558589118082, -6.503130916282954, -5.19642972795141, -4.076195364427848, -3.156572865948927, -2.4284177154338793, -1.867756389075352, -1.4134740547925062, -0.9519506194040761, -0.6328165991560301, -0.41535788488672293, -0.2696701343601691, -0.17468968122505532, -0.11622080075792464, -0.08534628497104084, -0.07972649078749602, -0.07865309581903579, -0.07687282513784174, -0.07201851555063243, -0.07988709834276767, -0.0792027059234796, -0.07635225113576416, -0.07191706461720956, -0.08155081485804927, -0.08110459418261859, -0.07847219438197836, -0.07693418670284946, -0.07230261609297572, -0.08120293024858602, -0.08067618680945715, -0.07683837442358168, -0.07612933545416685, -0.07613911662879878, -0.07942414760018078, -0.07535521134271313, -0.07370576042645635, -0.07266880443348551, -0.07330029409857201, -0.0720788402043126, -0.06771970193164974, -0.0765709052470827, -0.07577009087118215, -0.07293866659160284, -0.06858901655918577, -0.07772138302719717, -0.07700431619479473, -0.07421883767445452, -0.06981396558645214, -0.07673237947137078, -0.07314620596121815, -0.07370272121397364, -0.07341193834408774, -0.0897607282683829, -0.09051690920752785, -0.09057818759133676, -0.08966239200405539, -0.08515638928862203, -0.08263318419179694, -0.0823367698128887, -0.0807188900419225, -0.0771642762352759, -0.07381570046667185, -0.0753553976125001, -0.0795878002049073, -0.07561316254128574, -0.09831554633160668, -0.10054738726870088, -0.10243655848590112, -0.10351438731871536, -0.1035155005284591, -0.09877311247397007, -0.11991815357014446, -0.12460399670035971, -0.1287774124422355, -0.13223102107156112, -0.13484887492124237, -0.13656802435802878, -0.1373540546726697, -0.13389708118266228, -0.14424529173141334, -0.14773972794445714, -0.1506131400333436, -0.15288620988722856, -0.15458439701919244, -0.15573128975728492, -0.15634446760228332, -0.15643300748446057, -0.15599609697487976, -0.1550224602768628, -0.15349049797490225, -0.15136922118504786, -0.14862025454284752, -0.14520142230063451, -0.14107275714416057, -0.13620623573037696, -0.13060122506484867, -0.12286863256274295, -0.11616595542133198, -0.1277934390829518, -0.15556744093424932, -0.1678247714186936, -0.18138384264001853, -0.1964815240401584, -0.2135901832666228, -0.23342333008593627, -0.25697281782097253, -0.285579139071327, -0.3210400210056833, -0.3623083873483644, -0.46401115877702986, -0.5816484633558332, -0.8251429026397209, -1.1876709171355582, -1.7118349360157141, -2.599470792945586, -3.6673411316507005, -5.082482698294297, -6.884133990457363, -9.063522972380845, -11.340684145646879, -13.707153594499513, -14.127961254192652, -11.838747205515523, -9.654397518218174, -7.910796309258248, -6.303710454553943, -4.906923786444476, -3.5193679675760565, -2.4710760988242986, -1.8669780888527936, -1.4146182851926883, -0.9499915696258755, -0.741688344632906, -0.613928776714325, -0.3613634368779449, -0.18509313385436044, -0.10200498782262707, -0.0954492998410347, -0.06760288329795412, -0.027259684454310883, -0.01824964762819983, -0.015197899811919663, -0.012875784569762834, -0.011071349946624235, -0.009635514625903169, -0.00842059877946858, -0.007361297886259517, -0.00764832068592134, -0.00943481585558552, -0.006139006673425539, -0.006305163217985825, -0.00652607195232516, -0.006887332553931302, -0.00640235238076237, -0.006373340264729619, -0.008273478660955543, -0.0009711001111538942, -0.0013492276465588654, -0.002143790810687042, -0.0035978758937997147, -0.001660822200951367, -0.0036835001640476736, -0.0035366945773908985, -0.0005472570092810694], [-4.6741298790478, -4.599477645702595, -4.713481136973855, -5.119594969106773, -5.719121861133952, -6.59490647389754, -7.815352423115999, -9.288753649778482, -10.947630414711863, -11.402963079214347, -10.149733520733463, -8.849279881528846, -7.553359340116859, -6.318989369156314, -5.1966382794664625, -4.221058780339028, -3.4082782082356156, -2.758241608061791, -2.2603794334720373, -1.8994548812577339, -1.6602224577202134, -1.5305391724236423, -1.5031738031795547, -1.5767154627771391, -1.7539626668060089, -2.100621677903385, -2.626373127276009, -3.3568191163059735, -4.316686583035447, -5.520826295714727, -6.962808948361785, -8.604571966328525, -10.373237962790146, -12.170311028933432, -12.211838796240723, -10.746249545298834, -9.215891552049195, -7.693204838484085, -6.258739848506634, -4.978981442489676, -3.8923464769521288, -3.007931327454593, -2.3117282448099035, -1.7482650910376296, -1.3299010790144628, -0.8952756576589774, -0.5952364607278705, -0.3906444197061067, -0.25285462397247044, -0.16162224768981254, -0.10308974559340901, -0.06816603998033309, -0.05135961520142976, -0.05003558991769167, -0.06789108870027087, -0.06622959525537908, -0.06305266712482047, -0.0608452455133131, -0.07662646055659393, -0.07605444699006694, -0.07515898246013765, -0.07223514722491636, -0.06763384821602587, -0.07532824036295797, -0.07439532886761954, -0.07034311454166399, -0.0685699052886192, -0.0696937136089851, -0.06416459244408389, -0.06839858858044419, -0.06561707875529052, -0.06418971381515999, -0.060858573313283884, -0.07151047374184943, -0.07047213049129696, -0.06778419490142788, -0.06661099002082327, -0.06230765400398272, -0.0698347134285283, -0.06719237828214442, -0.06402938131885669, -0.07787425595789146, -0.07738992008917515, -0.07498879271508235, -0.07422323583742137, -0.07030351976851543, -0.0817764099787665, -0.07980697086698564, -0.08282779868679348, -0.08022612127817957, -0.07872940157438028, -0.07400812513375295, -0.07585121755069892, -0.0861952726470714, -0.12732767596094677, -0.13489292526033053, -0.14373748425991548, -0.15338407244024457, -0.1636531669241328, -0.17457965496044517, -0.18636599955619004, -0.19936255848772422, -0.214069925121811, -0.2271615015712383, -0.2980785266244903, -0.3403321810070598, -0.47415077851948007, -0.6816864364200632, -0.9894485983388256, -1.4371789372995973, -2.253688198892495, -3.2037198958911652, -4.285832633369292, -6.0294617488759314, -8.232226116959495, -10.852750987751534, -13.75770938188956, -15.845727108063423, -13.168010596890731, -10.974795556404295, -8.834308021118444, -6.888814721809287, -5.240234687472033, -3.6546666574781326, -2.3916562479854373, -1.5790049288355883, -1.2209245055213573, -0.7798811152290591, -0.4839204663934315, -0.2891440070728082, -0.16584560795920322, -0.15069630414167406, -0.12663488432548556, -0.11619254141017266, -0.06440520381781298, -0.030916720437683898, -0.03420775086711174, -0.021742868767076044, -0.014121368967145975, -0.009552318493712924, -0.006877165343809668, -0.005376813524956137, -0.004650751105837408, -0.004069732406343495, -0.0049160333181301145, -0.004541004039704966, -0.004321348369012983, -0.0059535633650598645, -0.00837948788267385, -0.016124305318120848, -0.012151018913245833, -0.029293971210967253, -0.04675802332174801, -0.10122489128415477, -0.08949387782911516, -0.11957826636133437, -0.1177049714158745, -0.12371481358217218, -0.13579317883086495, -0.15320021549591106, -0.1760558127756485, -0.20525451469667677, -0.24248986488122304, -0.2903818629034314, -0.3527123153323128, -0.4352762685308358, -0.7224712411869666, -0.9362992423053106, -1.2226797726151388, -1.8012406501591267, -2.623006258719621, -3.7572612367244673, -5.271141576489139, -7.207516831332272, -9.55420604673622, -12.217948847070433, -15.031028199700039, -14.005951891632735, -11.816211883255548, -9.629006925077576, -7.318477258572046, -5.366219911285703, -4.189704811040035, -2.891862538288374, -1.923163501680008, -1.4790629250165164, -1.099596061623614, -0.8011711910755207, -0.4964436274394938, -0.407197029847926, -0.32860972766884544, -0.2621753934789323, -0.2212564716717848, -0.18675484875569237, -0.15204417491701686, -0.14320618187670295, -0.13065915542386708, -0.12195559877011487, -0.11708727932563393, -0.1080816095585217], [-1.8833327842970584, -1.8177356699457996, -1.8670180186963485, -2.0340649750807978, -2.327266632566429, -2.7594991317607427, -3.345940614363309, -4.098451097063901, -5.133725763284355, -6.318627933821716, -7.746148785810349, -9.539177419719985, -11.472477339652087, -12.631739158490115, -11.20010022831989, -9.686151326120056, -8.155397159879154, -6.687973722265453, -5.356541885799704, -4.208846653290287, -3.259240235840467, -2.396913313028038, -1.8095835704947483, -1.3688600666421298, -1.0419985398736904, -0.6941113269624269, -0.45687391904955493, -0.2983601797648588, -0.19605193264349796, -0.13551638921607626, -0.11412982423681785, -0.10024264041219708, -0.0804776849685464, -0.08679426937572224, -0.08631481630908348, -0.08192937817431614, -0.10259344648672405, -0.10525205606449377, -0.10344970498094799, -0.1283794291798802, -0.22713098197711698, -0.25804793069852094, -0.29832624674123825, -0.345668288975239, -0.49605969738407524, -0.7463864664954395, -1.1197678705126692, -1.662611031294101, -2.437414898133478, -3.6900857912129066, -5.417882700337219, -7.606238182905994, -10.110144993335874, -12.951297477311277, -15.700462447594585, -14.395066879661433, -11.6755810062766, -9.666913428850473, -7.414708546091758, -5.499896768201034, -3.8120751703422076, -2.5173027831073114, -1.9030659591071584, -1.4467755757234597, -1.1177453765450043, -0.891255932071573, -0.5469387426967015, -0.30349849702552084, -0.15192471300537996, -0.14756193957357885, -0.16001933554753653, -0.07502816153485284, -0.0312619986139773, -0.01658983301770853, -0.007701707280094794, -0.002768160381025065, -0.001537960703911787, -0.005458487102382192, -0.0022921772717709125, -0.002682712609080044, -0.00477196262989088, -0.010175127509711052, -0.019703602115600957, -0.03638397823733459, -0.025022563819579534, -0.01946649130293328, -0.01125002055787592, -0.023853571202931915, -0.02229836537184524, -0.018813631392848088, -0.015996397047406744, -0.022028248233508223, -0.016790966253009167, -0.02214514392538343, -0.021319233950648542, -0.021843374999849535, -0.01982719075782352, -0.021907203852261435, -0.0442415577698694, -0.0454112791315573, -0.04787189632328193, -0.0511419870897619, -0.05496257611372958, -0.06035020004409163, -0.06136703912587201, -0.060915561613795965, -0.0643689445856112, -0.06344822589667846, -0.06569344725649766, -0.0657458536744896, -0.09581473399013476, -0.10387260979066182, -0.11333250656941138, -0.12172243093210379, -0.17442881303706642, -0.2029705037204752, -0.23922752614512974, -0.2857607366360302, -0.34624433697611506, -0.42581435664724526, -0.5315502212546758, -0.6731021313563645, -0.8608987616234463, -1.2342452335840086, -1.623376807951042, -2.1416493996509742, -2.8207759839754885, -3.867582454195744, -5.156192197324187, -6.742745024682924, -8.602576948377791, -10.659145076881265, -12.790057849028102, -13.61749504105349, -11.738259565865581, -10.004557491831589, -8.025180872626544, -6.297032995997496, -4.951060405865154, -3.4731346042960447, -2.5578811553916814, -1.8653030824873693, -1.3559381970677176, -1.045520360560231, -0.6977625802518294, -0.46373788193347043, -0.3150968330897968, -0.25780187964508566, -0.21366080220400982, -0.1794467477149232, -0.15313148645942765, -0.13374286928509915, -0.1213572084991213, -0.11484051066386144, -0.07369490196772431, -0.07592420210667702, -0.04300525207839892, -0.03524107682763836, -0.019574294788124766, -0.03054795224931268, -0.02106248674035484, -0.015455988475694018, -0.012252056616395777, -0.010482778138935936, -0.023875538335517654, -0.02392101260594547, -0.025190274669921655, -0.027345692577325432, -0.03022865606602182, -0.034617316476045504, -0.03409071462742906, -0.05348364984630886, -0.05787756447612325, -0.06341043568053327, -0.07002517585733897, -0.0789746112794655, -0.08316563929002004, -0.08749085058309287, -0.09177658846426999, -0.09595402144491282, -0.09890369301435872, -0.1079763411241284, -0.11407387852202117, -0.1206938100811912, -0.12809283981193642, -0.13548738604635316, -0.15109572401278773, -0.1731570985397142, -0.26769052130746457, -0.39589984884262647, -0.4961208369901745, -0.6306326069805155, -0.8115233642439046, -1.0531790594095962, -1.4475747742575085, -1.9910438389184868, -2.7282038994324878, -3.707003575258661, -4.96985458645056, -6.538725347431029]]\n",
      "Average Test Reward: -1.6151288673954445\n",
      "Hyperparameters: {'EnvName': 'Pendulum-v0', 'IntermediateSize': 64, 'Epsilon': 0.10480604571960442, 'ShowEvery': 10, 'InputShape': 3, 'NActions': 10}\n",
      "Test Rewards: [[-1.360768241254011, -1.7415987850831296, -2.3566990197385067, -3.2500898631799107, -4.470329119151151, -6.182376926245459, -8.17005018074026, -10.467504650263818, -12.953810076494284, -14.296959329260256, -12.254352702534051, -10.171335742191852, -8.16249689120849, -6.343837534957548, -4.794320457872284, -3.5417059399638964, -2.573669091991831, -1.94376755214045, -1.4692055187619308, -1.1187631679480805, -0.8657781289534399, -0.6913462301772781, -0.3910182214566206, -0.20204329552911224, -0.1326887605085683, -0.12201898179611648, -0.11974631083929539, -0.05766071751580161, -0.034588957790938214, -0.019800778102220112, -0.010744145105802662, -0.005837398196318389, -0.006626705398656948, -0.00731460015678259, -0.0036115282333852032, -0.0027736114717550786, -0.004184578529704622, -0.0068441830432680465, -0.00275197183198784, -0.0024925839326281093, -0.0024329615155001478, -0.005638345182852136, -0.008254178741315564, -0.005162251593806795, -0.011475632919586037, -0.007472824135720476, -0.0050213332802820495, -0.003554807152650636, -0.0026993847276082067, -0.0022114226404997134, -0.0019363156355480188, -0.001782048184017475, -0.0017033655766886964, -0.002733835448161396, -0.003134247179898473, -0.008027290397779788, -0.008535597963480447, -0.009496214335782974, -0.010883098626459971, -0.015164355166840357, -0.009380851568554538, -0.013110875918788957, -0.015470806535746123, -0.01855368461928318, -0.022649487729805094, -0.028172130908165286, -0.03627354474827966, -0.04280763120220355, -0.039761565144115676, -0.04122281217377084, -0.042555112155454274, -0.04235989826509745, -0.04973135295567029, -0.05236574028349591, -0.05677093308607128, -0.1028237949631596, -0.1038347963469468, -0.10679019951909696, -0.10651866312708566, -0.13824376066780716, -0.23371731009001873, -0.2662547480640943, -0.30883740993965697, -0.3595033437930612, -0.536264959540275, -0.8078853911846134, -1.2103636512433784, -1.7963834532313856, -2.338358425128658, -3.498996335537684, -4.937976906130015, -6.799513696194211, -9.086750357010892, -11.723826124665438, -14.550692757415282, -14.98360341915606, -12.695745846540875, -10.380530857917174, -8.046038776933557, -6.020518138565573, -4.3179159574584345, -2.9669637900064605, -2.0225829294904787, -1.5372911581702298, -0.9357097514819145, -0.5721369068623763, -0.4491290774460022, -0.3594957807952707, -0.29626929041857664, -0.25565984060222036, -0.13449381554480022, -0.12868329880846058, -0.08344080808912695, -0.053451241237502264, -0.043781718541050424, -0.0477142765444362, -0.01701177521822664, -0.01250519494467152, -0.009990268736675002, -0.008813387423509515, -0.008486216608365356, -0.015244616213340759, -0.017296677485471736, -0.020950983735250624, -0.02135955773781125, -0.026691925859098777, -0.037034909270399596, -0.09049620853631199, -0.08074986956234549, -0.07619341320997289, -0.07152849131768087, -0.08297241941126601, -0.0830898025719881, -0.08301457935713798, -0.08082006712083939, -0.08028008108137333, -0.07903488489811003, -0.07597522147609652, -0.0737973314500138, -0.07225193156313077, -0.07124552766495766, -0.07071830691257266, -0.0706386044409801, -0.07211994212897128, -0.07025546520410154, -0.06973940989901174, -0.06962478963706722, -0.06990368382944104, -0.07170940348542665, -0.07002745680896967, -0.06981324564013068, -0.07000169613715584, -0.0695608393392294, -0.09121017279803559, -0.09241843710582275, -0.09325924147017813, -0.0932682207962404, -0.09222432381715721, -0.08866874971729335, -0.08538733663994667, -0.08053942054572864, -0.07598054245800276, -0.07227553842478168, -0.0692028962525025, -0.06659239101314797, -0.06431048828610085, -0.06224992502434683, -0.05904230723120423, -0.06089404912410802, -0.061356727638714866, -0.0645997603301337, -0.068105814649159, -0.06732824984300992, -0.06982125522422118, -0.06849933121839188, -0.06887613671974925, -0.06924225204465413, -0.09255596113371292, -0.12271750775711912, -0.12934258669521756, -0.13708259604150738, -0.14538967855241375, -0.1540042575710977, -0.16261035990694434, -0.2576517876041052, -0.34783701106792225, -0.5310155588783606, -0.8928336734399156, -1.3354502169031008, -1.9713381489851207, -2.867804390116661, -4.10067724113513, -5.740376609478955, -7.825888674557174, -10.33037097213238, -13.13626272354607, -16.04906852559798, -14.087196423420211, -11.74668615546093, -9.322247246501346], [-1.9558669478109305, -2.158919570309032, -2.617451617306003, -3.2036494572223253, -4.163084285970251, -5.443111141722507, -7.045000621323353, -8.933843566944462, -11.029508567569438, -13.21469815593425, -12.262293047101279, -10.43633406886217, -8.708001052885693, -7.147404672260077, -5.7176398286625645, -4.430976694843481, -3.375099610925535, -2.5733642096604576, -1.9500350680214624, -1.4751922494274559, -1.1184989371695253, -0.8538747630516355, -0.5270049012452283, -0.420485076212908, -0.3405364094181622, -0.27992824709348374, -0.23339850626179265, -0.19698428778672336, -0.16807878560038778, -0.14482975688181374, -0.12526625200595282, -0.10726090788841719, -0.09694005093518801, -0.0909167831988293, -0.0894150323708151, -0.08378827137801619, -0.05467279297473118, -0.038127035240514466, -0.010139599451141748, -0.005112399975763005, -0.0021632267890268654, -0.0007304520694743229, -0.0005502438371031079, -0.0005199343556512703, -0.000784306622834905, -0.0005570354969248461, -0.0006520267814001722, -0.000635213145193661, -0.0005286555013661245, -0.0007652129212251367, -0.0004392804296202019, -0.00036854207125729154, -0.00037100992754601336, -0.0005407827898001548, -0.00037536812428306827, -0.0003829126187437344, -0.0005000253465322531, -0.0003427327567090447, -0.0006295210097287118, -0.0002731875577632472, -0.00043169522749241033, -0.0002877052934896608, -0.0024842839687243034, -0.004551588037160811, -0.003216359003789838, -0.0024366347468183437, -0.0019902242926749815, -0.001738803146632361, -0.0016043050327068833, -0.0015555942491726142, -0.0022374472373685324, -0.0020780743641838103, -0.0019834708326488216, -0.0019306283746944426, -0.0027415307270559222, -0.0026476538627221305, -0.002587867655020081, -0.0025327161981736008, -0.0033530555241184086, -0.0038013463376084062, -0.0029208546550884224, -0.006625387196466283, -0.0023086755830144605, -0.0021047823835669433, -0.002028092514513982, -0.0019863568318045557, -0.00260321678454501, -0.0025102292308272784, -0.002445792591268795, -0.005900313365902297, -0.00824041511592682, -0.003948329363115133, -0.0015440819979003365, -0.0005735301872543228, -0.0008678707360833646, -0.0006336561457610587, -0.0006932573477936854, -0.0007678948131885303, -0.0006193772648822667, -0.0007688590104548026, -0.0006152463661286331, -0.0005637404063181185, -0.0009032664905524058, -0.0006521969709376413, -0.0006905409231483621, -0.000822981419241181, -0.0006525774423016099, -0.0007666410327797743, -0.0006984555619495585, -0.0006059395871169902, -0.000825231317037016, -0.0005119666662791212, -0.0005438276767676938, -0.0006640974755010296, -0.0004987634756600723, -0.0006822286314623275, -0.0004729126306963946, -0.0004717598461167675, -0.0010303663619431495, -0.0035981978687626114, -0.002769269489685686, -0.0022996130610550294, -0.0020361988331757297, -0.001886972036186288, -0.004251315380132837, -0.00564921169351501, -0.002444284544473843, -0.0008787585399568734, -0.0006658480743238751, -0.000628309537218407, -0.0009586397585550782, -0.0007176184877631835, -0.0007438143319783647, -0.0009194991771235182, -0.0007357306023551206, -0.0008086622481892122, -0.0008498526244470844, -0.0007118792206637404, -0.0008393642846453117, -0.0007274441941540102, -0.0006476807217516184, -0.0011097982767859782, -0.0008320854167525298, -0.0007971069758482053, -0.0011838554912659387, -0.0009464708479165274, -0.0009171936113302396, -0.0013215753105992553, -0.0016099813993750848, -0.0015240733057550883, -0.0008233541654699185, -0.0009102916080575773, -0.0009029457668413864, -0.000779528759446576, -0.0009010897929533654, -0.0007941430310523098, -0.0007071605396863833, -0.001958539220622821, -0.0046079475446412525, -0.0021692263279008903, -0.0007965050411844283, -0.003718923359732966, -0.007281884655744687, -0.005142407501422899, -0.005299323973046527, -0.001059900555842268, -0.0036171986920226894, -0.009611823821879601, -0.032118830752479635, -0.01880969103215986, -0.011944504464576653, -0.010004056030510668, -0.010449003020563475, -0.0060010583896657225, -0.007422320914447748, -0.0070357944622656534, -0.003952265252208869, -0.0060814627720376276, -0.005451462061004524, -0.002824657849169087, -0.002551352786884268, -0.002494440657457222, -0.0024374239622286437, -0.004458826899965152, -0.014880315986755172, -0.008299691710927462, -0.005293470801194892, -0.006908454490959462, -0.006523947756694686, -0.0035436233580234543, -0.005605152573472924, -0.005263703444829528, -0.0025410043198537883, -0.0019928735544348913, -0.001935317670151128, -0.001925641881921503, -0.0021313525284514983, -0.0020244227381936352, -0.001960559964397411, -0.00193969715048737], [-0.05444463702165406, -0.049489161283083644, -0.039969391054964984, -0.03350441157877812, -0.03249313382718598, -0.04192331200080938, -0.04396771175095779, -0.04631689518897762, -0.04877139562428447, -0.05122777979212314, -0.05364581828854217, -0.056027536872753234, -0.05840439886373127, -0.060830182421605525, -0.0633780326502061, -0.06726083136124797, -0.06667448069928143, -0.06954952281192438, -0.06702744187314161, -0.07927179845354092, -0.07566513056221968, -0.08428874058445, -0.08163556797793584, -0.08595784553187119, -0.08348680988067206, -0.08223013246872185, -0.0803175077285987, -0.07664863942201992, -0.07358306398258642, -0.07117526265295207, -0.06928422452503916, -0.06780461540174076, -0.06665766217992944, -0.0657846703151736, -0.06514242312116834, -0.06469994219184433, -0.06443625106793992, -0.06433890055571201, -0.064403099014189, -0.06463135551535254, -0.06503359640346014, -0.06562776318368861, -0.06644094789832333, -0.06751117734933268, -0.07001002678150209, -0.07047808508855256, -0.06732921868585251, -0.06553851422933588, -0.06399514644267894, -0.06262777771705198, -0.061377076461864744, -0.060192167024313854, -0.05902800061055545, -0.05656344018257722, -0.06151761888666411, -0.10187395285209154, -0.10379044642651121, -0.10697392482510729, -0.11040896533306681, -0.11346022653402715, -0.11573675212217095, -0.1170042628369335, -0.11713063345649558, -0.11605535682854817, -0.11377787111944815, -0.10892284481824795, -0.10427963765264693, -0.09968128085576518, -0.09501133992295495, -0.09018795198023453, -0.08261582436918545, -0.08077231084078663, -0.08001955539044045, -0.07856325570502586, -0.07530054163540732, -0.07277586297032916, -0.07084724904078353, -0.06940250683086199, -0.06836076555535288, -0.06766543470883356, -0.06727943253988339, -0.06718212386948268, -0.06736761012393568, -0.06784417142347528, -0.06863479103870096, -0.0708988135756258, -0.07043924378158298, -0.10113375723687688, -0.10383052756921063, -0.1068281005312355, -0.10648020773232392, -0.15738771036813126, -0.17113322292281682, -0.18991659517300635, -0.20982077867047197, -0.23315144496587203, -0.2609158302755261, -0.2908489316882106, -0.4156133648332287, -0.6176673200588054, -0.8977487260540682, -1.3390504955751108, -1.975488622204849, -2.8720721960063926, -4.101587290291142, -5.734278622840344, -7.300407886454709, -9.63070658264085, -12.257900360683402, -15.013402715104602, -14.061421014342685, -11.816500299637873, -9.393561313303332, -7.361079200587871, -5.594918380672545, -4.04621794850581, -2.770197838462448, -1.8838904538947792, -1.4242650364582168, -0.9218676091625903, -0.7102172487372406, -0.557692627872426, -0.45315036391568686, -0.24172427200371577, -0.20866501630889167, -0.13621639694832918, -0.1365861813024239, -0.06312884306968213, -0.039380350266921424, -0.02386428330564693, -0.013886884854359405, -0.007912639581464272, -0.014431647114169893, -0.009679789001808232, -0.00679217177397456, -0.005102227288917948, -0.00416758968430474, -0.003696178797573437, -0.007248108932453662, -0.023984884253041603, -0.026716203852177222, -0.03423566008434414, -0.024028545763710874, -0.03160428153608412, -0.02980743113116113, -0.038859906116656774, -0.04021873470670917, -0.041936049721254906, -0.04372962582302202, -0.045430606603438166, -0.04694201178005112, -0.04821130478854919, -0.049212353699440124, -0.04993366441678208, -0.04909081223676768, -0.054876930495297675, -0.057337398245648596, -0.05983065365805682, -0.062423285898582676, -0.06632291176826881, -0.06571462227301467, -0.06918229985835814, -0.06670893482349387, -0.06659791608683763, -0.06674413577912329, -0.06715391244036222, -0.06784659330851667, -0.06885590495421577, -0.07135242160682756, -0.07007162599078488, -0.06944203203272122, -0.09005140763538365, -0.09108226928497833, -0.09169323696087998, -0.09144966798228454, -0.08872342634006247, -0.08694081493703638, -0.08460304200367139, -0.08059341116430532, -0.07725780947824046, -0.07477142503891675, -0.07297605564050313, -0.07176140280243684, -0.07105457384157378, -0.07081328045932703, -0.07102189996262373, -0.07273816204784349, -0.0712190034334649, -0.07116422561061897, -0.07269550091410823, -0.07087243215765657, -0.0704456452076717, -0.07045256803157615, -0.07201160192369717, -0.07019065425338848, -0.0697458156783188, -0.06970204026186134, -0.07005521950999044, -0.07194268930799601, -0.06891845328435217], [-0.02176297327763757, -0.011899204112493423, -0.006021612558479469, -0.00307981388120565, -0.002556727031332847, -0.004388300869166269, -0.0045209873610454485, -0.004725569784329896, -0.004961974913892481, -0.005206645010185667, -0.005446752968961863, -0.00567639768726108, -0.005894133085735599, -0.006101397252845629, -0.006301553151552516, -0.00649935159192188, -0.009758198646700512, -0.011256709611245311, -0.013156175176696884, -0.015596708060578864, -0.018784891060646697, -0.022951058299341263, -0.029734321608196404, -0.040369208082095584, -0.03640237036617797, -0.03616429258624885, -0.04509188836952717, -0.047642929225890966, -0.050329995806620675, -0.055026963252932846, -0.10326461867793192, -0.10379316688170714, -0.10656521293100346, -0.11022553683772823, -0.11392066823837807, -0.11712068609671926, -0.11950210498892017, -0.12087207247118134, -0.12112104639708514, -0.11751510545091527, -0.14953289571879821, -0.15617593476678107, -0.21812824329788544, -0.24676043965956682, -0.28181404211193156, -0.32125622126970754, -0.46688692902852935, -0.6986419991243874, -1.0506274624415226, -1.3635914075129494, -2.0062812134642782, -2.911421958000882, -4.151860333563812, -5.462797909858749, -7.424886831111639, -9.779104413909197, -12.42348268604402, -15.18606422072155, -13.793459657205538, -11.554293387959762, -9.364889217272966, -7.333094153615938, -5.451982128504385, -3.9392400945276647, -2.695137229237023, -1.8665335727189936, -1.411047620506809, -1.074764601176872, -0.8331543129638925, -0.47894305817299887, -0.38610899382415886, -0.3254581248124264, -0.1649862861336142, -0.1504328755662369, -0.0962093726040782, -0.060275934612745455, -0.03666050996114841, -0.021341158146365315, -0.011649523926330627, -0.005865888439928875, -0.005381046275100576, -0.009552446600408625, -0.0033051330006285016, -0.005773806809933091, -0.007037483677960493, -0.006271811447220559, -0.002781943600352435, -0.0010403617991801774, -0.0007277921255679195, -0.0007139852599638494, -0.0010048433454147073, -0.0007840331491068199, -0.0008085506380086877, -0.0009987643393921046, -0.0008134419712780736, -0.0008620505109099344, -0.0009783117154546315, -0.000816400298726453, -0.0008868107765529335, -0.0009329083422931316, -0.0007925743480961837, -0.0008919789655022258, -0.0008494622293186652, -0.0007387594860293193, -0.0008875656712426221, -0.000711764162867492, -0.0006553423148511497, -0.0012496008760701912, -0.0007287237870575493, -0.000916121754333127, -0.0006408354933590231, -0.0006293307523237708, -0.0008866137674423753, -0.0006697442342482524, -0.0007327561651347741, -0.0008007962302390974, -0.0006541968950222108, -0.0007926260714923184, -0.0006610098073154065, -0.004377657690880762, -0.012568254909640721, -0.00021800813660452284, -0.00037177250989567216, -0.0002058248608181152, -0.000647375640249157, -0.00016866199871654272, -0.0009806969039686966, -0.003424716518898092, -0.0020302320010588794, -0.0012187946784450224, -0.0007961141256257972, -0.0006670355464617119, -0.001286247364960681, -0.0009703427442947551, -0.0008776115828380792, -0.0015096875028544408, -0.0012347934085973906, -0.002731612122936862, -0.006576057487959719, -0.006293847264800116, -0.006448928116690139, -0.006913677754379627, -0.007621345797337607, -0.008550794597545371, -0.009718478126593844, -0.011176256447259185, -0.013014529508212264, -0.015370972360941123, -0.021063979132845738, -0.05415665194222484, -0.04141792868390439, -0.037471082038558264, -0.03869897600658229, -0.03873285053082299, -0.04617407692937604, -0.04861006329937155, -0.0510454952246993, -0.0549339054784595, -0.05280636072423927, -0.053386257983646324, -0.053757440932273366, -0.05392491916924907, -0.053890545591985334, -0.05237245559561874, -0.05690464585141216, -0.0589586578523709, -0.06104652727032026, -0.0632358334804791, -0.06560871029090028, -0.06938515839135571, -0.0699276881374698, -0.06861019555862906, -0.06899683310671122, -0.06974894473277603, -0.07202490905272359, -0.07062972142889822, -0.07092205923250593, -0.07278933334536702, -0.07116837950265842, -0.0710901746046223, -0.07259452148631836, -0.07105514794455399, -0.09628029482323633, -0.098267281618644, -0.09650533576040707, -0.1377847372657362, -0.14751010933208478, -0.15857927822894144, -0.17077998549737033, -0.18418132872677678, -0.1990821743992151, -0.21599505374375186, -0.23566018475724745, -0.25908848497518544, -0.28763605774665174, -0.3192760121032419, -0.44332468668019537, -0.6517192441522321, -0.9724836380618287, -1.4440355028410876], [-0.8015353172751796, -0.7546528752063871, -0.7745891229632333, -0.8306576096154461, -1.0367264798082423, -1.4107724775910164, -1.9907369807714124, -2.8277871817369995, -3.980312178927804, -5.500911032110571, -7.414690832627548, -9.692674355655598, -12.23400123546386, -14.877210119179107, -13.465089925207877, -11.298283944357607, -9.156834328107847, -7.172988907828723, -5.4514125703642655, -4.015647618366133, -2.7516187687764884, -1.9074709797103475, -1.4417754209234541, -1.0960644720660324, -0.706308106101467, -0.5530654036329804, -0.44672695556398256, -0.23866972340928078, -0.2052295623153088, -0.18576209382710554, -0.16626075074980082, -0.1617058387918304, -0.0788141430403586, -0.03774626958096784, -0.011940304604221158, -0.008750297391860338, -0.006962142483943746, -0.006894974536220124, -0.003582863448787906, -0.009656250457442287, -0.010413090789537444, -0.02021052683264473, -0.02405389553636749, -0.03216364928439433, -0.023834329800606353, -0.02976674065663714, -0.04029286677473797, -0.03652606778524992, -0.03751675288737098, -0.037373648935046064, -0.04505812440245277, -0.04729434359402013, -0.049489509307339315, -0.05158761940259754, -0.05357310482331368, -0.055456490181552784, -0.0572655505540133, -0.059040240697865176, -0.06083029103877952, -0.0626947994982554, -0.06470346789132712, -0.06805938585225421, -0.06719306358915154, -0.06855473451186461, -0.07131296235547681, -0.11129928030926323, -0.11549682870910968, -0.11809966220861434, -0.13911936616232864, -0.14447870503867796, -0.21039021954074408, -0.2375096779496018, -0.27090510666456424, -0.3121194832857639, -0.35971945780259823, -0.5232483893209723, -0.7813338028209503, -1.1680022883319807, -1.7303966376190216, -2.529251871110985, -3.6356704380068354, -5.120569691530144, -7.033274836495879, -9.37017676751102, -12.045780683085388, -14.89161553283547, -14.783797008677984, -12.479393844856554, -10.162088209156005, -7.843454732490534, -5.850019420780339, -4.037602509445342, -2.762099799895862, -1.87680037528126, -1.4220716285897046, -1.090039801645671, -0.8553203196975331, -0.5151774148058992, -0.2795106628248414, -0.2411121060634566, -0.11871177658351428, -0.08437190495150593, -0.08329688905315258, -0.05129916560915781, -0.030451210794962043, -0.017206722391897137, -0.009274173244578495, -0.005268809629039805, -0.0066477109092695046, -0.017518635243948946, -0.008649006152542098, -0.015602305085080363, -0.01208350430120314, -0.012625345625546316, -0.01541449073622992, -0.00818259127040254, -0.004580256364192601, -0.006384501740758184, -0.006004409090503752, -0.005806784891440823, -0.002649304687419049, -0.0015670434497474315, -0.0015933211013384318, -0.0016869049205382634, -0.0015610610373028766, -0.0013792474637821285, -0.001434915658797599, -0.0014827403516547216, -0.0014957866498756642, -0.0013739220640150004, -0.0013666772338637515, -0.0017295838408108942, -0.0015607042864120245, -0.0014909345342979548, -0.001521004968097964, -0.0016204552437408372, -0.001489845859178654, -0.001609518524917594, -0.0018049050344423317, -0.0011217156260437487, -0.001143999016490638, -0.0013592902253098773, -0.001188866326385949, -0.0011683397418943752, -0.0015914337323714588, -0.0013930826079473699, -0.0013206942542005136, -0.0013751181006520935, -0.0013944710811436083, -0.0012680964063717175, -0.0011813226604686824, -0.0012516284324737186, -0.0012092868680062356, -0.0010924223495172648, -0.0011412872176031013, -0.0012411547577245896, -0.0010920798856403093, -0.0011089558200251732, -0.0013490805600552488, -0.0011717740209430982, -0.0011483622073290023, -0.0015825294389879025, -0.0013802760501386863, -0.0013066251077119232, -0.001362010627957765, -0.0013810722423012027, -0.001254349329251465, -0.0012927351757200949, -0.0016189270413319576, -0.001431405961462634, -0.001362307952581214, -0.0014135748196242213, -0.0014352375836341174, -0.002451659711765891, -0.008405398997984103, -0.0046795188802580155, -0.013329851830029167, -0.006861083587734684, -0.004568834823327443, -0.0031267564927704343, -0.0030372670306183123, -0.006061928156524781, -0.004362102395233857, -0.0025139164118878473, -0.00537781682220937, -0.004085703075729898, -0.002040578261209364, -0.00204164670665024, -0.0019471739388020968, -0.0018972843632992563, -0.0026568569449322366, -0.0025552536467437314, -0.002489266264751244, -0.0024313778060530288, -0.0023772543889929057, -0.00543416615000049, -0.004090034073456751, -0.0051827427329362635, -0.0021945024175869837, -0.001730936927271295], [-0.0502026874048398, -0.04992672699185241, -0.06400462751437284, -0.0622533093655096, -0.05820809788894467, -0.057690263385168625, -0.05708991012550259, -0.05638895030717292, -0.0555674043740427, -0.05380349144660728, -0.0542982881084691, -0.05575593171911425, -0.05343365599667656, -0.05563883551337199, -0.08568194273712036, -0.08543913251484651, -0.08587603026186982, -0.08609709678671683, -0.08415998329892907, -0.08178981997494196, -0.08899111523586066, -0.13605094233093293, -0.14542996430688537, -0.1565251605553132, -0.1689880498529985, -0.18280618365145757, -0.19823473146192536, -0.21576989303212324, -0.23615692734837615, -0.2604305198684695, -0.2899893221058364, -0.3267102210951312, -0.3731114246863943, -0.42916323375018284, -0.623968554778717, -0.9213135241268091, -1.4005026408237156, -2.111087580582712, -3.1159406706332144, -4.071793325369044, -5.746319779631978, -8.003945581889077, -10.593886276656196, -13.486653959759856, -16.0924383999387, -13.497269132898591, -11.055467066884372, -8.717582300054767, -6.628060560398914, -4.879385106430427, -3.4979045975480534, -2.353125477391477, -1.7767023362576913, -1.346117374016297, -1.0313383204498634, -0.8078362394473814, -0.4831291552020808, -0.26091329245276845, -0.21951436823065573, -0.13952001557871027, -0.10388205419411779, -0.10621147797726302, -0.03909973036256489, -0.02259417920167979, -0.013427233519196034, -0.012130734692256593, -0.012286855894254177, -0.0075842443200738385, -0.009934871986805364, -0.02380988190596148, -0.021217088232083115, -0.016968466576953556, -0.013406992791919946, -0.01480560286961623, -0.02439049211718321, -0.023971583346922506, -0.021388627069955018, -0.018415030851534026, -0.017120117909610856, -0.019009919835200253, -0.01720705276593299, -0.01477354761528146, -0.012844324208507483, -0.014176323080965735, -0.012719623038577052, -0.01085233948519346, -0.00936329447859015, -0.008633644983265855, -0.009307250161812039, -0.007957210844447242, -0.006086061269616084, -0.008984127287237935, -0.007582913107057566, -0.008226327262842247, -0.007167199133584839, -0.005384745234081408, -0.012306666824824015, -0.03511620922938329, -0.03045605238489033, -0.02933215260225628, -0.02534270025245315, -0.023360856990433707, -0.023025673925643093, -0.024703804476190423, -0.031000650547955522, -0.013631414230763212, -0.015007580801634092, -0.02081646633007115, -0.008620279277064245, -0.01664418022511369, -0.01169879393499296, -0.011175987475585538, -0.016666109379391635, -0.012866278559736977, -0.012946792613131863, -0.014939429545884519, -0.017803171806014984, -0.015229935919190026, -0.015820633760925382, -0.018234496944173947, -0.020524321744150878, -0.007662089924065626, -0.014077278046314846, -0.009525222418089799, -0.01000478357306861, -0.012298508682020731, -0.0070934091918726135, -0.009404585239638002, -0.019417506827779974, -0.017312191294968415, -0.011822449306393803, -0.01245583850137863, -0.013458435465680202, -0.014920077622538426, -0.018257129079677546, -0.016050740845837692, -0.01772576279767381, -0.018032115252479202, -0.018174509644535805, -0.018935010299882756, -0.019654527092748595, -0.02784688859747012, -0.027224502756769197, -0.026956888971613767, -0.0266965098535897, -0.026270519713721345, -0.025649623759068832, -0.023505016426233424, -0.02181545790530899, -0.021273459016186002, -0.02060120129261376, -0.021720849152773676, -0.031242434209332665, -0.031171588783165255, -0.03141436902247767, -0.03099114257675997, -0.04977756711587486, -0.051124313020987466, -0.05501435046307789, -0.05941865976587067, -0.06433839107246006, -0.06987798017218434, -0.07623733807570816, -0.0848382848015234, -0.08920269002525409, -0.09350327579652606, -0.0977003762842921, -0.10181550473519858, -0.10591318135099327, -0.11009113110775892, -0.11447665395725029, -0.11922794670895887, -0.12453991129622102, -0.13065463309350805, -0.13787734904126953, -0.14404730779239927, -0.18596167597208896, -0.21382037169997004, -0.24915340871678887, -0.29472101876029494, -0.35432181033326293, -0.43316842810095235, -0.5383862454580919, -0.6796503830414421, -0.8699546732213587, -1.1264550553326607, -1.4713922294963906, -2.2616665653897594, -3.2241932559672932, -4.237468515451183, -5.498386131509619, -7.320719218372365, -9.649176006939982, -11.687434852856764, -14.30574449005804, -13.385766260480253, -11.350227215322894, -9.310373813821231, -7.390392613041679, -5.697304551777293], [-7.398475736591255, -7.378208691057023, -7.4814909662522, -7.592641888835978, -7.716431065223454, -7.848395855953996, -7.983758171561654, -8.117610836811156, -8.245111156503036, -8.361670647011447, -8.460609976910206, -8.624388275615994, -8.947857086458143, -9.408215884322805, -9.98653107182365, -9.770331719744183, -9.357787711715295, -8.903587715431808, -8.421437936842837, -7.9056130601295385, -7.41924281209082, -6.925798095454363, -6.566302673425516, -6.277857892367675, -6.253229260165003, -6.497336020655444, -7.002779250147695, -7.633853152770842, -8.535062323679314, -9.620876878390723, -10.881357538990974, -10.119987944862505, -9.147610896252667, -8.150647205276316, -7.165907261188879, -6.231457825759551, -5.38154902927062, -4.642596331489318, -4.030079013774207, -3.5160134091915762, -3.2889750048422113, -3.206270280311088, -3.383698803857849, -3.7000193508205017, -4.160283815930744, -4.731039677011094, -5.452738512674106, -6.500013977546107, -7.866641351873379, -9.44397637682054, -11.160717784032485, -11.452020159973863, -10.273320534399739, -9.030083969663126, -7.764982180556954, -6.376052477017536, -5.305039723493116, -4.356081781001421, -3.5479442946388597, -2.8842022900388895, -2.35591937889495, -1.862231308224451, -1.6880261544308086, -1.810530054301438, -2.2255518420828677, -2.961534014697649, -4.010229815840424, -5.1668944477963645, -6.859705199766763, -8.899301895397116, -11.206400926635217, -13.651034344626046, -12.963335355094117, -11.047214042538155, -9.123212756599813, -7.302074366210447, -5.787170888046977, -4.489282210867556, -3.4319799907259743, -2.4407548341092817, -1.7913734684678362, -1.3649410549333598, -1.0596413650536811, -0.8523052639575488, -0.5244907727697876, -0.29166463599693443, -0.14705303525683902, -0.06347035014547306, -0.07014443821484125, -0.024671831453764066, -0.014962707368326566, -0.013134787470643478, -0.011339085032841032, -0.009919383871921835, -0.008767383500216074, -0.007807199571373556, -0.007108476616232383, -0.006588942769403505, -0.005906042220051433, -0.006484955271862464, -0.0039271668445666355, -0.005805263954397454, -0.006280107614486337, -0.006862138214121619, -0.007548085269705269, -0.00835349228237689, -0.009311758705359288, -0.01047586998512109, -0.012265235232516563, -0.012220694457927235, -0.01379377764533738, -0.015884213036812096, -0.01996631775311955, -0.01762935010880754, -0.021105645901219945, -0.01913761287365282, -0.02241431344834644, -0.019808435892359876, -0.020555593070110397, -0.030959326715381624, -0.03101205348831299, -0.03171438987865109, -0.05968902657763746, -0.05890680816939259, -0.059464280856127566, -0.06045848748879174, -0.06020273243063617, -0.0643513554501559, -0.06381412900459883, -0.06687090121929262, -0.06579835005054555, -0.06581196276890898, -0.07116227627998123, -0.07173327041228006, -0.10814862254818856, -0.11992882612427343, -0.2224376153304778, -0.26431564835993976, -0.3206834479475156, -0.39653209138378503, -0.6832323757034342, -0.8809927759457862, -1.150113987983597, -1.5137342880196372, -2.000944198309445, -2.645855933603991, -3.482564883602389, -4.670161008441206, -6.154129987972427, -8.050941772726276, -10.086100367792216, -12.626583347799475, -14.329190920939926, -12.156208673105787, -10.24406544153053, -8.364658024969033, -6.624351639954429, -5.105674555053385, -3.8520098484626177, -2.9726496095253445, -2.1758919407102257, -1.5809652771482816, -1.1450460595055005, -0.8310544028831538, -0.6319938907449575, -0.4155766356680746, -0.27286375124833046, -0.18398538473694848, -0.14560890874176638, -0.1188287897363709, -0.1005606307518174, -0.08872605157648054, -0.08279039252677563, -0.07949509387197685, -0.07716225257091386, -0.07426210507594486, -0.08711550707550579, -0.08731530875119128, -0.0867072197829175, -0.08369753149552615, -0.08133566424312969, -0.07838777817745543, -0.07491004965200615, -0.07101895910173038, -0.0669312031409439, -0.06302460644176731, -0.059930473173774236, -0.05867301131184479, -0.06087915596776503, -0.06669342847551538, -0.0421399817478554, -0.02609067827100998, -0.01569195779748949, -0.009030068799709995, -0.004833668725039049, -0.0022733991085040774, -0.0008297088911461406, -0.00020944930256001812, -0.0002987420613753567, -0.0011449954396250232], [-4.004747443122836, -4.300501633387421, -4.954635130610029, -5.835616513345339, -7.078149893898034, -8.46205514842473, -10.203804724863618, -12.102300997426036, -11.216673615787093, -9.821877313196422, -8.39784400454226, -6.904812186420325, -5.660270589792268, -4.561393427569514, -3.6323360041535695, -2.876846211720996, -2.2840290676587722, -1.8336584581281878, -1.4575711916601632, -1.312430018318953, -1.2579930722898318, -1.2906107244749128, -1.4126826436633544, -1.6326980639937312, -1.964963907728203, -2.4268167195411015, -3.1265904363846957, -4.053401329949383, -5.2277007301877765, -6.650474374767273, -8.291437260248847, -10.083133305112074, -11.927322654500614, -12.70361189859525, -10.990297426933774, -9.474915304875049, -7.952558589118082, -6.503130916282954, -5.19642972795141, -4.076195364427848, -3.156572865948927, -2.4284177154338793, -1.867756389075352, -1.4134740547925062, -0.9519506194040761, -0.6328165991560301, -0.41535788488672293, -0.2696701343601691, -0.17468968122505532, -0.11622080075792464, -0.08534628497104084, -0.07972649078749602, -0.07865309581903579, -0.07687282513784174, -0.07201851555063243, -0.07988709834276767, -0.0792027059234796, -0.07635225113576416, -0.07191706461720956, -0.08155081485804927, -0.08110459418261859, -0.07847219438197836, -0.07693418670284946, -0.07230261609297572, -0.08120293024858602, -0.08067618680945715, -0.07683837442358168, -0.07612933545416685, -0.07613911662879878, -0.07942414760018078, -0.07535521134271313, -0.07370576042645635, -0.07266880443348551, -0.07330029409857201, -0.0720788402043126, -0.06771970193164974, -0.0765709052470827, -0.07577009087118215, -0.07293866659160284, -0.06858901655918577, -0.07772138302719717, -0.07700431619479473, -0.07421883767445452, -0.06981396558645214, -0.07673237947137078, -0.07314620596121815, -0.07370272121397364, -0.07341193834408774, -0.0897607282683829, -0.09051690920752785, -0.09057818759133676, -0.08966239200405539, -0.08515638928862203, -0.08263318419179694, -0.0823367698128887, -0.0807188900419225, -0.0771642762352759, -0.07381570046667185, -0.0753553976125001, -0.0795878002049073, -0.07561316254128574, -0.09831554633160668, -0.10054738726870088, -0.10243655848590112, -0.10351438731871536, -0.1035155005284591, -0.09877311247397007, -0.11991815357014446, -0.12460399670035971, -0.1287774124422355, -0.13223102107156112, -0.13484887492124237, -0.13656802435802878, -0.1373540546726697, -0.13389708118266228, -0.14424529173141334, -0.14773972794445714, -0.1506131400333436, -0.15288620988722856, -0.15458439701919244, -0.15573128975728492, -0.15634446760228332, -0.15643300748446057, -0.15599609697487976, -0.1550224602768628, -0.15349049797490225, -0.15136922118504786, -0.14862025454284752, -0.14520142230063451, -0.14107275714416057, -0.13620623573037696, -0.13060122506484867, -0.12286863256274295, -0.11616595542133198, -0.1277934390829518, -0.15556744093424932, -0.1678247714186936, -0.18138384264001853, -0.1964815240401584, -0.2135901832666228, -0.23342333008593627, -0.25697281782097253, -0.285579139071327, -0.3210400210056833, -0.3623083873483644, -0.46401115877702986, -0.5816484633558332, -0.8251429026397209, -1.1876709171355582, -1.7118349360157141, -2.599470792945586, -3.6673411316507005, -5.082482698294297, -6.884133990457363, -9.063522972380845, -11.340684145646879, -13.707153594499513, -14.127961254192652, -11.838747205515523, -9.654397518218174, -7.910796309258248, -6.303710454553943, -4.906923786444476, -3.5193679675760565, -2.4710760988242986, -1.8669780888527936, -1.4146182851926883, -0.9499915696258755, -0.741688344632906, -0.613928776714325, -0.3613634368779449, -0.18509313385436044, -0.10200498782262707, -0.0954492998410347, -0.06760288329795412, -0.027259684454310883, -0.01824964762819983, -0.015197899811919663, -0.012875784569762834, -0.011071349946624235, -0.009635514625903169, -0.00842059877946858, -0.007361297886259517, -0.00764832068592134, -0.00943481585558552, -0.006139006673425539, -0.006305163217985825, -0.00652607195232516, -0.006887332553931302, -0.00640235238076237, -0.006373340264729619, -0.008273478660955543, -0.0009711001111538942, -0.0013492276465588654, -0.002143790810687042, -0.0035978758937997147, -0.001660822200951367, -0.0036835001640476736, -0.0035366945773908985, -0.0005472570092810694], [-4.6741298790478, -4.599477645702595, -4.713481136973855, -5.119594969106773, -5.719121861133952, -6.59490647389754, -7.815352423115999, -9.288753649778482, -10.947630414711863, -11.402963079214347, -10.149733520733463, -8.849279881528846, -7.553359340116859, -6.318989369156314, -5.1966382794664625, -4.221058780339028, -3.4082782082356156, -2.758241608061791, -2.2603794334720373, -1.8994548812577339, -1.6602224577202134, -1.5305391724236423, -1.5031738031795547, -1.5767154627771391, -1.7539626668060089, -2.100621677903385, -2.626373127276009, -3.3568191163059735, -4.316686583035447, -5.520826295714727, -6.962808948361785, -8.604571966328525, -10.373237962790146, -12.170311028933432, -12.211838796240723, -10.746249545298834, -9.215891552049195, -7.693204838484085, -6.258739848506634, -4.978981442489676, -3.8923464769521288, -3.007931327454593, -2.3117282448099035, -1.7482650910376296, -1.3299010790144628, -0.8952756576589774, -0.5952364607278705, -0.3906444197061067, -0.25285462397247044, -0.16162224768981254, -0.10308974559340901, -0.06816603998033309, -0.05135961520142976, -0.05003558991769167, -0.06789108870027087, -0.06622959525537908, -0.06305266712482047, -0.0608452455133131, -0.07662646055659393, -0.07605444699006694, -0.07515898246013765, -0.07223514722491636, -0.06763384821602587, -0.07532824036295797, -0.07439532886761954, -0.07034311454166399, -0.0685699052886192, -0.0696937136089851, -0.06416459244408389, -0.06839858858044419, -0.06561707875529052, -0.06418971381515999, -0.060858573313283884, -0.07151047374184943, -0.07047213049129696, -0.06778419490142788, -0.06661099002082327, -0.06230765400398272, -0.0698347134285283, -0.06719237828214442, -0.06402938131885669, -0.07787425595789146, -0.07738992008917515, -0.07498879271508235, -0.07422323583742137, -0.07030351976851543, -0.0817764099787665, -0.07980697086698564, -0.08282779868679348, -0.08022612127817957, -0.07872940157438028, -0.07400812513375295, -0.07585121755069892, -0.0861952726470714, -0.12732767596094677, -0.13489292526033053, -0.14373748425991548, -0.15338407244024457, -0.1636531669241328, -0.17457965496044517, -0.18636599955619004, -0.19936255848772422, -0.214069925121811, -0.2271615015712383, -0.2980785266244903, -0.3403321810070598, -0.47415077851948007, -0.6816864364200632, -0.9894485983388256, -1.4371789372995973, -2.253688198892495, -3.2037198958911652, -4.285832633369292, -6.0294617488759314, -8.232226116959495, -10.852750987751534, -13.75770938188956, -15.845727108063423, -13.168010596890731, -10.974795556404295, -8.834308021118444, -6.888814721809287, -5.240234687472033, -3.6546666574781326, -2.3916562479854373, -1.5790049288355883, -1.2209245055213573, -0.7798811152290591, -0.4839204663934315, -0.2891440070728082, -0.16584560795920322, -0.15069630414167406, -0.12663488432548556, -0.11619254141017266, -0.06440520381781298, -0.030916720437683898, -0.03420775086711174, -0.021742868767076044, -0.014121368967145975, -0.009552318493712924, -0.006877165343809668, -0.005376813524956137, -0.004650751105837408, -0.004069732406343495, -0.0049160333181301145, -0.004541004039704966, -0.004321348369012983, -0.0059535633650598645, -0.00837948788267385, -0.016124305318120848, -0.012151018913245833, -0.029293971210967253, -0.04675802332174801, -0.10122489128415477, -0.08949387782911516, -0.11957826636133437, -0.1177049714158745, -0.12371481358217218, -0.13579317883086495, -0.15320021549591106, -0.1760558127756485, -0.20525451469667677, -0.24248986488122304, -0.2903818629034314, -0.3527123153323128, -0.4352762685308358, -0.7224712411869666, -0.9362992423053106, -1.2226797726151388, -1.8012406501591267, -2.623006258719621, -3.7572612367244673, -5.271141576489139, -7.207516831332272, -9.55420604673622, -12.217948847070433, -15.031028199700039, -14.005951891632735, -11.816211883255548, -9.629006925077576, -7.318477258572046, -5.366219911285703, -4.189704811040035, -2.891862538288374, -1.923163501680008, -1.4790629250165164, -1.099596061623614, -0.8011711910755207, -0.4964436274394938, -0.407197029847926, -0.32860972766884544, -0.2621753934789323, -0.2212564716717848, -0.18675484875569237, -0.15204417491701686, -0.14320618187670295, -0.13065915542386708, -0.12195559877011487, -0.11708727932563393, -0.1080816095585217], [-1.8833327842970584, -1.8177356699457996, -1.8670180186963485, -2.0340649750807978, -2.327266632566429, -2.7594991317607427, -3.345940614363309, -4.098451097063901, -5.133725763284355, -6.318627933821716, -7.746148785810349, -9.539177419719985, -11.472477339652087, -12.631739158490115, -11.20010022831989, -9.686151326120056, -8.155397159879154, -6.687973722265453, -5.356541885799704, -4.208846653290287, -3.259240235840467, -2.396913313028038, -1.8095835704947483, -1.3688600666421298, -1.0419985398736904, -0.6941113269624269, -0.45687391904955493, -0.2983601797648588, -0.19605193264349796, -0.13551638921607626, -0.11412982423681785, -0.10024264041219708, -0.0804776849685464, -0.08679426937572224, -0.08631481630908348, -0.08192937817431614, -0.10259344648672405, -0.10525205606449377, -0.10344970498094799, -0.1283794291798802, -0.22713098197711698, -0.25804793069852094, -0.29832624674123825, -0.345668288975239, -0.49605969738407524, -0.7463864664954395, -1.1197678705126692, -1.662611031294101, -2.437414898133478, -3.6900857912129066, -5.417882700337219, -7.606238182905994, -10.110144993335874, -12.951297477311277, -15.700462447594585, -14.395066879661433, -11.6755810062766, -9.666913428850473, -7.414708546091758, -5.499896768201034, -3.8120751703422076, -2.5173027831073114, -1.9030659591071584, -1.4467755757234597, -1.1177453765450043, -0.891255932071573, -0.5469387426967015, -0.30349849702552084, -0.15192471300537996, -0.14756193957357885, -0.16001933554753653, -0.07502816153485284, -0.0312619986139773, -0.01658983301770853, -0.007701707280094794, -0.002768160381025065, -0.001537960703911787, -0.005458487102382192, -0.0022921772717709125, -0.002682712609080044, -0.00477196262989088, -0.010175127509711052, -0.019703602115600957, -0.03638397823733459, -0.025022563819579534, -0.01946649130293328, -0.01125002055787592, -0.023853571202931915, -0.02229836537184524, -0.018813631392848088, -0.015996397047406744, -0.022028248233508223, -0.016790966253009167, -0.02214514392538343, -0.021319233950648542, -0.021843374999849535, -0.01982719075782352, -0.021907203852261435, -0.0442415577698694, -0.0454112791315573, -0.04787189632328193, -0.0511419870897619, -0.05496257611372958, -0.06035020004409163, -0.06136703912587201, -0.060915561613795965, -0.0643689445856112, -0.06344822589667846, -0.06569344725649766, -0.0657458536744896, -0.09581473399013476, -0.10387260979066182, -0.11333250656941138, -0.12172243093210379, -0.17442881303706642, -0.2029705037204752, -0.23922752614512974, -0.2857607366360302, -0.34624433697611506, -0.42581435664724526, -0.5315502212546758, -0.6731021313563645, -0.8608987616234463, -1.2342452335840086, -1.623376807951042, -2.1416493996509742, -2.8207759839754885, -3.867582454195744, -5.156192197324187, -6.742745024682924, -8.602576948377791, -10.659145076881265, -12.790057849028102, -13.61749504105349, -11.738259565865581, -10.004557491831589, -8.025180872626544, -6.297032995997496, -4.951060405865154, -3.4731346042960447, -2.5578811553916814, -1.8653030824873693, -1.3559381970677176, -1.045520360560231, -0.6977625802518294, -0.46373788193347043, -0.3150968330897968, -0.25780187964508566, -0.21366080220400982, -0.1794467477149232, -0.15313148645942765, -0.13374286928509915, -0.1213572084991213, -0.11484051066386144, -0.07369490196772431, -0.07592420210667702, -0.04300525207839892, -0.03524107682763836, -0.019574294788124766, -0.03054795224931268, -0.02106248674035484, -0.015455988475694018, -0.012252056616395777, -0.010482778138935936, -0.023875538335517654, -0.02392101260594547, -0.025190274669921655, -0.027345692577325432, -0.03022865606602182, -0.034617316476045504, -0.03409071462742906, -0.05348364984630886, -0.05787756447612325, -0.06341043568053327, -0.07002517585733897, -0.0789746112794655, -0.08316563929002004, -0.08749085058309287, -0.09177658846426999, -0.09595402144491282, -0.09890369301435872, -0.1079763411241284, -0.11407387852202117, -0.1206938100811912, -0.12809283981193642, -0.13548738604635316, -0.15109572401278773, -0.1731570985397142, -0.26769052130746457, -0.39589984884262647, -0.4961208369901745, -0.6306326069805155, -0.8115233642439046, -1.0531790594095962, -1.4475747742575085, -1.9910438389184868, -2.7282038994324878, -3.707003575258661, -4.96985458645056, -6.538725347431029]]\n",
      "Average Test Reward: -1.6151288673954445\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'EnvName': EnvName,\n",
    "    'IntermediateSize': IntermediateSize,\n",
    "    'Epsilon': Epsilon,\n",
    "    'ShowEvery': ShowEvery,\n",
    "    'InputShape': InputShape,\n",
    "    'NActions': NActions\n",
    "}\n",
    "\n",
    "dqn = DQN(InputShape = InputShape, NActions = NActions)\n",
    "\n",
    "# Test the best agent by loading the best weights\n",
    "dir_path = 'best_dqn_weights'\n",
    "\n",
    "dqn.load_weights(path=dir_path)\n",
    "test_episodes = 10\n",
    "Epsilon = 1.0\n",
    "test_rewards = []\n",
    "for _ in range(test_episodes):\n",
    "    print(f'Episode {_}')\n",
    "    reward = OneEpisode(dqn)\n",
    "    test_rewards.append(reward)\n",
    "\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env = gym.make(f'{EnvName}')\n",
    "state = env.reset()\n",
    "ListOfRewards = []\n",
    "Done = False\n",
    "while not Done:\n",
    "    Q = dqn.Main(state.reshape(-1, state.shape[0]))\n",
    "    action = np.argmax(Q)\n",
    "    action = PendulumActionConverter(action)\n",
    "    AStep = np.array([action])\n",
    "    action = PendulumInverseActionConverter(action)\n",
    "    env.render()\n",
    "    SNext, reward, Done, Info = env.step(AStep)\n",
    "\n",
    "    state = SNext\n",
    "\n",
    "print(f'Hyperparameters: {hyperparameters}')\n",
    "print(f'Test Rewards: {test_rewards}')\n",
    "print(f'Average Test Reward: {np.mean(test_rewards)}')\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
