{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, input_shape=(28, 28, 1), latent_dim=100):\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.gan = self.build_gan()\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(self.latent_dim,)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.Reshape((7, 7, 256)))\n",
    "        assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "        model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "        assert model.output_shape == (None, 7, 7, 128)\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "        assert model.output_shape == (None, 14, 14, 64)\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "        assert model.output_shape == (None, self.input_shape[0], self.input_shape[1], self.input_shape[2])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "    \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                        input_shape=self.input_shape))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "        model.add(layers.LeakyReLU())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(1))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_gan(self):\n",
    "        self.discriminator.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "        self.discriminator.trainable = False\n",
    "        gan = tf.keras.Sequential()\n",
    "        gan.add(self.generator)\n",
    "        gan.add(self.discriminator)\n",
    "        gan.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "        return gan\n",
    "    \n",
    "    def generate_and_save_images(self, model, epoch, test_input):\n",
    "        predictions = model(test_input, training=False)\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "        plt.show()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, images):\n",
    "        noise_dim = 100\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        # Train the discriminator\n",
    "        noise = tf.random.normal([batch_size, noise_dim])\n",
    "        generated_images = self.generator(noise, training=True)\n",
    "\n",
    "        real_output = self.discriminator(images, training=True)\n",
    "        fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "        d_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        g_loss = self.generator_loss(fake_output)\n",
    "\n",
    "        d_gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        g_gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}\n",
    "\n",
    "    def train(self, data, epochs=50, batch_size=128):\n",
    "        for epoch in range(epochs):\n",
    "            for image_batch in data:\n",
    "                self.train_step(image_batch)\n",
    "            if (epoch + 1) % 15 == 0:\n",
    "                self.generate_and_save_images(self.generator, epoch + 1, self.seed)\n",
    "            print('Epoch: ', epoch)\n",
    "        self.generate_and_save_images(self.generator, epochs, self.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.environ.get(\"DATASET_PATH\"), header=None)\n",
    "df.head()\n",
    "train_label = df[0]\n",
    "train_images = df.drop(0, axis=1)\n",
    "augment_images = []\n",
    "for i in train_images.index:\n",
    "    pixels = train_images.loc[i].values\n",
    "    image = np.array(pixels).reshape(28,28)\n",
    "    rotated_image = np.rot90(image, k=-1)\n",
    "    flipped_horizontal = np.fliplr(rotated_image)\n",
    "    augment_images.append(flipped_horizontal)\n",
    "\n",
    "train_images = np.array(augment_images)\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = GAN()\n",
    "dcgan.train(train_dataset, epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
