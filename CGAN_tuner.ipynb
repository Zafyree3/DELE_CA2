{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88800, 28, 28, 1) (88800,)\n"
     ]
    }
   ],
   "source": [
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\tdf = pd.read_csv('emnist-letters-train.csv', header=None)\n",
    "\tdf = df[df[0] != -1]\n",
    "\ttrainy = df[0]\n",
    "\ttrainX = df.drop(0, axis=1)\n",
    "\n",
    "\t# augement x\n",
    "\taugmented_data = []\n",
    "\tfor i in trainX.index:\n",
    "\t\tpixels = trainX.loc[i].values\n",
    "\t\timage = np.array(pixels).reshape(28,28)\n",
    "\t\trotated_image = np.rot90(image, k=-1)\n",
    "\t\tflipped_horizontal = np.fliplr(rotated_image)\n",
    "\t\taugmented_data.append(flipped_horizontal)\n",
    "\t\n",
    "\ttrainX = np.array(augmented_data)\n",
    "\ttrainX = trainX.reshape(trainX.shape[0], 28, 28, 1)\n",
    "\n",
    "\t# convert from ints to floats\n",
    "\tX = trainX.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\n",
    "\t# reset index\n",
    "\ttrainy = trainy.reset_index(drop=True)\n",
    "\n",
    "\treturn [X, trainy]\n",
    "\n",
    "(trainX, trainy) = load_real_samples()\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up local functions\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=26):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input], verbose=0)\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "def define_discriminator(in_shape=(28,28,1), n_classes=26, trial=None):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # scale up to image dimensions with linear activation\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # concat label as a channel\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    # downsample\n",
    "    d_conv_layers = trial.suggest_int('d_conv_layers', 1, 3)\n",
    "    for i in range(d_conv_layers):\n",
    "        d_num_filters = trial.suggest_int('d_num_filters_l{}'.format(i), 32, 128)\n",
    "        merge = Conv2D(d_num_filters, (3,3), strides=(2,2), padding='same')(merge)\n",
    "        merge = LeakyReLU(alpha=0.2)(merge)\n",
    "\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(merge)\n",
    "    # dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    # output\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "    # define model\n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "def define_generator(latent_dim, n_classes=26, trial=None):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 7 * 7\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "    \n",
    "    # upsample to 14x14\n",
    "    g_convT_layers = trial.suggest_int('g_convT_layers', 2, 4)\n",
    "\n",
    "    current_size = 7\n",
    "    target_size = 28\n",
    "\n",
    "    for i in range(g_convT_layers):\n",
    "        # Calculate the stride and kernel size based on remaining upsampling needed\n",
    "        stride = 2 if current_size * 2 <= target_size else 1\n",
    "        kernel_size = 4 if current_size * 2 <= target_size else 3  # Adjust based on stride\n",
    "        \n",
    "        g_num_filters = trial.suggest_int('g_num_filters_l{}'.format(i), 64, 128) if trial else 128  # Default value if trial is None\n",
    "        merge = Conv2DTranspose(g_num_filters, (kernel_size,kernel_size), strides=(stride,stride), padding='same')(merge)\n",
    "        merge = LeakyReLU(alpha=0.2)(merge)\n",
    "\n",
    "        current_size *= stride\n",
    "\n",
    "    # output\n",
    "    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(merge)\n",
    "\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model\n",
    "\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "\n",
    "    # print shapes\n",
    "    #print(gen_noise.shape)\n",
    "    #print(gen_label.shape)\n",
    "    #print(gen_output.shape)\n",
    "\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "def js_divergence(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
    "\n",
    "def learn(g_model, d_model, gan_model, dataset, latent_dim, n_batch=128, curr_epoch=0, max_epochs=100):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(1):\n",
    "        # enumerate batches over the training set\n",
    "        for j in tqdm(range(bat_per_epo), desc=\"Epoch {}/{}\".format(curr_epoch, max_epochs)):\n",
    "            # get randomly selected 'real' samples\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            # generate 'fake' examples\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            # summarize loss on this batch\n",
    "            #print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\n",
    "def evaluate(g_model, d_model, dataset, latent_dim, n_batch=128):\n",
    "    # calculate KL and JSD values\n",
    "    [X_real, labels_real], _ = generate_real_samples(dataset, n_batch)\n",
    "    [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "    [X_fake, _], _ = generate_fake_samples(g_model, latent_dim, n_batch)\n",
    "    # use the discriminator to classify real and fake samples\n",
    "    d_real = d_model.predict([X_real, labels_real], verbose=0)\n",
    "    d_fake = d_model.predict([X_fake, labels_input], verbose=0)\n",
    "\n",
    "    # calculate kl and js divergence\n",
    "    kl_score = kl_divergence(d_real, d_fake)\n",
    "    js_score = js_divergence(d_real, d_fake)\n",
    "\n",
    "    print('KL divergence: %.3f' % kl_score)\n",
    "    print('JS divergence: %.3f' % js_score)\n",
    "\n",
    "    return kl_score, js_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "            \n",
    "    (trainX, trainy) = load_real_samples()\n",
    "\n",
    "    # size of the latent space\n",
    "    latent_dim = 100\n",
    "\n",
    "    # create the discriminator\n",
    "    d_model = define_discriminator(trial=trial)\n",
    "    # create the generator\n",
    "    g_model = define_generator(latent_dim, trial=trial)\n",
    "    # create the gan\n",
    "    gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "    # train model\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        epochs = trial.suggest_int('epochs', 10, 50)\n",
    "        \n",
    "        # print trial\n",
    "        print(f\"Trial {trial.number} with parameters {trial.params}\")\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            learn(g_model, d_model, gan_model, [trainX, trainy], latent_dim, curr_epoch=_, max_epochs=epochs)\n",
    "\n",
    "        # evaluate model\n",
    "        kl_score, js_score = evaluate(g_model, d_model, [trainX, trainy], latent_dim)\n",
    "        return kl_score\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-03 04:57:07,317] Using an existing study with name 'emnist_letters_gan' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  28\n",
      "Best trial:\n",
      "  Value:  22.896785736083984\n",
      "  Params: \n",
      "    d_conv_layers: 3\n",
      "    d_num_filters_l0: 34\n",
      "    d_num_filters_l1: 33\n",
      "    d_num_filters_l2: 124\n",
      "    g_convT_layers: 4\n",
      "    g_num_filters_l0: 124\n",
      "    g_num_filters_l1: 64\n",
      "    g_num_filters_l2: 66\n",
      "    g_num_filters_l3: 65\n",
      "    epochs: 20\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize', study_name='emnist_letters_gan', storage='sqlite:///emnist_letters_gan10.db', load_if_exists=True)\n",
    "\n",
    "#study.optimize(objective, n_trials=1)\n",
    "\n",
    "#save to csv\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv('emnist_letters_gan10.csv')\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "# Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6272)         633472      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 50)        1300        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 6272)         0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1, 49)        2499        ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 7, 7, 128)    0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 7, 7, 1)      0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 7, 7, 129)    0           ['reshape_4[0][0]',              \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 14, 14, 124)  256060     ['concatenate_2[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 14, 14, 124)  0           ['conv2d_transpose_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 28, 28, 64)  127040      ['leaky_re_lu_9[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 28, 28, 64)   0           ['conv2d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 28, 28, 66)  38082       ['leaky_re_lu_10[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 28, 28, 66)   0           ['conv2d_transpose_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 28, 28, 65)  38675       ['leaky_re_lu_11[0][0]']         \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 28, 28, 65)   0           ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 28, 28, 1)    3186        ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,100,314\n",
      "Trainable params: 1,100,314\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "KL divergence: 2.867\n",
      "JS divergence: 0.018\n",
      "KL divergence:  2.8665311\n",
      "JS divergence:  0.017989277839660645\n"
     ]
    }
   ],
   "source": [
    "best_params = trial.params\n",
    "\n",
    "import json\n",
    "# save best params\n",
    "with open('best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "\n",
    "# save best model\n",
    "g_model = define_generator(100, trial=trial)\n",
    "print(g_model.summary())\n",
    "g_model.save('best_generator.h5')\n",
    "\n",
    "d_model = define_discriminator(trial=trial)\n",
    "d_model.save('best_discriminator.h5')\n",
    "\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "gan_model.save('best_gan.h5')\n",
    "\n",
    "# evaluate model\n",
    "kl_score, js_score = evaluate(g_model, d_model, [trainX, trainy], 100)\n",
    "print(\"KL divergence: \", kl_score)\n",
    "print(\"JS divergence: \", js_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21aad69f460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = g_model.predict([np.random.randn(100).reshape(1,100), np.array([3])])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
